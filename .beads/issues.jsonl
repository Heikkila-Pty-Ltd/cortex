{"id":"cortex-070","title":"Runbook: scheduler pause/resume maintenance operations","description":"Create a dedicated runbook for safe maintenance windows using scheduler pause/resume.\n\nAcceptance criteria:\n1) Document pre-checks, exact pause/resume API commands, and post-resume verification steps.\n2) Include at least one tabletop drill transcript or checklist under artifacts/launch/runbooks/.\n3) Link the runbook from docs/LAUNCH_READINESS_CHECKLIST.md runbook gate section.","status":"closed","priority":1,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:42:07.401303699+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T05:18:52.800671034+10:00","closed_at":"2026-02-18T05:18:52.800671034+10:00","close_reason":"Closed","labels":["stage:qa"],"dependencies":[{"issue_id":"cortex-070","depends_on_id":"cortex-c4j.3","type":"discovered-from","created_at":"2026-02-18T02:42:07.405631308+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-08z","title":"Phase 1: Cortex Core — Scheduler + Rate Limiter","description":"Working Go binary that reads beads from project dirs, builds dependency graphs, finds unblocked tasks, respects unified rate limits, dispatches openclaw agents, and tracks state in SQLite. This is the core scheduling engine.","status":"closed","priority":2,"issue_type":"epic","owner":"simon.heikkila@gmail.com","estimated_minutes":480,"created_at":"2026-02-17T13:33:07.156580998+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:54:32.932625657+10:00","closed_at":"2026-02-17T14:54:32.932625657+10:00","close_reason":"Phase 1 complete: all 10 tasks done, binary builds and tests pass","labels":["core","phase-1"]}
{"id":"cortex-08z.1","title":"Go module init + project scaffold","description":"Initialize Go module and create the full directory structure:\n\n  go mod init github.com/antigravity-dev/cortex\n  \nCreate all package directories per module layout:\n  cmd/cortex/, internal/config/, internal/beads/, internal/scheduler/,\n  internal/dispatch/, internal/health/, internal/learner/, internal/api/, internal/store/\n\nAdd core dependencies:\n  modernc.org/sqlite (pure-Go SQLite driver)\n  github.com/BurntSushi/toml (config parsing)\n\nCreate minimal main.go with signal handling skeleton (SIGINT/SIGTERM graceful shutdown).\nCreate Makefile with build, install, clean targets.\n\nAcceptance criteria:\n- go build ./cmd/cortex/ produces a working binary\n- Binary starts and exits cleanly on SIGINT\n- All package dirs exist with placeholder .go files","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":30,"created_at":"2026-02-17T13:45:59.053458725+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:40:50.31309257+10:00","closed_at":"2026-02-17T14:40:50.31309257+10:00","close_reason":"Scaffold complete: go mod, all packages, main.go with signal handling, Makefile, deps installed, builds clean","labels":["core","phase-1"],"dependencies":[{"issue_id":"cortex-08z.1","depends_on_id":"cortex-08z","type":"parent-child","created_at":"2026-02-17T13:45:59.057613426+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-08z.10","title":"Main binary entry point + systemd unit","description":"Wire everything together in cmd/cortex/main.go and create the systemd service file.\n\nmain.go:\n1. Parse flags: --config (default: cortex.toml), --once (run single tick then exit, for testing)\n2. Load config via config.Load()\n3. Open store via store.Open(config.StateDB)\n4. Create rateLimiter, dispatcher, scheduler\n5. Start scheduler in goroutine\n6. Block on signal (SIGINT/SIGTERM) for graceful shutdown\n7. On shutdown: cancel context, wait for running tick to finish, close store\n\ncortex.service (systemd user unit):\n  [Unit]\n  Description=Cortex Agent Orchestrator\n  After=openclaw-gateway.service\n\n  [Service]\n  Type=simple\n  ExecStart=%h/projects/cortex/cortex --config %h/projects/cortex/cortex.toml\n  Restart=always\n  RestartSec=10\n  Environment=PATH=%h/.local/bin:/usr/local/bin:/usr/bin\n\n  [Install]\n  WantedBy=default.target\n\nMakefile targets:\n  build: go build -o cortex ./cmd/cortex/\n  install: cp cortex ~/.local/bin/\n  service-install: cp cortex.service ~/.config/systemd/user/ \u0026\u0026 systemctl --user daemon-reload\n  service-start: systemctl --user enable --now cortex.service\n\nAcceptance criteria:\n- cortex binary starts, runs one tick with --once flag, exits cleanly\n- cortex binary runs continuously and responds to SIGTERM\n- systemd unit installs and starts correctly\n- Logs appear in journalctl --user -u cortex.service","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":45,"created_at":"2026-02-17T14:12:41.806052224+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:54:32.551083368+10:00","closed_at":"2026-02-17T14:54:32.551083368+10:00","close_reason":"Main binary, systemd unit, and Makefile all implemented","labels":["core","phase-1"],"dependencies":[{"issue_id":"cortex-08z.10","depends_on_id":"cortex-08z","type":"parent-child","created_at":"2026-02-17T14:12:41.809619678+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-08z.10","depends_on_id":"cortex-08z.9","type":"blocks","created_at":"2026-02-17T14:12:41.815717384+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-08z.2","title":"TOML config loader","description":"Implement internal/config/config.go that parses cortex.toml into typed Go structs.\n\nStructs needed:\n- Config (top-level): General, Projects map, RateLimits, Providers map, Tiers, Health, Reporter, API\n- General: TickInterval (duration), MaxPerTick (int), StuckTimeout (duration), MaxRetries (int), LogLevel (string), StateDB (path)\n- Project: Enabled (bool), BeadsDir (path), Workspace (path), Priority (int)\n- RateLimits: Window5hCap (int), WeeklyCap (int), WeeklyHeadroomPct (int)\n- Provider: Tier (string), Authed (bool), Model (string)\n- Tiers: Fast, Balanced, Premium ([]string provider names)\n- Health: CheckInterval (duration), GatewayUnit (string)\n- Reporter: Channel (string), AgentID (string), DailyDigestTime (string), WeeklyRetroDay (string)\n- API: Bind (string)\n\nValidate on load: all provider names in tiers exist in providers map, at least one project enabled, state_db dir exists.\n\nCreate the default cortex.toml with all providers and hg-website as the initial enabled project.\n\nAcceptance criteria:\n- Config loads from cortex.toml successfully\n- Invalid configs return descriptive errors\n- Unit test covers: valid config, missing required fields, unknown provider in tier","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":60,"created_at":"2026-02-17T13:50:22.592398066+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:48:50.180842457+10:00","closed_at":"2026-02-17T14:48:50.180842457+10:00","close_reason":"Implemented with tests, all passing","labels":["core","phase-1"],"dependencies":[{"issue_id":"cortex-08z.2","depends_on_id":"cortex-08z","type":"parent-child","created_at":"2026-02-17T13:50:22.618547657+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-08z.2","depends_on_id":"cortex-08z.1","type":"blocks","created_at":"2026-02-17T13:50:22.636563313+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-08z.3","title":"SQLite store layer","description":"Implement internal/store/store.go with SQLite operations.\n\nOn first run, auto-create schema:\n- dispatches table (id, bead_id, project, agent_id, provider, tier, pid, prompt, dispatched_at, completed_at, status, exit_code, duration_s, retries, escalated_from_tier)\n- provider_usage table (id, provider, agent_id, bead_id, dispatched_at)\n- health_events table (id, event_type, details, created_at)\n- tick_metrics table (id, tick_at, project, beads_open, beads_ready, dispatched, completed, failed, stuck)\n\nCRUD methods:\n- RecordDispatch(beadID, project, agent, provider, tier, pid, prompt) -\u003e id\n- UpdateDispatchStatus(id, status, exitCode, durationS)\n- GetRunningDispatches() -\u003e []Dispatch\n- GetStuckDispatches(timeout duration) -\u003e []Dispatch\n- RecordProviderUsage(provider, agentID, beadID)\n- CountAuthedUsage5h() -\u003e int\n- CountAuthedUsageWeekly() -\u003e int\n- RecordHealthEvent(eventType, details)\n- RecordTickMetrics(project, open, ready, dispatched, completed, failed, stuck)\n\nIndexes: idx_dispatches_status, idx_dispatches_bead, idx_usage_provider(provider, dispatched_at)\n\nAcceptance criteria:\n- All tables created on first Open()\n- All CRUD methods work with unit tests\n- Concurrent access safe (WAL mode enabled)\n- Database path from config.StateDB","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":90,"created_at":"2026-02-17T13:52:01.773492457+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:52:09.214755913+10:00","closed_at":"2026-02-17T14:52:09.214755913+10:00","close_reason":"Implemented with tests, all passing","labels":["core","phase-1"],"dependencies":[{"issue_id":"cortex-08z.3","depends_on_id":"cortex-08z","type":"parent-child","created_at":"2026-02-17T13:52:01.785318491+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-08z.3","depends_on_id":"cortex-08z.2","type":"blocks","created_at":"2026-02-17T13:52:01.796104448+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-08z.4","title":"Beads CLI wrapper","description":"Implement internal/beads/beads.go that wraps the bd CLI to read bead data from project directories.\n\nFunctions:\n- ListBeads(beadsDir string) -\u003e []Bead, error\n  Runs: bd list --json --quiet in the given directory\n  Parses JSON into Bead structs\n\n- ShowBead(beadsDir, beadID string) -\u003e BeadDetail, error\n  Runs: bd show --json {beadID}\n\n- CloseBead(beadsDir, beadID string) -\u003e error\n  Runs: bd close {beadID}\n\nBead struct fields:\n  ID, Title, Description, Status, Priority, Type, Labels []string,\n  EstimateMinutes int, ParentID string, DependsOn []string,\n  Acceptance string, Design string, CreatedAt time.Time\n\nBuildDepGraph(beads []Bead) -\u003e *DepGraph\n  Builds a directed graph from DependsOn + ParentID edges.\n  \nFilterUnblockedOpen(graph *DepGraph) -\u003e []Bead\n  Returns beads that are: status=open AND all DependsOn beads are closed AND parent is open (not skipped).\n  Sorted by: Priority ASC (P0 first), then EstimateMinutes ASC.\n\nAcceptance criteria:\n- ListBeads correctly parses bd list --json output\n- DepGraph correctly identifies unblocked beads\n- Unit tests with sample JSON fixtures (no actual bd calls)\n- Handles empty bead lists gracefully","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":90,"created_at":"2026-02-17T13:52:33.664382221+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:48:50.205960855+10:00","closed_at":"2026-02-17T14:48:50.205960855+10:00","close_reason":"Implemented with tests, all passing","labels":["core","phase-1"],"dependencies":[{"issue_id":"cortex-08z.4","depends_on_id":"cortex-08z","type":"parent-child","created_at":"2026-02-17T13:52:33.668720161+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-08z.4","depends_on_id":"cortex-08z.1","type":"blocks","created_at":"2026-02-17T13:52:33.674972084+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-08z.5","title":"Unified rate limiter","description":"Implement internal/dispatch/ratelimit.go with the unified authed rate limiter.\n\nCore concept: All authed subscription providers (Claude Max20, OpenAI Pro, Google Pro, Kimi) share two hard gates — a 5h rolling window cap and a weekly cap. Free-tier providers (cerebras, groq) are uncapped.\n\nFunctions:\n- NewRateLimiter(store *store.Store, cfg config.RateLimits) -\u003e *RateLimiter\n- CanDispatchAuthed() -\u003e (bool, string reason)\n  Checks both gates against store.CountAuthedUsage5h() and store.CountAuthedUsageWeekly()\n  Returns false + reason if either gate exceeded\n- RecordAuthedDispatch(provider, agentID, beadID string)\n  Delegates to store.RecordProviderUsage()\n- WeeklyUsagePct() -\u003e float64\n  Returns current weekly usage as percentage of cap\n- IsInHeadroomWarning() -\u003e bool\n  Returns true if WeeklyUsagePct \u003e= config.WeeklyHeadroomPct (default 80%)\n\nAlgorithm for provider selection within a tier:\n- PickProvider(tier string, providers []config.Provider) -\u003e *config.Provider\n  1. If tier is fast -\u003e pick from free providers (no quota check)\n  2. If tier is balanced/premium -\u003e check CanDispatchAuthed()\n  3. If authed gates pass -\u003e return first available provider in tier order\n  4. If gates fail -\u003e return nil (caller handles tier downgrade)\n\nTier downgrade logic (in scheduler, not here):\n  premium -\u003e balanced -\u003e fast, or defer to next tick\n\nAcceptance criteria:\n- 5h rolling window correctly counts dispatches in last 5 hours\n- Weekly rolling window correctly counts dispatches in last 7 days\n- Free-tier providers bypass all gates\n- Headroom warning triggers at configured percentage\n- Unit tests with seeded usage data covering: under cap, at cap, over cap, headroom warning","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":60,"created_at":"2026-02-17T13:52:59.000042143+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:52:58.486999173+10:00","closed_at":"2026-02-17T14:52:58.486999173+10:00","close_reason":"Rate limiter implemented with tests, all passing","labels":["core","phase-1"],"dependencies":[{"issue_id":"cortex-08z.5","depends_on_id":"cortex-08z","type":"parent-child","created_at":"2026-02-17T13:52:59.002997357+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-08z.5","depends_on_id":"cortex-08z.3","type":"blocks","created_at":"2026-02-17T13:52:59.008672868+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-08z.6","title":"Role inference + complexity detection","description":"Implement internal/scheduler/role.go and internal/scheduler/complexity.go.\n\nRole inference (role.go):\n- InferRole(bead Bead) -\u003e string\n  Maps bead labels/type to agent role:\n  | Bead Labels / Type | Role |\n  | Any open bead with code files listed | coder |\n  | Label contains review, test, qa | reviewer |\n  | Label contains deploy, ops, ci | ops |\n  | Type = epic | skip (Cortex tracks epic completion automatically) |\n  | Default | coder |\n  \n- ResolveAgent(project string, role string) -\u003e string\n  Returns '{project}-{role}' (e.g. 'hg-website-coder')\n  Falls back to 'main-{role}' if project-specific agent doesn't exist\n\nComplexity detection (complexity.go):\n- DetectComplexity(bead Bead) -\u003e string (tier: fast|balanced|premium)\n  | Signal | Tier |\n  | estimated_minutes \u003c= 30 | fast |\n  | estimated_minutes 31-90 | balanced |\n  | estimated_minutes \u003e 90 | premium |\n  | Label complex or architecture | premium |\n  | Label trivial or chore | fast |\n  Labels override time-based detection.\n\nAcceptance criteria:\n- Role correctly inferred from labels with priority ordering\n- Complexity correctly maps estimate + labels to tier\n- Label override takes precedence over time estimate\n- Unit tests cover all mapping combinations","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":45,"created_at":"2026-02-17T13:56:22.89995188+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:52:09.244025453+10:00","closed_at":"2026-02-17T14:52:09.244025453+10:00","close_reason":"Implemented with tests, all passing","labels":["core","phase-1"],"dependencies":[{"issue_id":"cortex-08z.6","depends_on_id":"cortex-08z","type":"parent-child","created_at":"2026-02-17T13:56:22.903471817+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-08z.6","depends_on_id":"cortex-08z.4","type":"blocks","created_at":"2026-02-17T13:56:22.908012317+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-08z.7","title":"Agent prompt builder","description":"Implement internal/scheduler/prompt.go that constructs the prompt sent to openclaw agents.\n\nFunction:\n- BuildPrompt(bead Bead, project config.Project) -\u003e string\n\nTemplate:\n  You are working on project {project_name} in {workspace_dir}.\n\n  ## Task: {bead.title} ({bead.id})\n\n  {bead.description}\n\n  ## Acceptance Criteria\n  {bead.acceptance}\n\n  ## Design Notes\n  {bead.design}\n\n  ## Instructions\n  1. Read the acceptance criteria carefully\n  2. Implement in the files listed (create if needed)\n  3. Run tests if they exist\n  4. Commit with message: feat({bead.id}): {short_title}\n  5. When done, run: bd close {bead.id}\n  6. Push: git push\n\n  ## Context Files\n  {extracted file paths from bead description}\n\nFile extraction: scan description for paths matching common patterns (src/, internal/, *.go, *.ts, *.py, etc.)\n\nAcceptance criteria:\n- Prompt includes all bead metadata (title, description, acceptance, design)\n- File paths extracted from description\n- Template is readable and well-structured\n- Unit test verifies template rendering with sample bead","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":30,"created_at":"2026-02-17T13:56:47.58364861+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:52:09.287511394+10:00","closed_at":"2026-02-17T14:52:09.287511394+10:00","close_reason":"Implemented with tests, all passing","labels":["core","phase-1"],"dependencies":[{"issue_id":"cortex-08z.7","depends_on_id":"cortex-08z","type":"parent-child","created_at":"2026-02-17T13:56:47.587726938+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-08z.7","depends_on_id":"cortex-08z.4","type":"blocks","created_at":"2026-02-17T13:56:47.59525896+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-08z.8","title":"OpenClaw agent dispatcher","description":"Implement internal/dispatch/dispatcher.go that wraps the openclaw CLI to dispatch agents.\n\nFunctions:\n- Dispatch(agent string, prompt string, provider string, thinkingLevel string) -\u003e (pid int, error)\n  Runs: openclaw agent --agent {agent} --message {prompt} --thinking {thinkingLevel}\n  Starts process in background, returns PID for tracking.\n  thinkingLevel derived from tier: fast=none, balanced=low, premium=high\n\n- IsProcessAlive(pid int) -\u003e bool\n  Checks if PID is still running via kill -0\n\n- KillProcess(pid int) -\u003e error\n  Sends SIGTERM, waits 5s, then SIGKILL if still alive\n\nEnvironment setup:\n  Ensure openclaw binary is in PATH\n  Set CWD to project workspace directory\n\nAcceptance criteria:\n- Dispatch starts an openclaw agent process and returns valid PID\n- IsProcessAlive correctly reports live/dead processes\n- KillProcess terminates gracefully with fallback to SIGKILL\n- Unit tests mock exec.Command for isolation\n- Integration test (manual): dispatches a real agent with a trivial prompt, confirms PID tracking","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":60,"created_at":"2026-02-17T13:58:10.798997021+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:48:50.233413221+10:00","closed_at":"2026-02-17T14:48:50.233413221+10:00","close_reason":"Implemented with tests, all passing","labels":["core","phase-1"],"dependencies":[{"issue_id":"cortex-08z.8","depends_on_id":"cortex-08z","type":"parent-child","created_at":"2026-02-17T13:58:10.801768094+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-08z.8","depends_on_id":"cortex-08z.1","type":"blocks","created_at":"2026-02-17T13:58:10.857391397+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-08z.9","title":"Core scheduler tick loop","description":"Implement internal/scheduler/scheduler.go — the main orchestration loop that ties everything together.\n\nScheduler struct holds references to: config, store, rateLimiter, dispatcher, logger.\n\nRunTick() method (called every config.TickInterval):\n1. For each enabled project (sorted by priority):\n   a. beads = ListBeads(project.BeadsDir)\n   b. graph = BuildDepGraph(beads)\n   c. ready = FilterUnblockedOpen(graph)\n   d. Record tick metrics (beads_open, beads_ready counts)\n   \n2. For each ready bead (up to maxPerTick across all projects):\n   a. Skip if alreadyDispatched (check store.GetRunningDispatches)\n   b. role = InferRole(bead) — skip if epic\n   c. tier = DetectComplexity(bead)\n   d. provider = rateLimiter.PickProvider(tier)\n   e. If provider nil: try tier downgrade (premium-\u003ebalanced-\u003efast), log if all exhausted\n   f. prompt = BuildPrompt(bead, project)\n   g. agent = ResolveAgent(project.Name, role)\n   h. pid = dispatcher.Dispatch(agent, prompt, provider, thinkingLevel)\n   i. store.RecordDispatch(bead.ID, project.Name, agent, provider, tier, pid, prompt)\n   j. rateLimiter.RecordAuthedDispatch(provider) if authed\n   \n3. CheckRunningDispatches():\n   a. For each running dispatch in store:\n   b. If PID dead -\u003e mark completed or failed based on exit code\n   c. Record duration\n\nStart() method:\n  Runs RunTick in a goroutine on a ticker, respects context cancellation for graceful shutdown.\n\nAcceptance criteria:\n- Tick loop iterates projects by priority\n- Respects maxPerTick limit across all projects\n- Skips already-dispatched beads (no double dispatch)\n- Tier downgrade works: premium-\u003ebalanced-\u003efast\n- Running dispatch status polling detects completed/failed\n- Integration test: mock all deps, verify dispatch sequence with sample beads\n- Structured logging (slog) for each dispatch decision","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":120,"created_at":"2026-02-17T14:07:02.448542707+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:53:43.738555982+10:00","closed_at":"2026-02-17T14:53:43.738555982+10:00","close_reason":"Scheduler tick loop implemented, all tests pass","labels":["core","phase-1"],"dependencies":[{"issue_id":"cortex-08z.9","depends_on_id":"cortex-08z","type":"parent-child","created_at":"2026-02-17T14:07:02.453104918+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-08z.9","depends_on_id":"cortex-08z.3","type":"blocks","created_at":"2026-02-17T14:07:02.459620762+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-08z.9","depends_on_id":"cortex-08z.4","type":"blocks","created_at":"2026-02-17T14:07:02.463452132+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-08z.9","depends_on_id":"cortex-08z.5","type":"blocks","created_at":"2026-02-17T14:07:02.467106582+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-08z.9","depends_on_id":"cortex-08z.6","type":"blocks","created_at":"2026-02-17T14:07:02.470851552+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-08z.9","depends_on_id":"cortex-08z.7","type":"blocks","created_at":"2026-02-17T14:07:02.474640783+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-08z.9","depends_on_id":"cortex-08z.8","type":"blocks","created_at":"2026-02-17T14:07:02.478246162+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-0gc","title":"StageForRole returns nondeterministic result for multi-stage roles","description":"StageForRole iterates over the stageRoles map which has Go's nondeterministic map iteration. For role 'coder', it could return either 'stage:ready' or 'stage:coding' depending on iteration order. Should return the earliest (lowest-order) stage for the role, since that's the entry point stage.","status":"closed","priority":2,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:40:57.896664699+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T20:03:22.283998294+10:00","closed_at":"2026-02-17T20:03:22.283998294+10:00","close_reason":"Fixed in role.go — StageForRole now returns lowest-order stage"}
{"id":"cortex-0kw","title":"Phase 5: Status API + Polish","description":"HTTP status endpoints (/status, /projects/{id}, /health, /metrics), Makefile with build/install/service-install targets, graceful shutdown, structured logging (slog), README.md with architecture overview.","status":"closed","priority":2,"issue_type":"epic","owner":"simon.heikkila@gmail.com","estimated_minutes":240,"created_at":"2026-02-17T13:40:32.974740877+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T15:03:00.339150723+10:00","closed_at":"2026-02-17T15:03:00.339150723+10:00","close_reason":"Closed","labels":["api","phase-5","polish"]}
{"id":"cortex-0kw.1","title":"HTTP status API","description":"Implement internal/api/api.go — lightweight HTTP API for querying Cortex state.\n\nEndpoints:\n- GET /status -\u003e overall Cortex status (uptime, last tick, dispatches running, rate limiter state)\n- GET /projects -\u003e list of enabled projects with bead counts (open, ready, running, completed)\n- GET /projects/{id} -\u003e detailed project view: recent dispatches, ready beads, velocity\n- GET /health -\u003e health check summary: gateway status, recent health events, stuck count\n- GET /metrics -\u003e Prometheus-compatible metrics: dispatches_total, dispatches_failed_total, rate_limiter_usage_ratio, tick_duration_seconds\n\nServer:\n- net/http stdlib (no framework needed for 5 endpoints)\n- Bind to config.API.Bind (default 127.0.0.1:8900)\n- JSON responses with proper Content-Type headers\n- Starts as goroutine from main.go, shutdown via context cancellation\n\nAcceptance criteria:\n- All 5 endpoints return valid JSON\n- /health returns 200 when healthy, 503 when gateway down\n- /metrics compatible with Prometheus scraping format\n- Server starts on configured bind address\n- Graceful shutdown on context cancellation\n- Unit tests for each endpoint handler with mock store data","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":60,"created_at":"2026-02-17T14:25:40.41699718+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T15:01:50.741273815+10:00","closed_at":"2026-02-17T15:01:50.741273815+10:00","close_reason":"Closed","labels":["api","phase-5"],"dependencies":[{"issue_id":"cortex-0kw.1","depends_on_id":"cortex-0kw","type":"parent-child","created_at":"2026-02-17T14:25:40.443618494+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-0kw.1","depends_on_id":"cortex-08z.3","type":"blocks","created_at":"2026-02-17T14:25:40.487881873+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-0kw.1","depends_on_id":"cortex-08z.10","type":"blocks","created_at":"2026-02-17T14:25:40.506134929+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-0kw.2","title":"Structured logging with slog","description":"Replace all fmt.Printf/log.Printf calls with Go's structured logging (log/slog).\n\nSetup:\n- Configure slog in main.go based on config.LogLevel (debug/info/warn/error)\n- Use slog.With() for per-component loggers: scheduler, dispatcher, health, api, learner\n- JSON output format for machine parsing, text format for development (--dev flag)\n\nLog key events with structured fields:\n- Dispatch: bead_id, project, agent, provider, tier, pid\n- Completion: bead_id, duration_s, exit_code, status\n- Rate limit: tier, usage_5h, usage_weekly, cap_5h, cap_weekly\n- Health: event_type, details, action_taken\n- Tick: project, beads_open, beads_ready, dispatched_count\n\nAcceptance criteria:\n- All log output uses slog with structured fields\n- Log level configurable via cortex.toml\n- JSON format in production, text in dev\n- No raw fmt.Printf left in non-test code\n- Logs parseable by standard log aggregators","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":30,"created_at":"2026-02-17T14:26:00.96225876+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T15:01:50.781848424+10:00","closed_at":"2026-02-17T15:01:50.781848424+10:00","close_reason":"Closed","labels":["phase-5","polish"],"dependencies":[{"issue_id":"cortex-0kw.2","depends_on_id":"cortex-0kw","type":"parent-child","created_at":"2026-02-17T14:26:01.00291675+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-0kw.2","depends_on_id":"cortex-08z.10","type":"blocks","created_at":"2026-02-17T14:26:01.074752193+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-0kw.3","title":"Graceful shutdown + README","description":"Polish the binary for production use.\n\nGraceful shutdown (enhance main.go):\n1. On SIGTERM/SIGINT: set shutdown flag\n2. Wait for any in-progress tick to complete (don't kill mid-dispatch)\n3. Close HTTP API server with context timeout (5s)\n4. Close SQLite store cleanly\n5. Log shutdown reason and duration\n\nREADME.md:\n- Architecture overview with ASCII diagram from plan\n- Quick start: build, configure cortex.toml, install systemd unit, start\n- Configuration reference: all cortex.toml sections with defaults\n- Provider setup: how to add/remove providers\n- Project setup: how to enable a new project (beads dir, workspace, agent creation)\n- Monitoring: how to query the HTTP API, where logs go\n- Troubleshooting: common issues (gateway down, rate limit hit, stuck tasks)\n\nAcceptance criteria:\n- Binary handles shutdown cleanly in all states (idle, mid-tick, mid-dispatch)\n- README covers all sections listed above\n- README is accurate to the actual implementation\n- No orphan processes left on shutdown","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":45,"created_at":"2026-02-17T14:26:28.456959192+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T15:03:00.120347648+10:00","closed_at":"2026-02-17T15:03:00.120347648+10:00","close_reason":"Closed","labels":["phase-5","polish"],"dependencies":[{"issue_id":"cortex-0kw.3","depends_on_id":"cortex-0kw","type":"parent-child","created_at":"2026-02-17T14:26:28.712913955+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-0kw.3","depends_on_id":"cortex-0kw.1","type":"blocks","created_at":"2026-02-17T14:26:28.73566296+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-0kw.3","depends_on_id":"cortex-0kw.2","type":"blocks","created_at":"2026-02-17T14:26:28.741505263+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-0u3","title":"Implement config-driven backend selection","description":"Replace hardcoded tmux availability check with dispatch.routing configuration. Currently dispatcher selection ignores configured backend preferences.\n\n## Goal  \nMake dispatch.routing.*_backend settings control actual dispatcher selection instead of being ignored.\n\n## Current Problem\ncmd/cortex/main.go hardcodes dispatcher selection:\n```go\nif dispatch.IsTmuxAvailable() {\n    d = dispatch.NewTmuxDispatcher()\n} else {  \n    d = dispatch.NewDispatcher()\n}\n```\n\nThe configured routing.fast_backend, routing.balanced_backend, etc. are unused.\n\n## Scope\n- Replace hardcoded selection with config-driven logic\n- Support backend names: \"tmux\", \"headless_cli\", \"pid\"\n- Add validation for backend names in config validation\n- Preserve fallback behavior for missing/unavailable backends\n- Update main.go to use routing configuration\n\n## Acceptance Criteria  \n1) Dispatcher selection uses dispatch.routing.*_backend configuration\n2) Invalid backend names fail config validation with clear messages\n3) Unavailable backends (e.g., tmux not installed) fall back gracefully  \n4) All tier mappings (fast/balanced/premium/comms/retry) work correctly\n5) Backward compatibility maintained when routing config is missing\n\n## Test Coverage\n- Valid backend configurations select correct dispatcher\n- Invalid backend names fail validation\n- Missing tmux falls back to PID dispatcher  \n- All routing tiers work correctly","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:30:54.933335708+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:30:54.933335708+10:00","labels":["config","dispatch","routing"]}
{"id":"cortex-13y","title":"Cortex --once mode doesn't wait for dispatched agents to complete","description":"In --once mode, Cortex dispatches agents to tmux sessions then exits immediately without waiting for completion. The agents keep running but subsequent --once invocations don't properly coordinate with them. Options: (1) --once waits for agents to finish, (2) --once skips dispatch if live sessions exist, (3) add --fire-and-forget flag for current behavior.","status":"open","priority":2,"issue_type":"bug","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T21:09:39.741988815+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T01:25:29.721320642+10:00","labels":["code","scheduler"]}
{"id":"cortex-19e","title":"Add per-project reporter routing","description":"Modify Reporter to send messages through project-specific agents instead of generic 'main' agent. Simplified version of cortex-a4s.3.\n\n## Goal\nRoute digest messages through each project's scrum master agent for personalized communication.\n\n## Scope\nModify internal/learner/reporter.go to dispatch per-project instead of broadcasting:\n\n## Current Behavior\n- Reporter.SendDigest() dispatches to single 'main' agent\n- Message goes to global reporter.channel\n\n## New Behavior  \n- Reporter.SendProjectDigest(project) dispatches to '{project}-scrum' agent\n- Each project gets its own digest with project-specific content\n- Fall back to 'main' agent if project scrum agent doesn't exist\n\n## Implementation\n- Modify SendDigest() to iterate over enabled projects\n- Create SendProjectDigest(project) method\n- Agent resolution: try '{project}-scrum', fallback to 'main'  \n- Include basic project stats in digest (use cortex-nkq when ready)\n\n## Acceptance Criteria\n1) SendDigest iterates all enabled projects and calls SendProjectDigest\n2) SendProjectDigest uses '{project}-scrum' agent naming convention\n3) Falls back to 'main' agent if project agent doesn't exist\n4) Each project gets tailored digest with project name\n5) Backward compatible - works with existing agent configs\n6) Unit tests cover agent resolution and fallback logic\n\n## Dependencies\n- Requires cortex-a4s.1 (Matrix room config) for routing\n- Can use cortex-nkq (project stats) when available","status":"open","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:38:08.640795649+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:38:08.640795649+10:00","labels":["reporting","routing","scrum"],"dependencies":[{"issue_id":"cortex-19e","depends_on_id":"cortex-a4s.1","type":"blocks","created_at":"2026-02-18T02:39:02.824404227+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-1b2","title":"Wire TmuxDispatcher into scheduler","description":"Replace *dispatch.Dispatcher with *dispatch.TmuxDispatcher in scheduler.go and main.go. Change dispatch tracking from PID (int) to session name (string). Update store.RecordDispatch and store.GetRunningDispatches to use session names. Update checkRunningDispatches to use SessionStatus() instead of IsProcessAlive(). The TmuxDispatcher already exists in internal/dispatch/tmux.go with full Dispatch/SessionStatus/CaptureOutput/KillSession methods.\n\n⚠️  EXISTING PARTIAL WORK: The scheduler already has hybrid PID/tmux support with output capture in checkRunningDispatches(), and store has dispatch_output table with CaptureOutput/GetOutput methods. Need to complete the transition by updating main.go dispatcher creation, store schema to include session_name column, and removing PID-based heuristics.","design":"Complete TmuxDispatcher integration by replacing PID-based dispatch tracking with session-name based tracking.\n\n## Current State Analysis\n- Scheduler has hybrid PID/tmux support with heuristic tryParseSessionName method\n- TmuxDispatcher exists with Dispatch(ctx, sessionName, agentCmd, workDir, env) error signature\n- Store schema has pid INTEGER column but needs session_name TEXT\n- Output capture infrastructure already exists via dispatch_output table\n\n## Implementation Plan\n\n### 1. Database Schema Migration\n- File: internal/store/store.go\n- Add migration to include session_name TEXT column in dispatches table\n- Keep pid column temporarily for backward compatibility during migration\n\n### 2. Update Store Methods  \n- File: internal/store/store.go\n- Modify Dispatch struct: add SessionName string field\n- Update RecordDispatch signature to accept sessionName instead of pid\n- Update queries in GetRunningDispatches, GetStuckDispatches to work with session names\n- Update queryDispatches to handle new field\n\n### 3. Update Scheduler Implementation\n- File: internal/scheduler/scheduler.go  \n- Change struct field: dispatcher *dispatch.TmuxDispatcher instead of *dispatch.Dispatcher\n- Update New constructor signature to accept *dispatch.TmuxDispatcher\n- In RunTick dispatch logic:\n  - Generate session name using dispatch.SessionName(item.name, item.bead.ID)\n  - Call dispatcher.Dispatch(ctx, sessionName, agentCmd, workDir, env) - note no PID return\n  - Update store.RecordDispatch call to pass session name instead of PID\n- In checkRunningDispatches:  \n  - Remove tryParseSessionName heuristic method\n  - Use stored session names directly from database\n  - Replace dispatch.IsProcessAlive(d.PID) with dispatch.SessionStatus(d.SessionName)\n  - Update logging to show session names\n\n### 4. Update Main.go\n- File: cmd/cortex/main.go\n- Change: d := dispatch.NewTmuxDispatcher() instead of dispatch.NewDispatcher()\n- Update scheduler constructor call to pass TmuxDispatcher\n\n### 5. Build Agent Command String\n- File: internal/scheduler/scheduler.go\n- Create agent command string for TmuxDispatcher (openclaw command with proper args)\n- Set up environment variables map for dispatch call\n\n### 6. Update Tests\n- Files: Various test files  \n- Update tests to work with session-based dispatching\n- Mock TmuxDispatcher interface\n- Test session name generation and lifecycle\n\n### 7. Clean Up\n- Remove unused PID-based logic and imports\n- Remove tryParseSessionName method\n- Update error handling for new dispatch signature\n\n## Files to Modify\n1. internal/scheduler/scheduler.go - Core scheduler changes\n2. cmd/cortex/main.go - Dispatcher initialization  \n3. internal/store/store.go - Schema migration and method updates\n4. internal/scheduler/scheduler_test.go - Update tests\n5. internal/store/store_test.go - Update tests\n\n## Migration Strategy\n- Add session_name column with migration \n- Populate session_name for existing records where possible\n- Phase out PID usage gradually\n- Maintain backward compatibility during transition\n\n## Risk Mitigation\n- Keep existing dispatch_output capture working\n- Ensure session name collision handling\n- Add proper error handling for tmux command failures\n- Validate session lifecycle management","acceptance_criteria":"\nACCEPTANCE CRITERIA:\n1. **Main.go Integration**: Replace dispatch.NewDispatcher() with dispatch.NewTmuxDispatcher() in main.go and update scheduler constructor call\n2. **Scheduler Struct Update**: Change Scheduler.dispatcher field to *dispatch.TmuxDispatcher and update New() constructor signature\n3. **Database Schema Migration**: Add session_name TEXT NOT NULL DEFAULT '' column to dispatches table with proper migration handling\n4. **Store Struct Update**: Add SessionName string field to store.Dispatch struct and update all related scanning/queries\n5. **Store Method Signature**: Update store.RecordDispatch to accept (beadID, project, agent, provider, tier, sessionName, prompt) - remove pid parameter\n6. **Agent Command Building**: Create proper openclaw agent command string and environment map for TmuxDispatcher.Dispatch() call\n7. **Dispatch Call Update**: In scheduler RunTick:\n   - Generate session name using dispatch.SessionName(projectName, beadID) \n   - Call dispatcher.Dispatch(ctx, sessionName, agentCmd, workDir, env)\n   - Handle error-only return (no PID)\n   - Update store.RecordDispatch call with session name\n8. **Session Status Integration**: In checkRunningDispatches:\n   - Remove tryParseSessionName heuristic method entirely\n   - Use d.SessionName directly from database\n   - Replace dispatch.IsProcessAlive(d.PID) with dispatch.SessionStatus(d.SessionName)\n   - Update all logging to show session names instead of PIDs\n9. **Query Updates**: Update store.GetRunningDispatches, GetStuckDispatches, and queryDispatches to handle SessionName field\n10. **Backward Compatibility**: Ensure migration handles existing records gracefully (null/empty session names)\n11. **Test Updates**: Update all tests in scheduler_test.go and store_test.go to work with session-based dispatching\n12. **Cleanup**: Remove unused imports, PID-based logic, and ensure dispatch_output capture still works with session-based flow\n13. **Validation**: Verify session name collision handling and tmux command failure error handling","status":"closed","priority":0,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":4,"created_at":"2026-02-17T17:57:08.716910567+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T18:31:16.564163482+10:00","closed_at":"2026-02-17T18:31:16.564163482+10:00","close_reason":"Duplicate of cortex-j5d.1 — merging design notes from this bead into j5d.1. Both cover TmuxDispatcher integration.","labels":["code","stage:backlog","stage:ready"],"dependencies":[{"issue_id":"cortex-1b2","depends_on_id":"cortex-j5d","type":"parent-child","created_at":"2026-02-17T17:57:21.688315317+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-1ik","title":"Add chief scrum master configuration schema","description":"Add configuration support for Chief Scrum Master in cortex.toml. Foundation for cross-team coordination.\n\n## Goal\nExtend configuration to support Chief Scrum Master coordination settings.\n\n## Scope\nAdd Chief SM configuration section to internal/config/config.go:\n\n## Configuration Schema\n\n\n## Implementation\n- Add Chief struct to Config with Enabled, MatrixRoom, Model, AgentID fields\n- Add validation: if enabled, require matrix_room and agent_id\n- Add defaults in applyDefaults(): model defaults to premium tier\n- Backward compatible: chief section optional\n\n## Acceptance Criteria  \n1) Config parses [chief] section correctly\n2) Validation fails if enabled=true but missing required fields\n3) Defaults apply correctly (model, agent_id)\n4) Configuration is backward compatible (no [chief] section works)\n5) Unit tests cover parsing and validation scenarios\n\n## Files to Create/Modify\n- internal/config/config.go (add Chief struct and validation)\n- internal/config/config_test.go (test chief configuration)","status":"closed","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:43:37.733950773+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T03:08:57.215245595+10:00","closed_at":"2026-02-18T03:08:54.091420242+10:00","close_reason":"Closed","labels":["stage:qa","stage:review"]}
{"id":"cortex-1ix","title":"Add basic cross-project statistics queries","description":"Create basic queries to gather statistics across all projects for coordination. Foundation for Chief Scrum Master context.\n\n## Goal  \nProvide cross-project visibility with simple statistics queries.\n\n## Scope\nCreate internal/coordination/stats.go with cross-project query functions:\n\n## Data Structure\nSimple project summary with key metrics:\n- Project name and configuration\n- Open bead counts (by stage/priority)\n- Running dispatch counts\n- Completion rates (daily/weekly)\n- Current velocity estimates\n\n## Implementation\n- Query beads.ListBeads() across all enabled projects\n- Query store.GetRunningDispatches() grouped by project  \n- Query recent dispatch completions/failures by project\n- Calculate basic velocity (completed beads per day)\n- Format as structured data for downstream consumers\n\n## Output Format\nReturn structured slice of project summaries for easy processing by other coordination components.\n\n## Acceptance Criteria\n1) Queries all enabled projects from configuration\n2) Returns accurate counts for open/running/completed beads\n3) Calculates basic velocity metrics per project\n4) Handles empty/inactive projects gracefully\n5) Efficient queries (no N+1 patterns)\n6) Unit tests cover cross-project statistics gathering\n\n## Files to Create\n- internal/coordination/stats.go\n- internal/coordination/stats_test.go","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:44:05.61921003+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:44:05.61921003+10:00","labels":["coordination","cross-project","statistics"]}
{"id":"cortex-1jl","title":"Scheduler re-dispatches same bead every tick when agent exits quickly","description":"When a dispatched agent completes (or fails) within the 60s tick interval, checkRunningDispatches marks the dispatch as completed, making the bead eligible for re-dispatch on the next tick. This causes repeated dispatches of the same bead burning credits. Partial fix: HasLiveSession() check added. Full fix needed: cooldown period after dispatch completion, or smarter bead-level dedup that checks recent dispatch history.","notes":"**Review Result: APPROVED**\n\n**Excellent Implementation - Comprehensive Solution**\n\n## Dual Protection Against Re-Dispatch\n\n**Two-Layer Defense Implemented:**\n\n1. **Cooldown Period Check** - WasBeadDispatchedRecently prevents re-dispatch within configurable period\n   - Default: 5 minutes cooldown via dispatch_cooldown config\n   - Database-driven: queries recent dispatch history per bead\n   - Configurable and can be disabled by setting to 0\n\n2. **Live Session Check** - HasLiveSession prevents dispatch when tmux sessions still running\n   - Catches cases where DB shows completed but tmux pane still active\n   - Pattern matching for cortex session names\n   - Only considers running status sessions\n\n## Implementation Quality\n\n**Configuration Integration:**\n- DispatchCooldown Duration in config.General\n- TOML: dispatch_cooldown = 5m\n- Proper defaults with 5 minutes fallback\n- Zero-duration disables feature\n\n**Database Method:**\n- WasBeadDispatchedRecently with time window check\n- Efficient single query with time cutoff\n- Proper error handling\n\n**Scheduler Integration:**\n- Early check before agent resolution\n- Debug logging for troubleshooting\n- Clean continue logic on cooldown hit\n\n## Testing Excellence\n\n**Comprehensive Test Coverage:**\n- Store cooldown tests: 3 tests covering basic functionality, multi-bead, multiple dispatches\n- Scheduler cooldown tests: 2 tests for enabled/disabled scenarios\n- All tests pass\n- Clean compilation\n\n## Problem Resolution\n\n**Original Issue**: Agent completes within 60s → re-dispatched next tick → credit burn\n\n**Solution Effectiveness:**\n- Prevents rapid re-dispatch via cooldown window\n- Catches live sessions that DB missed\n- Configurable behavior for different environments\n- Preserves normal flow for legitimate retries\n\n## Architecture Assessment\n\n**Design Strengths:**\n- Non-intrusive: fits cleanly into existing dispatch logic\n- Performant: single DB query per bead check\n- Flexible: configurable cooldown period\n- Defensive: dual-layer protection\n- Observable: proper logging\n\n**Backward Compatibility:**\n- Default 5min cooldown reasonable for most cases\n- Can disable with zero duration\n- No breaking changes to existing APIs\n\nOutstanding implementation addressing core P1 issue with robust, well-tested solution.\n\nApproved for stage:qa","status":"closed","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T21:09:36.46504164+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T21:26:14.121170411+10:00","closed_at":"2026-02-17T21:25:06.966445232+10:00","close_reason":"Closed","labels":["stage:qa","stage:review"]}
{"id":"cortex-255","title":"Operational resilience improvements","description":"Several reliability gaps in the current implementation: ungraceful shutdown (500ms hardcoded sleep), fragile zombie detection via pgrep, simplistic retry strategy (always escalate tier), no backoff.\n\nKey deliverables:\n- Graceful shutdown: wait for running dispatches to complete (with timeout)\n- Smarter retry: exponential backoff, not just tier escalation\n- Zombie detection via tmux session list (replaces fragile pgrep)\n- Startup validation: verify config completeness before starting\n- Signal handling: SIGUSR1 for state dump","status":"open","priority":2,"issue_type":"epic","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:57:33.623757994+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T17:57:33.623757994+10:00"}
{"id":"cortex-255.1","title":"Implement graceful shutdown with dispatch draining","description":"Replace the 500ms hardcoded sleep with proper graceful shutdown that waits for running dispatches.\n\nChanges to cmd/cortex/main.go:\n- On SIGINT/SIGTERM: cancel context, then wait for goroutines\n- Use sync.WaitGroup for scheduler, health monitor, API server\n- Add shutdown timeout (configurable, default 60s)\n- If timeout reached, log warning and force exit\n\nChanges to internal/scheduler/scheduler.go:\n- On context cancellation: stop accepting new ticks\n- Wait for any in-progress tick to complete\n- Log: 'scheduler shutdown: N dispatches still running'\n\nChanges to internal/api/api.go:\n- Use http.Server.Shutdown(ctx) for graceful HTTP shutdown\n\nConfig:\n```toml\n[general]\nshutdown_timeout = \"60s\"\n```\n\nAcceptance: Clean shutdown waits for in-progress work, timeout prevents hanging, all goroutines tracked","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:00:28.12110888+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T18:00:28.12110888+10:00","labels":["code"],"dependencies":[{"issue_id":"cortex-255.1","depends_on_id":"cortex-255","type":"parent-child","created_at":"2026-02-17T18:00:28.125714686+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-255.2","title":"Implement exponential backoff retry strategy","description":"Replace the simplistic 'always escalate tier' retry with intelligent backoff.\n\nCurrent behavior (health/stuck.go): stuck dispatch → kill → escalate tier → retry immediately.\nProblem: if the task is genuinely impossible, we burn through all tiers quickly.\n\nNew retry strategy (internal/dispatch/retry.go):\n```go\ntype RetryPolicy struct {\n    MaxRetries     int\n    InitialDelay   time.Duration  // delay before first retry\n    BackoffFactor  float64        // multiply delay each retry\n    MaxDelay       time.Duration  // cap on delay\n    EscalateAfter  int            // escalate tier after N same-tier failures\n}\n\n// DefaultPolicy returns sensible defaults\nfunc DefaultPolicy() RetryPolicy {\n    return RetryPolicy{\n        MaxRetries:    3,\n        InitialDelay:  5 * time.Minute,\n        BackoffFactor: 2.0,\n        MaxDelay:      30 * time.Minute,\n        EscalateAfter: 2,  // try same tier twice before escalating\n    }\n}\n\n// NextRetry calculates when and how to retry\nfunc (p RetryPolicy) NextRetry(attempt int, currentTier string) (delay time.Duration, tier string, shouldRetry bool)\n```\n\nStore additions:\n- Add next_retry_at column to dispatches (nullable)\n- Scheduler skips bead if next_retry_at is in the future\n\nIntegration:\n- stuck.go uses RetryPolicy instead of hardcoded escalation\n- Different policies possible per tier or per project (config extension)\n\nAcceptance: Retries back off exponentially, tier escalation delayed, configurable policy","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:00:35.35983923+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T18:00:35.35983923+10:00","labels":["code"],"dependencies":[{"issue_id":"cortex-255.2","depends_on_id":"cortex-255","type":"parent-child","created_at":"2026-02-17T18:00:35.363108233+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-255.3","title":"Add startup config validation","description":"Validate config completeness and correctness before starting the scheduler.\n\nCreate internal/config/validate.go:\n```go\nfunc ValidateRuntime(cfg *Config) []ValidationError\n\ntype ValidationError struct {\n    Field   string\n    Message string\n    Fatal   bool   // if true, cannot start\n}\n```\n\nChecks:\n- State DB parent directory exists and is writable\n- At least one project enabled\n- At least one provider defined per referenced tier\n- BeadsDir exists and contains .beads data for each enabled project\n- Workspace directories exist\n- openclaw binary is in PATH\n- tmux binary is in PATH (if TmuxDispatcher selected)\n- API bind port is available (try listen, close)\n- No circular dependencies in tier definitions\n\nOn validation failure:\n- Fatal errors: log and exit with clear message\n- Warnings: log and continue\n\nRun validation in main.go before starting goroutines.\n\nAcceptance: All checks run on startup, fatal errors prevent start, clear error messages","status":"open","priority":3,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:00:40.710272932+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T18:00:40.710272932+10:00","labels":["code"],"dependencies":[{"issue_id":"cortex-255.3","depends_on_id":"cortex-255","type":"parent-child","created_at":"2026-02-17T18:00:40.71300238+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-255.4","title":"Add SIGUSR1 state dump","description":"On SIGUSR1 signal, dump current state to log for debugging.\n\nChanges to cmd/cortex/main.go:\n- Add SIGUSR1 handler\n\nState dump includes:\n- Current time, uptime\n- Scheduler: paused?, last tick time, next tick time\n- Running dispatches: count, list of (bead, agent, duration, PID/session)\n- Rate limiter: 5h usage/cap, weekly usage/cap, headroom status\n- Per-project: open beads, ready beads, in-progress, blocked\n- Health: gateway status, restarts in last hour\n- Memory: goroutine count, heap alloc (runtime.MemStats)\n\nOutput: structured JSON to log (slog.Info with all fields).\nAlso write to /tmp/cortex-state-dump.json for easy access.\n\nAcceptance: SIGUSR1 produces comprehensive state dump, readable in logs and file","status":"open","priority":3,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:00:45.829668458+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T18:00:45.829668458+10:00","labels":["code"],"dependencies":[{"issue_id":"cortex-255.4","depends_on_id":"cortex-255","type":"parent-child","created_at":"2026-02-17T18:00:45.833747932+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-255.5","title":"Harden single-leader lock to prevent split-brain schedulers","description":"## Summary\nSingle-instance protection is currently brittle: lock file removal and process races can allow multiple schedulers to run concurrently. This creates split-brain dispatch and duplicate work.\n\n## Scope\n- Harden `AcquireFlock`/`ReleaseFlock` semantics to preserve kernel lock ownership correctly across crashes/restarts.\n- Remove lock-file deletion behavior that can invalidate active lock state.\n- Ensure stale file presence alone never blocks startup if lock is not held.\n- Update docs for safe recovery (no manual `rm /tmp/cortex.lock` requirement).\n\n## Hardening\n- Keep PID write as observability only, not a source of truth.\n- Verify behavior when lock file already exists from prior process.\n- Ensure second process fails while first holds lock.\n\n## Tests\n- Add/extend flock tests to cover:\n  - lock acquisition with pre-existing file\n  - exclusivity across two open file handles\n  - release behavior without file deletion side effects\n\n## Acceptance Criteria\n- Two simultaneous Cortex processes cannot both acquire leadership lock.\n- Restart after crash with stale lock file succeeds without manual cleanup.\n- Test coverage added for lock lifecycle and exclusivity.\n","status":"closed","priority":0,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T21:25:59.020559379+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T21:57:31.065095033+10:00","closed_at":"2026-02-17T21:57:31.065095033+10:00","close_reason":"Implemented with hardening changes and automated tests","labels":["code","hardening","test"],"dependencies":[{"issue_id":"cortex-255.5","depends_on_id":"cortex-255","type":"parent-child","created_at":"2026-02-17T21:25:59.023604546+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-255.6","title":"Persist stuck-dispatch retries into pending_retry control path","description":"## Summary\nStuck dispatch handling records retry intent in memory/logs but does not requeue work in persistent state. Result: stuck runs fail permanently instead of entering controlled retry flow.\n\n## Scope\n- Make stuck-handler transitions explicit in DB:\n  - `failed` + `pending_retry` when retry budget remains\n  - permanent `failed` when retry budget exceeded\n- Increment retries consistently for requeued attempts.\n- Keep tier escalation data visible for scheduler retry path.\n\n## Hardening\n- Ensure idempotent transition logic per dispatch ID.\n- Keep stage/status aligned for observability (`failed`, `pending_retry`, terminal states).\n\n## Tests\n- Add health/scheduler tests proving stuck dispatch enters `pending_retry` when allowed.\n- Add test for max-retries terminal behavior.\n\n## Acceptance Criteria\n- Stuck dispatches with retry budget are automatically requeued.\n- Max-retry dispatches stop retrying and remain terminal.\n- Retry path is DB-driven and survives process restarts.\n","status":"closed","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T21:25:59.146607409+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T21:57:31.109885418+10:00","closed_at":"2026-02-17T21:57:31.109885418+10:00","close_reason":"Implemented with hardening changes and automated tests","labels":["code","hardening","health","scheduler","test"],"dependencies":[{"issue_id":"cortex-255.6","depends_on_id":"cortex-255","type":"parent-child","created_at":"2026-02-17T21:25:59.14963895+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-26q","title":"Build burn-in metrics collector","description":"Create a collector that extracts raw metrics data from the store database for burn-in SLO evaluation.\n\n## Goal\nBuild a command-line tool that queries the store database and outputs raw metrics data in JSON format.\n\n## Scope\n- Query dispatches table for failure analysis\n- Query health_events table for critical events\n- Extract intervention data (cancellations, retries)\n- Calculate time-based metrics (uptime, availability)\n- Output structured JSON for downstream processing\n\n## Implementation\nCreate :\n- Accept date range parameters (--start-date, --end-date)  \n- Connect to store database (same connection as main cortex)\n- Execute defined SQL queries from metrics schema\n- Output JSON with raw counts and percentages\n\n## Data to Collect\n```json\n{\n  \"period\": {\n    \"start\": \"2026-02-11T00:00:00Z\",\n    \"end\": \"2026-02-18T00:00:00Z\"\n  },\n  \"dispatches\": {\n    \"total\": 150,\n    \"failed\": 12,\n    \"unknown_exit\": 3,\n    \"session_disappeared\": 2,\n    \"cancelled_manual\": 4,\n    \"retried_manual\": 6\n  },\n  \"health_events\": {\n    \"gateway_critical\": 1,\n    \"dispatch_session_gone\": 2,\n    \"bead_churn_blocked\": 3\n  },\n  \"system\": {\n    \"uptime_seconds\": 604800,\n    \"total_seconds\": 604800\n  }\n}\n```\n\n## Acceptance Criteria\n1) Collector connects to store database using cortex config  \n2) Extracts all data needed for burn-in SLO calculations\n3) Supports date range filtering for flexible reporting\n4) Outputs structured JSON format\n5) Handles missing data gracefully (empty results)\n6) Includes data validation and error handling","status":"open","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:33:32.994133398+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:33:32.994133398+10:00","labels":["collector","data","json","launch"],"dependencies":[{"issue_id":"cortex-26q","depends_on_id":"cortex-zly","type":"blocks","created_at":"2026-02-18T02:34:25.174417063+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-27c","title":"Stale openclaw session locks block all dispatches to agent","description":"When an openclaw agent process crashes or is killed, it leaves a .lock file in ~/.openclaw/agents/{name}/sessions/. All subsequent dispatches to that agent fail with 'session file locked'. Partial fix in place (clearStaleLocks in tmux.go) but needs hardening: lock files from LIVE sessions of a different dispatch also block. Need to either use per-dispatch session IDs or clear+recreate sessions.","notes":"**Review Result: Changes Needed**\n\n**Critical Issue - Session Name Collision Detected**\n\n## Test Failure\nTestSessionName_Uniqueness FAILED: same session name generated twice\nThis defeats the primary purpose of preventing session conflicts.\n\n## Architecture Assessment - Generally Good\n\n**Excellent Design Improvements:**\n- Per-session directories for resource isolation\n- Conservative stale lock cleanup (only clears dead PIDs)\n- Retry logic with fallback cleanup\n- Proper resource lifecycle management\n- Session isolation testing passes\n\n## Critical Flaw - Insufficient Uniqueness\n\n**SessionName Generation Issues:**\n- Uses millisecond timestamp (reduced precision)\n- Only 2-byte random component (65k possibilities)\n- Same PID for all rapid dispatches in single process\n- Result: High collision probability under load\n\n## Required Fixes\n\n**1. Stronger Uniqueness:**\n- Use full nanosecond precision timestamps\n- Increase random bytes to 4+ bytes\n- Consider atomic sequence counter per process\n\n**2. Collision Detection:**\n- Check if session name exists before use\n- Regenerate with new random component on collision\n\n**3. Test Reliability:**\n- TestSessionName_Uniqueness must pass 100% reliably\n- Consider concurrent load testing\n\n## Acceptance Criteria Status\n- Per-session resource isolation: IMPLEMENTED\n- Conservative lock cleanup: IMPLEMENTED  \n- Collision prevention: FAILS - critical issue\n- Resource lifecycle: IMPLEMENTED\n- Retry mechanism: IMPLEMENTED\n\n## Action Required\nFix session name uniqueness to ensure zero collisions. Core architecture is sound but uniqueness is critical for P0 reliability.\n\nTransitioned back to stage:coding for uniqueness fixes.","status":"closed","priority":0,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T21:09:32.669283096+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T21:25:44.43159755+10:00","closed_at":"2026-02-17T21:25:44.43159755+10:00","close_reason":"Closed","labels":["stage:coding"]}
{"id":"cortex-298","title":"Auto: churn guard blocked bead cortex-evu.2 (6 dispatches/1h0m0s)","description":"Bead `cortex-evu.2` in project `cortex` exceeded churn threshold (6 dispatches in 1h0m0s) and was blocked from further overnight dispatch.\n\nPlease investigate root cause, split work into smaller tasks if needed, and add hardening/tests before re-enabling.\n\nBead title: Add scheduler RunTick end-to-end test\nBead type: task","status":"open","priority":1,"issue_type":"bug","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:00:14.78036953+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:01:08.296914429+10:00","dependencies":[{"issue_id":"cortex-298","depends_on_id":"cortex-evu.2","type":"discovered-from","created_at":"2026-02-18T02:00:14.783175723+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-2cv","title":"Auto: churn guard blocked bead cortex-c4j.3 (6 dispatches/1h0m0s)","description":"Bead `cortex-c4j.3` in project `cortex` exceeded churn threshold (6 dispatches in 1h0m0s) and was blocked from further overnight dispatch.\n\nPlease investigate root cause, split work into smaller tasks if needed, and add hardening/tests before re-enabling.\n\nBead title: Publish operational runbook set for launch operations\nBead type: task","status":"closed","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:28:08.822157751+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:43:25.968016555+10:00","closed_at":"2026-02-18T02:43:25.968016555+10:00","close_reason":"Duplicate churn-guard incident for cortex-c4j.3; superseded by cortex-ztu resolution (scheduler dedupe hardening + runbook task decomposition).","dependencies":[{"issue_id":"cortex-2cv","depends_on_id":"cortex-c4j.3","type":"discovered-from","created_at":"2026-02-18T02:28:08.942974222+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-2cx","title":"Auto: break down epic cortex-c4j into executable bug/task beads","description":"Epic `cortex-c4j` is still open in project `cortex`.\n\nPolicy: epics should not be assigned directly to coders. Break this epic into concrete `bug`/`task` beads with acceptance criteria so overnight automation can execute them.\n\nEpic title: Launch readiness go/no-go execution plan","status":"closed","priority":1,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T03:05:10.52856492+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:23:42.663370825+10:00","closed_at":"2026-02-18T04:23:42.663370825+10:00","close_reason":"Duplicate breakdown task - epic was already decomposed and completed by cortex-bjc","dependencies":[{"issue_id":"cortex-2cx","depends_on_id":"cortex-c4j","type":"discovered-from","created_at":"2026-02-18T03:05:10.531758528+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-2px","title":"Git workflow: branches, PRs, and review","description":"Agents push directly to whatever branch they're on. No feature branches, no PRs, no diff visibility. The reviewer agent can't actually review a PR because there isn't one. No rollback mechanism if an agent breaks something.\n\nKey deliverables:\n- Feature branch per bead (git checkout -b feat/{bead-id})\n- PR creation on stage completion (gh pr create)\n- Reviewer agent reviews actual PR diffs (structured code review)\n- Merge gating: only merge after reviewer approves\n- Rollback: revert if post-merge checks fail\n- Diff capture: store what changed per dispatch for audit trail","status":"closed","priority":1,"issue_type":"epic","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:57:33.200443457+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:26:35.340112393+10:00","closed_at":"2026-02-18T04:26:35.340112393+10:00","close_reason":"Epic completed - broken down into 5 main tasks with 8 concrete subtasks"}
{"id":"cortex-2px.1","title":"Implement feature branch creation per bead","description":"Automatically create a feature branch for each bead before dispatching an agent.\n\nCreate internal/git/branch.go:\n```go\n// CreateFeatureBranch creates and checks out a branch for a bead\n// Branch name: feat/{bead-id} (e.g. feat/cortex-abc)\nfunc CreateFeatureBranch(workspace, beadID, baseBranch string) error\n\n// GetCurrentBranch returns the current branch name\nfunc GetCurrentBranch(workspace string) (string, error)\n\n// BranchExists checks if a branch already exists\nfunc BranchExists(workspace, branch string) (bool, error)\n\n// EnsureFeatureBranch creates branch if not exists, checks out if exists\nfunc EnsureFeatureBranch(workspace, beadID string) error\n```\n\nConfig:\n```toml\n[projects.hg-website]\nbase_branch = \"main\"          # branch to create features from\nbranch_prefix = \"feat/\"        # prefix for feature branches\nuse_branches = true            # enable branch workflow (default false for backward compat)\n```\n\nScheduler integration:\n- Before dispatching, call EnsureFeatureBranch if use_branches=true\n- Agent works on the feature branch, not main\n- Update prompt to NOT include 'git push' — PR creation handles that\n\nAcceptance: Feature branches created per bead, agent works on branch, backward compatible when use_branches=false","notes":"**Review Result: APPROVED**\n\n**Excellent Implementation - Strong Architecture**:\n\n**Core Functionality**:\n- internal/git/branch.go: All required functions fully implemented\n- Config Integration: Project struct extended with required fields  \n- Scheduler Integration: Clean integration in RunTick\n- Prompt Updates: BuildPromptWithRoleBranches implemented\n\n**Test Coverage**:\n- Git branch tests: Comprehensive test suite, all tests pass\n- Integration: Scheduler tests continue to pass\n- Build: Fixed API constructor call in main.go during review\n\n**Architecture Quality**:\n- Clean separation between git operations and scheduler\n- Proper use of workspace paths and config expansion  \n- Good error handling and logging throughout\n- Interface-driven design maintains modularity\n\n**Acceptance Criteria Met**:\n- Feature branches created per bead  \n- Agent works on feature branch, not main\n- Backward compatible when use_branches=false\n- Prompt updated to NOT include git push for branch workflow\n\n**Overall Assessment**: Excellent implementation with comprehensive testing, clean integration, and proper backward compatibility. Ready for QA testing.\n\nApproved for stage:qa","status":"closed","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:59:34.313610422+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T20:57:33.249739042+10:00","closed_at":"2026-02-17T20:57:33.249739042+10:00","close_reason":"Closed","labels":["stage:qa"],"dependencies":[{"issue_id":"cortex-2px.1","depends_on_id":"cortex-2px","type":"parent-child","created_at":"2026-02-17T17:59:34.318199416+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-2px.2","title":"Implement PR creation on stage completion","description":"Automatically create a GitHub PR when the coder agent completes its work.\n\nCreate internal/git/pr.go:\n```go\n// CreatePR creates a pull request for a feature branch\nfunc CreatePR(workspace, branch, baseBranch, title, body string) (prURL string, prNumber int, err error)\n// Uses: gh pr create --head {branch} --base {baseBranch} --title {title} --body {body}\n\n// GetPRStatus checks if a PR exists and its status\nfunc GetPRStatus(workspace, branch string) (*PRStatus, error)\n// Uses: gh pr view {branch} --json state,reviewDecision,number,url\n\ntype PRStatus struct {\n    Number         int\n    URL            string\n    State          string   // OPEN, CLOSED, MERGED\n    ReviewDecision string   // APPROVED, CHANGES_REQUESTED, REVIEW_REQUIRED\n}\n```\n\nTrigger: when coder agent completes (stage:coding → stage:review), create PR.\nPR body includes: bead title, description, acceptance criteria, link to bead.\nStore PR URL and number in dispatches or new pr_tracking table.\n\nAcceptance: PR auto-created after coding stage, PR info stored, gh CLI used","status":"closed","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:59:44.96383625+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T21:20:04.805750284+10:00","closed_at":"2026-02-17T21:20:04.805750284+10:00","close_reason":"Closed","labels":["code"],"dependencies":[{"issue_id":"cortex-2px.2","depends_on_id":"cortex-2px","type":"parent-child","created_at":"2026-02-17T17:59:44.967010247+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-2px.2","depends_on_id":"cortex-2px.1","type":"blocks","created_at":"2026-02-17T18:00:15.892878007+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-2px.3","title":"Reviewer agent reviews actual PR diffs","description":"Update the reviewer agent's prompt to review the actual PR diff instead of just the bead description.\n\n**What is code:** Fetching PR diff, adding to prompt.\n**What is LLM:** The actual code review.\n\nChanges to prompt building:\n- When role=reviewer and a PR exists, fetch diff: gh pr diff {number}\n- Include diff in reviewer prompt: 'Review the following code changes...'\n- Include PR conversation if any comments exist\n\nCreate internal/git/diff.go:\n```go\n// GetPRDiff returns the diff for a PR\nfunc GetPRDiff(workspace string, prNumber int) (string, error)\n// Uses: gh pr diff {number}\n\n// Truncate diff if \u003e50KB (too large for prompt)\nfunc TruncateDiff(diff string, maxBytes int) string\n```\n\nReviewer prompt update (internal/scheduler/prompt.go):\n- Add PR diff section to reviewer stage instructions\n- Include file list and stats\n- Ask reviewer to: approve (gh pr review --approve) or request changes (gh pr review --request-changes)\n\nAcceptance: Reviewer sees actual diff, reviews code not just description, can approve/request changes","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:59:55.105698777+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T21:29:43.909599275+10:00","closed_at":"2026-02-17T21:29:43.909599275+10:00","close_reason":"Closed","dependencies":[{"issue_id":"cortex-2px.3","depends_on_id":"cortex-2px","type":"parent-child","created_at":"2026-02-17T17:59:55.109299999+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-2px.3","depends_on_id":"cortex-2px.2","type":"blocks","created_at":"2026-02-17T18:00:21.861504922+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-2px.4","title":"Implement merge gating and post-merge validation","description":"Only merge PRs after reviewer approves. Run post-merge validation. Rollback if checks fail.\n\nCreate internal/git/merge.go:\n```go\n// MergePR merges an approved PR\nfunc MergePR(workspace string, prNumber int, method string) error\n// Uses: gh pr merge {number} --squash (or --merge)\n// method from config: squash, merge, rebase\n\n// RevertMerge reverts the last merge commit\nfunc RevertMerge(workspace, commitSHA string) error\n// Uses: git revert {sha} --no-edit \u0026\u0026 git push\n\n// RunPostMergeChecks runs DoD checks after merge\nfunc RunPostMergeChecks(workspace string, checks []string) (*DoDResult, error)\n```\n\nWorkflow:\n1. Reviewer approves PR → scheduler detects approval on next tick\n2. Merge PR (squash by default)\n3. Run post-merge validation (DoD checks on main branch)\n4. If checks pass → close bead\n5. If checks fail → revert merge, reopen bead, notify scrum master\n\nConfig:\n```toml\n[projects.hg-website]\nmerge_method = \"squash\"\npost_merge_checks = [\"go test ./...\", \"go vet ./...\"]\nauto_revert_on_failure = true\n```\n\nAcceptance: PRs only merge after approval, post-merge checks run, auto-revert on failure","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:00:05.811713+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T18:00:05.811713+10:00","labels":["code"],"dependencies":[{"issue_id":"cortex-2px.4","depends_on_id":"cortex-2px","type":"parent-child","created_at":"2026-02-17T18:00:05.814776129+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-2px.4","depends_on_id":"cortex-2px.3","type":"blocks","created_at":"2026-02-17T18:00:25.130866488+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-2px.4.1","title":"Create merge.go with PR merge and revert functions","description":"Implement core PR merge and revert functions in internal/git/merge.go.\n\nFiles to create/modify:\n- internal/git/merge.go (new)\n- internal/git/merge_test.go (new)\n\nAcceptance criteria:\n- MergePR(workspace, prNumber, method) function implemented using gh CLI\n- RevertMerge(workspace, commitSHA) function implemented using git revert\n- Support for merge methods: squash, merge, rebase\n- Proper error handling and validation\n- Unit tests with 90%+ coverage\n- Mock gh CLI and git commands for testing\n\nFunction signatures:\n- MergePR(workspace string, prNumber int, method string) error\n- RevertMerge(workspace, commitSHA string) error\n\nImplementation details:\n- Use 'gh pr merge {number} --{method}' for merging\n- Use 'git revert {sha} --no-edit \u0026\u0026 git push' for reverting\n- Validate merge method parameter\n- Return descriptive errors for all failure modes","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:05:18.6401264+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:05:18.6401264+10:00","dependencies":[{"issue_id":"cortex-2px.4.1","depends_on_id":"cortex-2px.4","type":"parent-child","created_at":"2026-02-18T04:05:18.643586987+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-2px.4.2","title":"Add post-merge DoD validation system","description":"Implement post-merge validation system that runs DoD checks after PR merge.\n\nFiles to create/modify:\n- internal/git/merge.go (extend)\n- internal/git/validation.go (new)\n- internal/git/validation_test.go (new)\n\nAcceptance criteria:\n- RunPostMergeChecks(workspace, checks) function implemented\n- Executes arbitrary shell commands as validation checks\n- Returns structured validation results (pass/fail per check)\n- Timeout handling for long-running checks\n- Capture stdout/stderr for debugging failed checks\n- Unit tests with mock command execution\n\nFunction signature:\n- RunPostMergeChecks(workspace string, checks []string) (*DoDResult, error)\n\nDoDResult struct:\n- OverallPass bool\n- CheckResults []CheckResult (command, passed, output, error)\n- Duration time.Duration\n\nImplementation details:\n- Run each check command in the workspace directory\n- Stop on first failure or run all checks (configurable)\n- 5-minute timeout per check by default\n- Log check execution and results","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:05:25.95266668+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:05:25.95266668+10:00","dependencies":[{"issue_id":"cortex-2px.4.2","depends_on_id":"cortex-2px.4","type":"parent-child","created_at":"2026-02-18T04:05:25.955896566+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-2px.4.2","depends_on_id":"cortex-2px.4.1","type":"blocks","created_at":"2026-02-18T04:05:25.964398047+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-2px.4.3","title":"Add merge workflow config fields to project configuration","description":"Extend project configuration to support merge workflow settings.\n\nFiles to create/modify:\n- internal/config/config.go (extend Project struct)\n- Config validation and TOML parsing\n\nAcceptance criteria:\n- Project struct has MergeMethod, PostMergeChecks, AutoRevertOnFailure fields\n- TOML parsing supports merge_method, post_merge_checks, auto_revert_on_failure keys\n- Default values: merge_method=\"squash\", auto_revert_on_failure=true\n- Config validation: merge_method must be squash/merge/rebase\n- Backward compatible with existing configs\n\nNew Project fields:\n- MergeMethod string (squash, merge, rebase)\n- PostMergeChecks []string (shell commands to run)\n- AutoRevertOnFailure bool\n\nExample TOML:\nmerge_method = \"squash\"\npost_merge_checks = [\"go test ./...\", \"go vet ./...\"]\nauto_revert_on_failure = true","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:05:33.811792079+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:05:33.811792079+10:00","dependencies":[{"issue_id":"cortex-2px.4.3","depends_on_id":"cortex-2px.4","type":"parent-child","created_at":"2026-02-18T04:05:33.814522973+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-2px.4.4","title":"Integrate merge gating into scheduler workflow","description":"Integrate PR merge gating and post-merge validation into the main scheduler workflow.\n\nFiles to create/modify:\n- internal/scheduler/scheduler.go (add merge workflow logic)\n- internal/scheduler/scheduler_test.go (test merge workflow)\n\nAcceptance criteria:\n- Scheduler detects when PRs are approved and ready for merge\n- Only merge PRs that have approved review status\n- Run post-merge checks automatically after successful merge\n- Auto-revert merge if post-merge checks fail (when configured)\n- Update bead status appropriately (close on success, reopen on failure)\n- Notify scrum master of auto-reverts\n- Integration tests verify complete merge workflow\n\nWorkflow logic:\n1. Check PR status for beads in review stage\n2. If approved → merge using configured method\n3. Run post-merge validation checks\n4. If checks pass → close bead as completed  \n5. If checks fail and auto_revert_on_failure → revert merge, reopen bead\n6. Log all merge workflow actions for audit\n\nImplementation details:\n- Add merge workflow phase to scheduler RunTick\n- Use existing PR tracking to identify ready PRs\n- Handle merge conflicts and other git errors gracefully\n- Rate limit merge operations to avoid overwhelming CI systems","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:05:43.241073976+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:05:43.241073976+10:00","dependencies":[{"issue_id":"cortex-2px.4.4","depends_on_id":"cortex-2px.4","type":"parent-child","created_at":"2026-02-18T04:05:43.244387266+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-2px.4.4","depends_on_id":"cortex-2px.4.1","type":"blocks","created_at":"2026-02-18T04:05:43.254931408+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-2px.4.4","depends_on_id":"cortex-2px.4.2","type":"blocks","created_at":"2026-02-18T04:05:43.266281553+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-2px.4.4","depends_on_id":"cortex-2px.4.3","type":"blocks","created_at":"2026-02-18T04:05:43.276655036+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-2px.5","title":"Store git diffs and change audit trail","description":"Capture and store what each dispatch changed for audit and analysis.\n\nDB additions:\n```sql\nCREATE TABLE dispatch_changes (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    dispatch_id INTEGER NOT NULL REFERENCES dispatches(id),\n    files_changed INTEGER,\n    insertions INTEGER,\n    deletions INTEGER,\n    diff_stat TEXT,      -- git diff --stat output\n    commit_shas TEXT,    -- JSON array of commit SHAs\n    pr_number INTEGER,\n    pr_url TEXT,\n    captured_at TEXT NOT NULL\n);\n```\n\nCapture trigger: on dispatch completion, run in workspace:\n- git log --oneline {base}..HEAD → commit SHAs\n- git diff --stat {base}..HEAD → change stats\n- Store in dispatch_changes\n\nAPI: GET /dispatches/{id}/changes — returns diff stats, commit list, PR info.\n\nUse in retro: 'agent X changed 500 lines across 12 files for a trivial bead — possible over-engineering'\n\nAcceptance: Changes captured per dispatch, stored, queryable via API","status":"open","priority":3,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:00:11.530799638+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T18:00:11.530799638+10:00","labels":["code"],"dependencies":[{"issue_id":"cortex-2px.5","depends_on_id":"cortex-2px","type":"parent-child","created_at":"2026-02-17T18:00:11.541531793+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-2px.5","depends_on_id":"cortex-2px.1","type":"blocks","created_at":"2026-02-17T18:00:30.548136789+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-2px.5.1","title":"Add dispatch_changes database schema and migrations","description":"Create database schema for tracking git changes per dispatch with proper migrations.\n\nFiles to create/modify:\n- internal/store/migrations/ (new migration file)\n- internal/store/store.go (extend with new table operations)\n\nAcceptance criteria:\n- dispatch_changes table created with all required columns\n- Proper foreign key relationship to dispatches table\n- Database migration script that works on existing databases\n- Schema documented in comments\n- Migration tested with empty and populated databases\n\nTable schema:\n\n\nMigration details:\n- Add CREATE TABLE IF NOT EXISTS for safety\n- Include appropriate indexes for query performance\n- Handle SQLite-specific constraints and types","status":"open","priority":3,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:05:52.396350879+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:05:52.396350879+10:00","dependencies":[{"issue_id":"cortex-2px.5.1","depends_on_id":"cortex-2px.5","type":"parent-child","created_at":"2026-02-18T04:05:52.399290853+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-2px.5.2","title":"Implement git diff capture and storage functions","description":"Create functions to capture git diff statistics and store them in the database.\n\nFiles to create/modify:\n- internal/git/changes.go (new)\n- internal/git/changes_test.go (new)\n- internal/store/store.go (extend with change tracking methods)\n\nAcceptance criteria:\n- CaptureDispatchChanges(workspace, dispatchID, baseBranch) function implemented\n- Captures commit SHAs, diff stats, file counts, insertions/deletions\n- Stores data in dispatch_changes table\n- Handles edge cases (no commits, large diffs, binary files)\n- Unit tests with mock git commands and database operations\n- Performance optimized for large repositories\n\nFunction signatures:\n- CaptureDispatchChanges(workspace string, dispatchID int, baseBranch string) error\n- GetDispatchChanges(dispatchID int) (*DispatchChanges, error)\n\nDispatchChanges struct:\n- DispatchID, FilesChanged, Insertions, Deletions int\n- DiffStat string, CommitSHAs []string\n- PRNumber int, PRURL string, CapturedAt time.Time\n\nImplementation details:\n- Use 'git log --oneline base..HEAD' for commit SHAs\n- Use 'git diff --stat base..HEAD' for change statistics\n- Parse git output to extract file counts and line changes\n- Store commit SHAs as JSON array\n- Handle empty diffs gracefully","status":"open","priority":3,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:06:00.454614399+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:06:00.454614399+10:00","dependencies":[{"issue_id":"cortex-2px.5.2","depends_on_id":"cortex-2px.5","type":"parent-child","created_at":"2026-02-18T04:06:00.460710541+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-2px.5.2","depends_on_id":"cortex-2px.5.1","type":"blocks","created_at":"2026-02-18T04:06:00.475967685+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-2px.5.3","title":"Add API endpoint for dispatch change queries","description":"Create API endpoint to query git change data for dispatches and analysis.\n\nFiles to create/modify:\n- internal/api/changes.go (new)\n- internal/api/changes_test.go (new)\n- internal/api/router.go (add changes endpoints)\n\nAcceptance criteria:\n- GET /dispatches/{id}/changes returns change details for specific dispatch\n- GET /changes API supports filtering by project, date range, file patterns\n- Response includes commit links, diff statistics, PR information\n- Proper error handling and HTTP status codes\n- Unit tests for endpoint logic and filtering\n- API documentation in comments\n\nEndpoints:\n- GET /dispatches/{id}/changes - Single dispatch changes\n- GET /changes?project=X\u0026since=Y\u0026until=Z - Filtered change history\n\nResponse schema includes:\n- Dispatch metadata (ID, bead, project, agent)\n- Change statistics (files, insertions, deletions)\n- Commit information (SHAs, messages, timestamps)\n- PR details (number, URL) if applicable\n- Diff summary and file list\n\nImplementation details:\n- Support pagination for large result sets\n- Include links to GitHub commits and PRs when available\n- Filter sensitive information (no actual diff content in API)\n- Cache frequently requested data for performance","status":"open","priority":3,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:06:10.014165005+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:06:10.014165005+10:00","dependencies":[{"issue_id":"cortex-2px.5.3","depends_on_id":"cortex-2px.5","type":"parent-child","created_at":"2026-02-18T04:06:10.0167831+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-2px.5.3","depends_on_id":"cortex-2px.5.2","type":"blocks","created_at":"2026-02-18T04:06:10.028701365+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-2px.5.4","title":"Integrate change capture into dispatch completion workflow","description":"Integrate git change capture into the main dispatch completion workflow.\n\nFiles to create/modify:\n- internal/scheduler/scheduler.go (add change capture on dispatch completion)\n- internal/scheduler/scheduler_test.go (test change capture integration)\n\nAcceptance criteria:\n- Changes captured automatically when dispatch completes\n- Capture triggered for both successful and failed dispatches\n- Proper error handling - change capture failures don't break dispatch flow\n- Performance impact minimized (async capture if possible)\n- Integration tests verify change data is captured\n- Capture works with both branch and direct-push workflows\n\nIntegration points:\n- After dispatch agent completes work\n- Before bead transitions to next stage\n- Capture base branch from git/PR context\n- Store PR number and URL if PR workflow is used\n\nImplementation details:\n- Add change capture step to scheduler RunTick\n- Use goroutine for async capture to avoid blocking\n- Log capture errors but don't fail dispatch\n- Handle race conditions with concurrent dispatches\n- Skip capture if git operations fail (workspace issues)","status":"open","priority":3,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:06:18.235270576+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:06:18.235270576+10:00","dependencies":[{"issue_id":"cortex-2px.5.4","depends_on_id":"cortex-2px.5","type":"parent-child","created_at":"2026-02-18T04:06:18.242202788+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-2px.5.4","depends_on_id":"cortex-2px.5.2","type":"blocks","created_at":"2026-02-18T04:06:18.254407949+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-2zc","title":"Add basic scrum master command handling","description":"Handle basic inbound commands from Matrix for project management. Simplified version of cortex-a4s.6.\n\n## Goal  \nAllow scrum master to respond to simple project management commands from Matrix.\n\n## Scope\nAdd command parsing to scrum master agent prompts when messages are received via Matrix polling.\n\n## Supported Commands\n1. **status** - Show current project status (running beads, recent completions)\n2. **priority \u003cbead-id\u003e \u003cp0-p4\u003e** - Change bead priority  \n3. **cancel \u003cdispatch-id\u003e** - Cancel running dispatch\n4. **create task \"\u003ctitle\u003e\" \"\u003cdescription\u003e\"** - Create new task bead\n\n## Implementation\n- Extend scrum master ROLE.md with command handling instructions\n- Add command templates to scrum master system prompt\n- Commands execute via bd CLI or direct store/scheduler calls\n- Response sent back to Matrix room where command originated\n\n## Command Response Format\n- status: Brief project summary with key metrics\n- priority: Confirmation of priority change\n- cancel: Confirmation of cancellation or error message  \n- create: New bead ID and confirmation\n\n## Error Handling\n- Invalid commands get helpful usage message\n- Missing permissions result in polite denial\n- Malformed arguments get specific correction guidance\n\n## Acceptance Criteria\n1) Scrum master recognizes and parses the four basic commands\n2) Commands execute appropriate actions (priority changes, cancellations, etc.)\n3) Responses are sent back to the originating Matrix room\n4) Invalid commands receive helpful error messages\n5) Commands work with existing bd CLI infrastructure  \n6) Integration tests cover command parsing and execution\n\n## Dependencies\n- Requires cortex-g9r (Matrix polling) to receive commands\n- Requires cortex-a4s.7 (updated ROLE.md) for command instructions","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:38:44.427970391+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:38:44.427970391+10:00","labels":["commands","inbound","matrix","scrum"],"dependencies":[{"issue_id":"cortex-2zc","depends_on_id":"cortex-g9r","type":"blocks","created_at":"2026-02-18T02:39:13.052125407+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-32o","title":"Auto: churn guard blocked bead cortex-y6s (6 dispatches/1h0m0s)","description":"Bead `cortex-y6s` in project `cortex` exceeded churn threshold (6 dispatches in 1h0m0s) and was blocked from further overnight dispatch.\n\nPlease investigate root cause, split work into smaller tasks if needed, and add hardening/tests before re-enabling.\n\nBead title: Auto: break down epic cortex-46d into executable bug/task beads\nBead type: task","status":"closed","priority":1,"issue_type":"bug","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:16:25.10871912+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:32:58.739257759+10:00","closed_at":"2026-02-18T04:32:58.739257759+10:00","close_reason":"Fixed scheduler reconciliation for auto epic-breakdown tasks: it now auto-closes stage:qa breakdown tasks once target epic already has executable child work (or is closed), preventing redispatch churn on completed breakdowns; added regression tests in internal/scheduler/churn_guard_test.go covering QA+children auto-close and non-QA/no-child non-close; verified with go test ./internal/scheduler and go test ./...","dependencies":[{"issue_id":"cortex-32o","depends_on_id":"cortex-y6s","type":"discovered-from","created_at":"2026-02-18T04:16:25.111937705+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-34e","title":"Auto: break down epic cortex-a6p into executable bug/task beads","description":"Epic `cortex-a6p` is still open in project `cortex`.\n\nPolicy: epics should not be assigned directly to coders. Break this epic into concrete `bug`/`task` beads with acceptance criteria so overnight automation can execute them.\n\nEpic title: Cost tracking and budget management","status":"closed","priority":1,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T03:05:11.428086726+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:12:13.420221448+10:00","closed_at":"2026-02-18T04:12:13.420221448+10:00","close_reason":"Work completed successfully - epic cortex-a6p was broken down into 9 executable tasks and closed. All deliverables achieved: cortex-a6p.3.1-3.4 (cost budgeting) and cortex-a6p.4.1-4.5 (API/retro integration) created with detailed acceptance criteria.","labels":["stage:review"],"dependencies":[{"issue_id":"cortex-34e","depends_on_id":"cortex-a6p","type":"discovered-from","created_at":"2026-02-18T03:05:11.43282668+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-37g","title":"Align dispatch cancel/retry API behavior with runtime control","description":"handleDispatchCancel only updates DB state and does not terminate tmux/session/process. handleDispatchRetry marks pending_retry but scheduler lacks explicit retry consumption path. Add runtime effect: cancel should stop execution, release resources, and update state consistently; retry should actively requeue for re-execution and respect backoff policies.","notes":"**Review Result: APPROVED ✅**\n\n**Excellent Implementation - All Previous Issues Addressed**\n\n## ✅ CANCEL Functionality - REMAINS COMPLETE\n- handleDispatchCancel properly calls scheduler.CancelDispatch\n- Terminates tmux sessions via dispatch.KillSession  \n- Kills processes via dispatcher.Kill\n- Updates DB status to cancelled with proper stage tracking\n- Comprehensive error handling and logging\n- ✅ API tests pass (TestHandleDispatchCancel)\n\n## ✅ RETRY Functionality - NOW FULLY IMPLEMENTED\n\n**Previous Issue: Missing scheduler consumption logic**  \n**✅ RESOLVED**: Complete processPendingRetries implementation\n\n### 1. Scheduler Integration ✅ COMPLETE:\n- RunTick now calls s.processPendingRetries(ctx) \n- Retrieves pending_retry dispatches via GetPendingRetryDispatches\n- Processes all retries in each tick cycle\n\n### 2. Backoff Policy Integration ✅ COMPLETE:\n- Uses dispatch.ShouldRetry with configured delays\n- Respects RetryBackoffBase and RetryMaxDelay from config\n- Exponential backoff with proper jitter via BackoffDelay\n- Honors MaxRetries limit with permanent failure handling\n\n### 3. Runtime Re-execution ✅ COMPLETE:\n- Creates new dispatch via dispatcher.Dispatch\n- Records new dispatch in database with proper linking\n- Updates original dispatch status to retried\n- Handles feature branch creation for retry\n- Proper agent availability and project validation checks\n\n### 4. Configuration Support ✅ COMPLETE:\n- Added RetryBackoffBase (default: 2m) and RetryMaxDelay (default: 30m)\n- Proper defaults in Load function\n- Full TOML config support\n\n## ✅ Testing Status\n- ✅ All scheduler tests pass\n- ✅ API retry tests pass (TestHandleDispatchRetry)  \n- ✅ API cancel tests pass (TestHandleDispatchCancel)\n- ✅ Backoff logic extensively tested (backoff_test.go)\n- ✅ Code compiles successfully\n\n## Acceptance Criteria Assessment\n\n**✅ Cancel stops execution, releases resources, updates state consistently**: FULLY IMPLEMENTED\n- Runtime termination of tmux sessions and processes\n- Consistent database state updates  \n- Proper error handling and logging\n\n**✅ Retry actively requeues for re-execution**: FULLY IMPLEMENTED  \n- Scheduler processes pending_retry dispatches every tick\n- Creates new dispatches with proper state management\n- Handles all edge cases (agent busy, project disabled, max retries)\n\n**✅ Backoff policies respected**: FULLY IMPLEMENTED\n- Configurable exponential backoff with jitter\n- Proper time-based retry gating via ShouldRetry\n- Max retry enforcement with permanent failure handling\n\n## Architecture Quality\n- Clean separation between API layer and scheduler logic  \n- Proper integration with existing dispatch system\n- Comprehensive error handling and observability\n- Follows established patterns and conventions\n\n**Outstanding implementation** - addresses all previous review concerns with robust, well-architected solution.\n\n**Ready for QA testing** ✅\n\nApproved for stage:qa","status":"closed","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T20:48:28.852070094+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T21:22:40.6970552+10:00","closed_at":"2026-02-17T21:22:40.6970552+10:00","close_reason":"Closed","labels":["stage:qa"]}
{"id":"cortex-3bf","title":"Implement SLO computation engine","description":"Build computation engine that transforms raw metrics into SLO scores and pass/fail evaluations.\n\n## Goal  \nCreate a tool that takes raw metrics JSON and computes SLO scores against defined thresholds.\n\n## Scope\n- Parse raw metrics JSON from collector\n- Apply SLO calculation formulas  \n- Compare against defined thresholds\n- Generate pass/fail results for each metric\n- Output scored results in structured format\n\n## Implementation\nCreate :\n- Accept raw metrics JSON as input\n- Load SLO thresholds from config file\n- Calculate percentages and rates per metric definitions\n- Evaluate pass/fail against thresholds\n- Output scored JSON\n\n## Input/Output Example\n**Input** (from collector):\n```json\n{\n  \"dispatches\": {\"total\": 150, \"unknown_exit\": 3, \"session_disappeared\": 2},\n  \"health_events\": {\"gateway_critical\": 1}\n}\n```\n\n**Output** (scored):\n```json\n{\n  \"period\": \"2026-02-11 to 2026-02-18\",\n  \"overall_pass\": false,\n  \"metrics\": {\n    \"unknown_disappeared_rate\": {\n      \"value\": 3.33,\n      \"threshold\": 2.0,  \n      \"pass\": false,\n      \"unit\": \"percent\"\n    },\n    \"critical_events\": {\n      \"value\": 1,\n      \"threshold\": 5,\n      \"pass\": true, \n      \"unit\": \"count\"\n    }\n  }\n}\n```\n\n## Acceptance Criteria\n1) Computes all defined SLO metrics correctly per schema\n2) Loads thresholds from configuration file  \n3) Evaluates pass/fail for each metric\n4) Determines overall pass/fail (all metrics must pass)\n5) Outputs structured JSON with scores and evaluation\n6) Handles edge cases (zero dispatches, missing data)","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:33:43.141262125+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:33:43.141262125+10:00","labels":["computation","launch","scoring","slo"],"dependencies":[{"issue_id":"cortex-3bf","depends_on_id":"cortex-zly","type":"blocks","created_at":"2026-02-18T02:34:28.238109823+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-3q5","title":"Auto: churn guard blocked bead cortex-46d.7 (8 dispatches/1h0m0s)","description":"Bead `cortex-46d.7` in project `cortex` exceeded churn threshold (8 dispatches in 1h0m0s) and was blocked from further overnight dispatch.\n\nPlease investigate root cause, split work into smaller tasks if needed, and add hardening/tests before re-enabling.\n\nBead title: Align runtime behavior with dispatch routing and CLI config\nBead type: task","status":"in_progress","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:20:13.968537668+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:35:18.393028025+10:00","labels":["stage:review"],"dependencies":[{"issue_id":"cortex-3q5","depends_on_id":"cortex-46d.7","type":"discovered-from","created_at":"2026-02-18T02:20:14.016501321+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-3zi","title":"Auto: churn guard blocked bead cortex-46d.7 (8 dispatches/1h0m0s)","description":"Bead `cortex-46d.7` in project `cortex` exceeded churn threshold (8 dispatches in 1h0m0s) and was blocked from further overnight dispatch.\n\nPlease investigate root cause, split work into smaller tasks if needed, and add hardening/tests before re-enabling.\n\nBead title: Align runtime behavior with dispatch routing and CLI config\nBead type: task","status":"open","priority":1,"issue_type":"bug","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:00:13.798259978+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:03:07.104200165+10:00","dependencies":[{"issue_id":"cortex-3zi","depends_on_id":"cortex-46d.7","type":"discovered-from","created_at":"2026-02-18T02:00:13.801074326+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-46d","title":"Self-healing control-loop hardening","description":"Harden Cortex orchestration for self-healing and failure containment. Focus on correctness of dispatch lifecycle, health loop ownership, gateway recovery semantics, dependency resolution, and adaptive learning integration. This epic captures concrete issues found in architecture/code review and drives them to implementation-ready specs.","acceptance_criteria":"1) All child tasks are spec'd with explicit invariants and failure-mode tests. 2) Critical failure paths (dispatch persistence, gateway restart logic, zombie/stuck handling) have deterministic behavior. 3) Observability is sufficient to diagnose failures within one run.","status":"closed","priority":1,"issue_type":"epic","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T22:12:00.833875618+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:21:32.027520592+10:00","closed_at":"2026-02-18T04:21:32.027520592+10:00","close_reason":"Epic completed - broken down into 13 executable tasks"}
{"id":"cortex-46d.1","title":"Fix gateway inactive detection and truthful restart events","description":"Health monitor currently treats systemctl is-active non-zero as a hard error and may skip restart flow when the unit is simply inactive. It also records gateway_restart even when restart attempts fail. This weakens self-healing and pollutes health telemetry.","design":"## Goal\nMake gateway recovery deterministic and health telemetry truthful.\n\n## Problem\nCurrent health check treats `systemctl --user is-active` non-zero as a hard error, which can skip recovery when unit is simply inactive. It also records `gateway_restart` regardless of restart outcome.\n\n## Policy\n1. Distinguish \"inactive\" from \"check failure\":\n   - Active: healthy, no action.\n   - Inactive/failed: recoverable down state -\u003e restart flow.\n   - Command execution failure (e.g. systemctl unavailable): health check error.\n2. Record restart events truthfully:\n   - `gateway_restart_success` only when restart command succeeds and post-check reports active.\n   - `gateway_restart_failed` when restart attempt fails or post-check remains inactive.\n3. Critical logic uses real failures, not optimistic restart counts.\n\n## Flow\n1. Read unit state using output + exit code from `systemctl is-active`.\n2. If state active: return healthy.\n3. If state inactive/failed:\n   - attempt restart #1\n   - if failed, optionally clear stale lock files then attempt restart #2\n   - verify active after each attempt\n4. Emit exactly one terminal event per check cycle: success or failed.\n5. Compute `restarts_failed_1h` and mark critical when failures in 1h \u003e= 3.\n\n## API/Health Surface\n- `/health` should reflect current gateway status plus recent success/failure restart events.\n- `gateway_critical` should only be emitted from real repeated failures.\n\n## Required Code Changes\n- `internal/health/health.go`\n  - Replace boolean `isUnitActive` check with richer state classification.\n  - Split restart event recording into success vs failure events.\n  - Ensure `gateway_restart` legacy event is removed or emitted only on success for compatibility.\n- `internal/api/api.go`\n  - Health endpoint should consume updated event semantics (critical based on failure patterns).\n\n## Test Plan\n1. `is-active` inactive path triggers restart attempts.\n2. Successful restart records success event only.\n3. Failed restart records failure event only.\n4. Three failures in 1h marks critical.\n5. systemctl command execution error does not falsely record restart success.\n\n## Non-goals\n- Automatic escalation actions beyond health signaling.","acceptance_criteria":"1) Inactive gateway state triggers restart attempts rather than early-return check error. 2) Success and failure restart events are recorded truthfully and exclusively. 3) Critical health state is derived from repeated real failures, not optimistic restart counting. 4) Tests cover inactive, success, failure, and command-error scenarios.","status":"in_progress","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T22:12:25.922075369+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T23:04:07.078827208+10:00","labels":["code","stage:coding"],"dependencies":[{"issue_id":"cortex-46d.1","depends_on_id":"cortex-46d","type":"parent-child","created_at":"2026-02-17T22:12:25.955849684+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-46d.10","title":"Fix OpenClaw embedded-mode fallback for --message incompatibility","description":"## Summary\nDispatches are failing repeatedly when OpenClaw falls back to embedded mode. Current launch path always uses `--message`, but embedded mode rejects that flag, producing failures like:\n`Gateway agent failed; falling back to embedded: Error: Message (--message) ...`\n\n## Scope\n- Update shared OpenClaw launch script used by PID + tmux dispatchers.\n- Attempt dispatch via `--message` first.\n- If failure indicates embedded-mode message incompatibility, retry using stdin prompt input.\n- Preserve model/tier thinking behavior and command parity across dispatchers.\n\n## Hardening\n- Fallback should trigger only for known message-flag incompatibility signatures.\n- Non-message-related failures should still fail fast and surface stderr.\n- Keep script behavior deterministic and shell-safe.\n\n## Tests\n- Add dispatch unit tests that assert fallback logic exists in generated script.\n- Verify model passthrough remains present in fallback path.\n- Verify compatibility-detection patterns are present and regression-protected.\n\n## Acceptance Criteria\n1) Embedded-mode fallback errors no longer cause immediate dispatch failure due to `--message` incompatibility.\n2) PID and tmux dispatchers both benefit from the same fallback behavior.\n3) Tests cover fallback script behavior and protect against regression.\n","status":"closed","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T22:27:20.690055613+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T22:49:34.508157562+10:00","closed_at":"2026-02-17T22:49:34.508157562+10:00","close_reason":"Fixed OpenClaw fallback by removing fragile tmux inline sh -c quoting, adding stdin fallback hardening, and validating via dispatch tests + live successful completions","labels":["code","dispatch","hardening","test"],"dependencies":[{"issue_id":"cortex-46d.10","depends_on_id":"cortex-46d","type":"parent-child","created_at":"2026-02-17T22:27:20.693785915+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-46d.11","title":"Replace gone terminal stage with failed_needs_check workflow","description":"Dispatches whose tmux session disappears are currently marked stage=gone. This is operationally ambiguous and bypasses a clear manual triage lane. Introduce explicit failed_needs_check semantics and make it first-class in APIs/metrics so operators can quickly see and resolve uncertain failures.","design":"## Goal\nReplace ambiguous terminal stage `gone` with an actionable triage state and keep failure diagnosis queryable.\n\n## Observed Failure\nLive dispatch rows currently contain `stage='gone'` when a tmux session disappears.\n\n## Scope\n1. Classification update:\n   - session disappeared -\u003e `status='failed'`, `stage='failed_needs_check'`, `failure_category='session_disappeared'`.\n   - keep non-disappeared failures in existing `failed` stage semantics.\n2. Data migration:\n   - migrate existing `dispatches.stage='gone'` rows to `failed_needs_check`.\n3. Operator visibility:\n   - API/status surface includes a `failed_needs_check` count and recent items.\n4. Idempotency:\n   - duplicate polling must not oscillate stage/status.\n\n## Required Code Areas\n- `internal/scheduler/scheduler.go` (gone classification path)\n- `internal/store/store.go` (migration/query helpers)\n- `internal/api/api.go` (needs-check visibility)\n\n## Test Plan\n1. `SessionStatus(gone)` maps to failed + failed_needs_check + session_disappeared diagnosis.\n2. Existing `gone` rows are migrated on startup/open without data loss.\n3. Non-gone failures remain unchanged.\n4. API exposes needs-check diagnostics for operator triage.\n\n## Non-goals\n- Auto-remediation for needs-check incidents.","acceptance_criteria":"1) After rollout, no new dispatch rows are written with `stage='gone'`.\n2) Session-disappeared outcomes are persisted as `status='failed'`, `stage='failed_needs_check'`, with actionable diagnosis fields.\n3) Existing historical `gone` rows are migrated to `failed_needs_check` safely.\n4) API/metrics expose needs-check counts and recent incidents.\n5) Regression tests cover gone mapping, migration, and non-gone behavior.","notes":"[2026-02-17 13:06:08Z] Runtime evidence snapshot:\n- dispatch rows with stage='gone': 2\n- Latest examples:\n  - id=905 bead=cortex-46d.5 completed_at=2026-02-17 13:01:53\n  - id=865 bead=cortex-46d.4 completed_at=2026-02-17 12:17:46\nThis confirms the need for gone-\u003efailed_needs_check mapping + migration.","status":"in_progress","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T22:58:09.223001462+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T23:07:15.90038071+10:00","labels":["code","stage:coding"],"dependencies":[{"issue_id":"cortex-46d.11","depends_on_id":"cortex-46d","type":"parent-child","created_at":"2026-02-17T22:58:09.226943279+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-46d.12","title":"Quarantine no-op completed dispatch loops via progression watchdog","description":"Cortex can record repeated completed dispatches for the same bead while the bead remains in the same open stage label, creating an infinite no-op loop that looks healthy in status metrics. Add progression watchdog logic to detect repeated completion-without-progress and route those beads to a manual triage lane instead of continuing blind retries.","design":"## Goal\nQuarantine false-progress loops where dispatches complete but bead workflow/state does not advance.\n\n## Observed Signal\nFrequent `zombie_killed` events and repeated retries indicate possible no-progress cycles.\n\n## Scope\n1. Add progression watchdog in scheduler:\n   - track per-bead consecutive `completed` dispatches with no bead state/label/stage change.\n2. Quarantine policy:\n   - when streak reaches threshold N, mark latest dispatch `failed_needs_check` and suppress redispatch for cooldown window.\n3. Recovery policy:\n   - clear quarantine when bead state progresses or operator explicitly clears quarantine.\n4. Visibility:\n   - emit deduped `no_progress_loop` event with bead/agent/provider/streak.\n   - expose quarantined beads + cooldown expiry via API/status.\n\n## Hardening\n- Threshold/cooldown configurable with safe defaults.\n- Single writer remains scheduler-owned (aligns with `cortex-46d.3`).\n- Avoid false positives for long-running single dispatches.\n\n## Required Code Areas\n- `internal/scheduler/scheduler.go` (watchdog + quarantine gating)\n- `internal/store/store.go` (watchdog/quarantine persistence)\n- `internal/api/api.go` (quarantine visibility)\n\n## Test Plan\n1. Repeated complete-without-progression triggers quarantine.\n2. Quarantined bead is not redispatched until cooldown/manual clear.\n3. Progressing bead does not trigger watchdog.\n4. Event emission is deduped per incident.\n\n## Non-goals\n- Automatic root-cause remediation.","acceptance_criteria":"1) Repeated completion without bead progression is detected and quarantined automatically.\n2) Quarantined beads are excluded from redispatch until cooldown expiry or manual clear.\n3) `no_progress_loop` incidents are visible in health/API with bead and streak context.\n4) Watchdog state transitions are scheduler-single-writer and idempotent.\n5) Tests cover trigger, suppression, recovery, and false-positive protection.","notes":"[2026-02-17 13:06:08Z] Runtime evidence snapshot:\n- health_events in last 24h: zombie_killed=43, dispatch_session_gone=2\n- health_events in last 1h: zombie_killed=43, dispatch_session_gone=2\nThis supports implementing progression watchdog + quarantine to stop repeated no-progress churn.","status":"in_progress","priority":1,"issue_type":"bug","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T22:58:24.797331923+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T23:06:28.883653129+10:00","labels":["code","stage:coding"],"dependencies":[{"issue_id":"cortex-46d.12","depends_on_id":"cortex-46d","type":"parent-child","created_at":"2026-02-17T22:58:24.799893749+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-46d.13","title":"Operate hardening rollout monitor and incident triage loop","description":"Set up an operations-grade monitoring and triage loop for the self-healing hardening rollout so newly emerging failure signatures are detected quickly and converted into actionable beads without clashing with active work.","design":"## Goal\nCreate a repeatable monitor-and-triage loop while `cortex-46d.*` fixes are rolling out.\n\n## Scope\n1. Monitoring baseline (every 10-15m while rollout active):\n   - failed dispatches (last 60m)\n   - running dispatch age outliers\n   - health event spikes (`dispatch_session_gone`, `zombie_killed`, launch failures)\n2. Signature triage:\n   - map known signatures to existing beads (`46d.7`, `46d.11`, `46d.12`, etc.).\n   - if signature is new/unmapped, create a new `46d` child bug with evidence.\n3. Collision avoidance:\n   - never modify/claim beads already `in_progress` by another actor.\n   - append evidence to existing bead notes instead of duplicating issues.\n4. Exit criteria:\n   - 24h window with no new high-severity signatures and no repeating incident spikes.\n\n## Operational Queries\n- Dispatch status breakdown + recent failed rows\n- Running rows older than timeout by tier/backend\n- Health event counts by type over 1h and 24h windows\n\n## Non-goals\n- Replacing automated health checks in runtime code.","acceptance_criteria":"1) A documented, repeatable monitoring loop exists with concrete DB/API checks and cadence.\n2) New failure signatures are either linked to existing `46d` beads or captured as new `46d` child bugs with evidence.\n3) The process explicitly avoids clashes by skipping beads already in progress.\n4) Rollout completion criteria are defined and measurable.","notes":"[2026-02-17 13:06:08Z] Initial monitor baseline:\n- dispatch status counts: completed=870 failed=30 interrupted=5 running=1\n- active running dispatch: id=906 bead=cortex-46d.3 age~95s at snapshot time\n- focus signatures currently active: stage='gone', zombie_killed spike, command/CLI mismatch failures.","status":"in_progress","priority":1,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T23:05:16.045133611+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T23:28:29.405062774+10:00","labels":["code","stage:coding"],"dependencies":[{"issue_id":"cortex-46d.13","depends_on_id":"cortex-46d","type":"parent-child","created_at":"2026-02-17T23:05:16.048351252+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-46d.2","title":"Correct PID dispatcher completion semantics","description":"PID mode currently infers completion from process death and defaults to completed without reliable exit code or output capture. Non-zero failures can be misclassified as success, breaking self-healing decisions.","design":"## Goal\nKeep PID mode supported, but make completion/failure classification accurate and diagnosable.\n\n## Policy (selected)\n- Keep PID backend and harden it (no deprecation).\n- Non-zero process exits must produce `failed` status.\n- PID completion must not default to `completed` without observed exit info.\n\n## Problem\nCurrent scheduler treats non-session dispatch death as completed by default, because only liveness is checked.\n\n## Design\n1. Extend PID dispatcher runtime metadata:\n   - Track handle -\u003e process state (`running|exited|unknown`), exit code, completion timestamp.\n   - Capture stderr/stdout to a file or buffer for post-run diagnostics.\n2. Expose status API from dispatcher for PID handles (exit-aware), consumed by scheduler completion logic.\n3. Scheduler completion logic for PID handles:\n   - exit code 0 -\u003e completed\n   - exit code != 0 -\u003e failed\n   - unknown exit state -\u003e failed with diagnostic category `unknown_exit_state`\n4. Output capture:\n   - persist captured output or explicit marker that output was unavailable.\n\n## Required Code Changes\n- `internal/dispatch/dispatch.go`\n  - Add PID exit tracking data structure and lifecycle updates around `cmd.Wait()`.\n  - Add output capture sink for PID mode.\n- `internal/dispatch/dispatch.go` + interface\n  - Add exit-aware status method(s) to `DispatcherInterface`, or equivalent safe abstraction.\n- `internal/scheduler/scheduler.go`\n  - Replace default success for PID dead process with exit-aware classification.\n- `internal/store/store.go`\n  - Ensure failure diagnosis path can run with PID captured output.\n\n## Test Plan\n1. PID dispatch exits 0 -\u003e completed.\n2. PID dispatch exits non-zero -\u003e failed.\n3. PID process killed by watchdog -\u003e failed/interrupted classification consistent.\n4. PID output captured and persisted (or explicit unavailable marker).\n5. Regression: no path where dead PID defaults to completed without exit info.\n\n## Non-goals\n- Cross-restart reattachment of PID child processes.","acceptance_criteria":"1) PID completion uses real exit status; non-zero exits are failed. 2) Dead PID handle cannot default to completed without exit-state evidence. 3) PID output is captured for diagnostics or explicitly marked unavailable. 4) Tests cover zero-exit, non-zero-exit, and killed-process scenarios.","notes":"**Review Result: APPROVED**\n\n**Outstanding Implementation - All Acceptance Criteria Exceeded**\n\n## PID Completion Semantics Corrected\n\n**Real Exit Status Implementation:**\n- Process monitoring: monitorProcess goroutine tracks cmd.Wait results\n- Exit code capture: Proper handling of exec.ExitError and zero exits\n- Non-zero = failed: Exit code != 0 results in failed status\n- Zero = completed: Exit code 0 results in completed status\n\n**Scheduler Integration:**\n- Exit-aware logic: Uses ProcessState.ExitCode for completion classification\n- No default success: Dead processes without exit info marked as failed\n- Unknown state handling: Processes with unknown exit state marked as failed with diagnostic\n\n## Process State Tracking Excellence\n\n**ProcessState Structure:**\n- State: running, exited, unknown\n- ExitCode: Real exit code or -1 for unknown/killed\n- CompletedAt: Timestamp of completion\n- OutputPath: Path to captured output file\n\n**Dispatcher Interface Enhancement:**\n- GetProcessState method added to DispatcherInterface\n- Both PID and Tmux dispatchers implement the interface\n- Consistent state representation across dispatcher types\n\n## Output Capture Implementation\n\n**PID Dispatcher Output Handling:**\n- Output file creation: Creates temp file for each dispatch\n- Stdout + stderr capture: Both streams redirected to output file\n- Path tracking: OutputPath stored in ProcessState\n- Scheduler integration: Reads output file and stores via store.CaptureOutput\n- Cleanup: Temp files cleaned up after process completion\n\n**Availability Markers:**\n- Empty OutputPath indicates no output available\n- Graceful handling when output files are missing\n\n## Comprehensive Test Coverage\n\n**Test Scenarios - All Pass (5/5):**\n\n1. TestPIDDispatcherZeroExit - Process exits 0 → completed classification\n2. TestPIDDispatcherNonZeroExit - Process exits 42 → failed classification  \n3. TestPIDDispatcherKilledProcess - Killed process → failed, no false success\n4. TestPIDDispatcherProcessNotTracked - Unknown PID → failed, prevents defaults\n5. TestPIDDispatcherOutputCapture - Mixed stdout/stderr properly captured\n\n## Scheduler Logic Updates\n\n**Process Completion Logic:**\n- case exited: ExitCode 0 = completed, non-zero = failed\n- case unknown: status = failed (no default to completed)\n- Diagnostic logging for unknown states\n- Output integration with process output capture\n\n## Architecture Quality\n\n**Process Lifecycle Management:**\n- Proper goroutine monitoring with cmd.Wait\n- Thread-safe process info tracking with RWMutex\n- Cleanup of temporary files and resources\n- State transitions: running → exited with proper exit codes\n\n## Acceptance Criteria Assessment\n\n1) Real exit status used: exit code 0=completed, non-zero=failed ✓\n2) No default completion: Dead processes without exit info = failed ✓\n3) Output captured: File-based capture with OutputPath tracking ✓\n4) Comprehensive tests: All scenarios covered with passing tests ✓\n\nOutstanding implementation that completely fixes PID completion semantics with proper exit code handling, output capture, and comprehensive testing.\n\nReady for production deployment.\n\nApproved for stage:qa","status":"closed","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T22:12:26.007240656+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:37:45.807341762+10:00","closed_at":"2026-02-18T02:37:42.349307089+10:00","close_reason":"Closed","labels":["stage:qa","stage:review"],"dependencies":[{"issue_id":"cortex-46d.2","depends_on_id":"cortex-46d","type":"parent-child","created_at":"2026-02-17T22:12:26.010856347+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-46d.3","title":"Establish single-writer ownership for stuck/zombie transitions","description":"Stuck/zombie lifecycle checks run from both scheduler tick and health monitor loop. This creates race conditions and duplicate side effects (double retries, conflicting status updates, noisy health events).","design":"## Goal\nEliminate race conditions by giving exactly one runtime component write-ownership of stuck/zombie dispatch state transitions.\n\n## Policy (selected)\n- Scheduler owns stuck/zombie write transitions.\n- Health monitor remains responsible for gateway checks and read-only diagnostics.\n\n## Problem\nBoth scheduler tick and health monitor currently invoke stuck/zombie lifecycle mutation paths, causing duplicate retries/events and non-deterministic outcomes.\n\n## Design\n1. Ownership boundary:\n   - `scheduler.RunTick` performs `CheckStuckDispatches` and `CleanZombies` writes.\n   - `health.Monitor` no longer mutates dispatch lifecycle state.\n2. Idempotent transition protection:\n   - Add conditional state updates in store (`WHERE status='running'` style guards) for critical transitions.\n   - Transition methods return affected-row count so duplicate invocations become safe no-ops.\n3. Event dedup strategy:\n   - Emit health events only from owner path for stuck/zombie transitions.\n\n## Required Code Changes\n- `internal/health/health.go`\n  - Remove or disable dispatch lifecycle mutation from monitor loop.\n- `internal/scheduler/scheduler.go`\n  - Keep dispatch lifecycle mutations centralized.\n- `internal/store/store.go`\n  - Add guarded update helpers for idempotent transitions.\n\n## Test Plan\n1. Regression test: concurrent calls into stuck transition path produce one retry enqueue, not duplicates.\n2. Regression test: duplicate zombie cleanup invocations do not double-kill or double-log.\n3. Integration test: health monitor running alongside scheduler does not mutate dispatch states.\n\n## Non-goals\n- Multi-process distributed locking across hosts (single-process ownership only in this scope).","acceptance_criteria":"1) Exactly one runtime component performs stuck/zombie dispatch state mutations. 2) State transitions are idempotent under duplicate invocation. 3) Duplicate retries and duplicate zombie lifecycle events are prevented by tests.","notes":"Policy chosen: scheduler is single writer for stuck/zombie dispatch lifecycle transitions (1A).","status":"in_progress","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T22:12:26.010973376+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T23:02:39.694764345+10:00","labels":["code","stage:coding"],"dependencies":[{"issue_id":"cortex-46d.3","depends_on_id":"cortex-46d","type":"parent-child","created_at":"2026-02-17T22:12:26.075220721+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-46d.4","title":"Make dispatch launch/persistence atomic to prevent untracked runs","description":"Scheduler dispatches process or session before persisting dispatch row. If DB write fails, work may continue untracked and unrecoverable. Add failure containment so launched work cannot survive without persisted state.","design":"## Goal\nGuarantee that Cortex never leaves live dispatch work untracked in persistence.\n\n## Chosen Policy (confirmed)\n- Strategy: intent-first launch (precreate DB row before process/session launch).\n- Rollback-kill failure: emit health event + error log, continue scheduler (no auto-pause).\n- Retry semantics: if new retry attempt launch or persistence fails, keep original dispatch in `pending_retry`.\n- Launch intent timeout: `launching` intents auto-fail as stale after 2 minutes and count as busy until then.\n\n## State Model\nUse existing `dispatches` row as source of truth:\n1. `status=running, stage=launching` (intent created, not yet fully active)\n2. `status=running, stage=running` (handle/session persisted, active)\n3. Terminal: `completed|failed|cancelled|interrupted|retried` with terminal stage\n\nInvariant: every launched dispatch must have a DB row created before launch attempt starts.\n\n## Initial Dispatch Flow\n1. Create intent row via store method (`RecordDispatchIntent`):\n   - `pid=0`, `session_name=''`, `status='running'`, `stage='launching'`\n   - include bead/project/agent/provider/tier/prompt/log/branch/backend fields\n2. Launch dispatcher.\n3. If launch fails:\n   - mark same row failed (`exit_code=-1`, stage=`launch_failed`, completed_at set)\n   - do not leave `running` row.\n4. If launch succeeds:\n   - persist handle/session + stage transition to `running` in one store call (`BindDispatchHandle`).\n5. If handle/session persistence fails after successful launch:\n   - attempt immediate kill of launched work.\n   - if kill succeeds: mark intent row failed (`stage=launch_persist_failed_killed`).\n   - if kill fails: mark intent row failed (`stage=launch_persist_failed_kill_failed`) and emit health event `dispatch_orphan_risk` with bead/agent/handle/session details.\n\n## Retry Flow\n1. Original row remains `pending_retry` while attempting new run.\n2. Create new intent row in `launching`.\n3. Launch and bind as above.\n4. Only after new row reaches `status=running, stage=running`, update original row to `retried`.\n5. If new launch/bind fails, original row stays `pending_retry` for future attempt.\n\n## Stale Launching Cleanup (2m)\nIn running-dispatch check path:\n- If `stage=launching` and age \u003c 2m: treat as busy, do not evaluate liveness.\n- If `stage=launching` and age \u003e= 2m: mark failed (`stage=launch_timeout`, `exit_code=-1`), emit health event `dispatch_launch_timeout`.\n\n## Required Code Changes\n- `internal/store/store.go`\n  - Add `RecordDispatchIntent(...)` (explicit stage `launching`)\n  - Add `BindDispatchHandle(id, pid, sessionName)` (set handle + stage `running`)\n  - Add helper for launch failure terminalization (or reuse existing status/stage updates consistently)\n- `internal/scheduler/scheduler.go`\n  - Replace launch-then-record order with intent-\u003elaunch-\u003ebind flow in:\n    - normal dispatch path\n    - `processPendingRetries` path\n  - Ensure retry old-row transition to `retried` occurs only after new-row bind success\n  - Add stale-`launching` handling in running-dispatch checks\n- Optional metrics/health event additions for observability:\n  - `dispatch_launch_timeout`\n  - `dispatch_orphan_risk`\n  - `dispatch_launch_bind_failed`\n\n## Test Plan\n1. Initial dispatch DB failure injection:\n   - Intent created, launch succeeds, bind fails -\u003e kill attempted, row terminalized, no untracked running dispatch.\n2. Retry path failure injection:\n   - New retry bind fails -\u003e original remains `pending_retry`.\n3. Launch failure:\n   - Intent row transitions from `launching` to terminal failed.\n4. Stale launching timeout:\n   - `launching` older than 2m auto-fails.\n5. Busy semantics:\n   - `launching` rows block duplicate dispatch for same bead/agent until terminalized.\n\n## Non-goals\n- Auto-pausing scheduler on rollback kill failure (explicitly not selected).\n- Full orphan reattachment flow (covered by separate hardening work).","acceptance_criteria":"1) Dispatch path is intent-first: row enters running+launching before launch, then running+running only after handle/session bind success. 2) On post-launch bind failure, launched work is killed immediately; failures to kill emit dispatch_orphan_risk health event and terminalize the row. 3) Retry path keeps original dispatch in pending_retry until replacement row reaches running+running. 4) Launching rows timeout after 2 minutes and auto-fail with dispatch_launch_timeout event. 5) Tests cover initial dispatch bind failure, retry bind failure, launch failure, launching timeout, and busy semantics.","notes":"Spec decisions confirmed: 1B intent-first launch with precreated row; 2A on rollback kill failure log plus health event and continue; 3A for retry path keep original pending_retry row for future attempts when new launch or persistence fails.","status":"closed","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T22:12:54.551110966+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T22:46:59.478488924+10:00","closed_at":"2026-02-17T22:46:59.478488924+10:00","close_reason":"Implemented intent-first dispatch persistence, bind-after-launch rollback, and launching-timeout protections with store/scheduler tests","dependencies":[{"issue_id":"cortex-46d.4","depends_on_id":"cortex-46d","type":"parent-child","created_at":"2026-02-17T22:12:54.554563183+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-46d.5","title":"Fix bead stage keying to prevent cross-project collisions","description":"bead_stages uniqueness and upsert conflict key are bead_id only. If different projects use same bead ID, stage state can overwrite across projects.","design":"## Goal\nPrevent workflow stage state collisions when multiple projects use identical bead IDs.\n\n## Problem\n`bead_stages` uniqueness and upsert conflict key currently use `bead_id` alone, so one project can overwrite another project's stage state.\n\n## Design\n1. Schema keying:\n   - Replace unique key on `bead_id` with composite unique key `(project, bead_id)`.\n2. Query/API keying:\n   - Stage read/write methods must key by both project and bead_id.\n   - Keep temporary compatibility wrappers only if needed, but disallow ambiguous operations.\n3. Migration plan:\n   - Create `bead_stages_new` with composite uniqueness.\n   - Copy existing rows preserving `project` and history JSON.\n   - Swap tables atomically and recreate indexes.\n4. Validation:\n   - If compatibility path receives bead_id-only lookup and finds multiple projects, return explicit ambiguity error.\n\n## Required Code Changes\n- `internal/store/store.go`\n  - Schema and migration updates for composite key.\n  - Update stage-related methods to require project-aware keying.\n- Callers/tests:\n  - Update any stage APIs currently bead_id-only.\n\n## Test Plan\n1. Two projects with same bead_id keep independent stage histories.\n2. Upsert on project A does not modify project B row.\n3. Migration test from old schema preserves all rows/history.\n4. Ambiguous bead-only lookup fails explicitly (if compatibility wrappers exist).\n\n## Non-goals\n- Global cross-project stage synchronization semantics.","acceptance_criteria":"1) bead_stages uniqueness and upsert use composite project+bead_id key. 2) Stage APIs and queries avoid cross-project ambiguity. 3) Migration preserves stage rows and history safely. 4) Tests prove identical bead IDs across projects do not collide.","notes":"**Review Result: APPROVED**\n\n**Excellent Implementation - All Acceptance Criteria Met**\n\n## Schema \u0026 Migration Excellence\n\n**Composite Key Implementation:**\n- Unique constraint: CREATE UNIQUE INDEX idx_bead_stages_project_bead ON bead_stages(project, bead_id)\n- Proper schema with project column added to bead_stages table\n- Migration safety: migrateBeadStagesTable handles existing databases properly\n- Index optimization: Composite project+bead_id and project+stage indexes\n\n**Schema Design Quality:**\n- Preserves all historical data during migration\n- Removes legacy bead-only indexes to prevent ambiguity\n- Proper column ordering and defaults\n- WAL mode and busy timeout for concurrency\n\n## API \u0026 Method Updates\n\n**All Stage APIs Updated for Project Awareness:**\n- GetBeadStage(project, beadID) - requires both parameters\n- UpsertBeadStage(stage) - uses composite key in ON CONFLICT\n- UpdateBeadStageProgress(project, beadID, ...) - project-scoped\n- ListBeadStagesForProject(project) - proper project filtering\n- DeleteBeadStage(project, beadID) - composite key deletion\n\n**Legacy Compatibility with Safety:**\n- GetBeadStagesByBeadIDOnly(beadID) - detects cross-project ambiguity\n- Returns explicit error: ambiguous bead_id found in multiple projects\n- Prevents accidental overwrites from legacy callers\n\n## Cross-Project Collision Prevention\n\n**Test Coverage - All Pass (8/8):**\n\n1. TestBeadStageProjectIsolation - Same bead ID in different projects have independent stage state\n2. TestBeadStageUpsertConflictResolution - Composite key upsert works correctly\n3. TestBeadStageAmbiguityDetection - Multiple projects with same bead_id detected with explicit error\n4. TestBeadStageNonAmbiguousLookup - Single project lookup succeeds normally\n5. TestBeadStageListByProject - Project isolation in list operations\n6. Plus comprehensive CRUD tests\n\n## Implementation Quality\n\n**Code Excellence:**\n- Clean separation of project-aware vs legacy methods\n- Proper error handling with descriptive messages\n- Efficient composite key queries\n- SQL injection safe with proper parameter binding\n- Consistent naming conventions\n\n**Database Design:**\n- Composite unique constraint prevents collisions at DB level\n- Optimal indexing for both lookup patterns\n- Migration preserves existing data integrity\n- Proper foreign key relationships maintained\n\n## Acceptance Criteria Assessment\n\n1) Composite project+bead_id key: Implemented with unique index\n2) Cross-project ambiguity avoided: All APIs require project parameter\n3) Migration preserves data safely: migrateBeadStagesTable tested\n4) Tests prove collision prevention: 8 comprehensive tests all pass\n\nOutstanding implementation that completely eliminates cross-project stage collision risks with excellent testing and proper migration handling.\n\nReady for production deployment.\n\nApproved for stage:qa","status":"closed","priority":1,"issue_type":"bug","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T22:13:04.589274401+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T01:14:58.913898899+10:00","closed_at":"2026-02-18T01:14:58.913898899+10:00","close_reason":"Closed","labels":["code","stage:coding","stage:qa","stage:review"],"dependencies":[{"issue_id":"cortex-46d.5","depends_on_id":"cortex-46d","type":"parent-child","created_at":"2026-02-17T22:13:04.603563074+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-46d.6","title":"Enable cross-project dependency resolution in scheduler dispatch gating","description":"Cross-project dependency parsing exists but scheduler currently uses local-only unblocked filtering. This can block valid work or mis-handle project:bead dependencies, undermining orchestration correctness across projects.","design":"## Goal\nMake scheduler dispatch gating correctly respect cross-project dependencies.\n\n## Policy (selected)\n- Fail closed on cross-project graph/lookup failures: unresolved means blocked.\n\n## Problem\nCross-project dependency support exists, but scheduler currently uses local-only filtering, so `project:bead` dependencies are not enforced consistently.\n\n## Design\n1. Build cross-project graph once per scheduler tick from enabled projects.\n2. For each project, use `FilterUnblockedCrossProject` instead of local-only ready filter.\n3. Cross-project dependency rule:\n   - `project:bead` is unblocked only when referenced bead exists and is `closed` in source project.\n4. Failure handling (fail-closed):\n   - If source project cannot be read or lookup fails, treat dependency as unresolved.\n   - Emit health event `cross_dep_graph_unavailable` with affected project/dependency details.\n\n## Required Code Changes\n- `internal/scheduler/scheduler.go`\n  - Build and pass cross-project graph into filtering path.\n- `internal/beads/crossdeps.go`\n  - Ensure unresolved/missing project behavior remains conservative and observable.\n- Optional observability:\n  - metric/event count for cross-project blocked reasons.\n\n## Test Plan\n1. Cross-project dependency resolved -\u003e bead becomes ready.\n2. Cross-project dependency open -\u003e bead blocked.\n3. Unknown cross-project reference -\u003e bead blocked.\n4. Project read failure for cross-graph build -\u003e bead blocked + health event emitted.\n5. Local-only dependencies remain unchanged.\n\n## Non-goals\n- Prioritization across projects beyond dependency gating.","acceptance_criteria":"1) Scheduler evaluates ready beads with cross-project dependency graph support. 2) project:bead deps unblock only when referenced bead is closed in source project. 3) Cross-project read/lookup failures block conservatively and emit observable health signal. 4) Tests cover resolved, unresolved, unknown, and read-failure cases.","notes":"Policy chosen: fail-closed for cross-project lookup/read failures (2A).","status":"in_progress","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T22:13:04.620309102+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T23:07:16.100868816+10:00","labels":["code","stage:coding"],"dependencies":[{"issue_id":"cortex-46d.6","depends_on_id":"cortex-46d","type":"parent-child","created_at":"2026-02-17T22:13:04.635480388+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-46d.7","title":"Align runtime behavior with dispatch routing and CLI config","description":"dispatch.routing and dispatch.cli config sections are defined but runtime selection is mostly hardcoded to tmux availability. This creates config drift and makes control-plane settings unreliable.","design":"## Goal\nMake dispatch runtime strictly follow config, and make misconfiguration fail fast with explicit diagnostics.\n\n## Observed Failures (from live DB)\n- `error: unknown option '--model'`\n- shell parse failures (`Syntax error: Unterminated quoted string`, `Bad fd number`, `(\" unexpected`)\nThese indicate config/runtime command assembly drift.\n\n## Scope\n1. Introduce explicit backend resolver used by scheduler dispatch paths:\n   - tier/context -\u003e `dispatch.routing.*_backend`\n   - no hidden backend override based only on tmux availability.\n2. Validate provider-\u003eCLI binding at startup:\n   - if provider requires CLI backend, resolve provider CLI key deterministically.\n   - missing CLI config or invalid flags cause startup error.\n3. Harden command construction:\n   - construct argv safely (no shell-string interpolation for user/config fragments).\n   - ensure prompt/model args cannot create malformed shell command lines.\n4. Runtime failure behavior:\n   - invalid/unavailable configured backend produces defer/fail with health event (no silent fallback unless explicitly configured).\n\n## Required Code Areas\n- `internal/config/config.go` (routing/CLI validation)\n- `internal/scheduler/scheduler.go` + dispatch selection path\n- `internal/dispatch/*` command construction/runtime validation\n\n## Observability\nEmit structured events:\n- `dispatch_config_invalid`\n- `dispatch_backend_unavailable`\n- `dispatch_command_build_failed`\nwith bead, provider, backend, and reason.\n\n## Test Plan\n1. Valid routing matrix dispatches through expected backend.\n2. Missing CLI binding for provider fails config load.\n3. Invalid backend name fails config load.\n4. Command builder handles complex prompts without shell parse errors.\n5. Runtime unavailable backend is surfaced as explicit defer/failure event.\n\n## Non-goals\n- New backend types.","acceptance_criteria":"1) Dispatch backend selection is driven by `dispatch.routing` for fast/balanced/premium/comms/retry with no hidden override path.\n2) Startup validation fails on missing/invalid provider CLI bindings and invalid backend names.\n3) Dispatch command construction no longer emits malformed shell invocations under complex prompt/config content.\n4) Runtime backend/config failures emit explicit structured events and deterministic defer/fail behavior.\n5) Tests cover the observed signatures (`unknown option --model`, shell parse failures) and prevent regressions.","notes":"[2026-02-17 13:06:08Z] Runtime evidence snapshot:\n- model_flag_errors_24h=2 (dispatch_output contains \"unknown option '--model'\")\n- syntax-like shell failures observed on failed dispatches around 12:33-12:42 UTC:\n  - \"Syntax error: Unterminated quoted string\"\n  - \"Syntax error: Bad fd number\"\n  - \"Syntax error: ( unexpected\"\n- Relevant dispatch IDs: 888, 887, 886, 885, 884, 881, 879, 878.","status":"closed","priority":2,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T22:13:17.179791444+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:09:38.717543038+10:00","closed_at":"2026-02-18T04:09:38.717543038+10:00","close_reason":"Broken down into 4 executable sub-tasks: config validation, backend selection, command hardening, and observability","labels":["code","stage:coding"],"dependencies":[{"issue_id":"cortex-46d.7","depends_on_id":"cortex-46d","type":"parent-child","created_at":"2026-02-17T22:13:17.182726399+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-46d.7.1","title":"Add dispatch backend selection validation to config loading","description":"Implement strict config validation for dispatch routing and CLI backend configuration at startup.\n\nFiles to create/modify:\n- internal/config/config.go (add validation functions)\n- internal/config/config_test.go (test validation logic)\n\nAcceptance criteria:\n- Config validation fails startup on missing CLI bindings for providers that require them\n- Invalid backend names (not tmux/direct/etc.) cause config load failure\n- Provider-\u003eCLI key resolution is deterministic and documented\n- Validation provides clear error messages indicating what's missing/invalid\n- Unit tests cover all validation error paths\n- Backward compatibility with existing valid configs\n\nValidation requirements:\n- Each provider's tier requirements map to valid dispatch.routing backends\n- CLI providers have corresponding [dispatch.cli.{provider}] sections with valid flags\n- Backend names match known dispatcher types\n- Required CLI flags (model, provider-specific) are present and valid\n\nImplementation details:\n- Add ValidateDispatchConfig() function called during config load\n- Check dispatch.routing.{tier}_backend values against known backend types\n- Validate provider CLI bindings exist for CLI-dependent backends\n- Return structured validation errors with field paths and suggestions","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:08:35.403786417+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:08:35.403786417+10:00","dependencies":[{"issue_id":"cortex-46d.7.1","depends_on_id":"cortex-46d.7","type":"parent-child","created_at":"2026-02-18T04:08:35.410027392+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-46d.7.2","title":"Implement strict config-driven backend selection in scheduler","description":"Replace hardcoded tmux availability checks with strict dispatch.routing config-driven backend selection.\n\nFiles to create/modify:\n- internal/scheduler/scheduler.go (update dispatch selection logic)\n- internal/scheduler/backend.go (new - backend resolver)\n- internal/scheduler/scheduler_test.go (test backend selection)\n\nAcceptance criteria:\n- Backend selection uses dispatch.routing.{tier}_backend exclusively\n- No hidden overrides based on tmux availability or other runtime detection\n- Tier/context mapping (fast/balanced/premium/comms/retry) resolves deterministically\n- Backend resolver is testable in isolation\n- Integration tests verify correct backend selection for each tier\n- Scheduler fails dispatch gracefully when configured backend unavailable\n\nBackend resolver interface:\n- ResolveBackend(tier string, context DispatchContext) (BackendType, error)\n- Backend types: tmux, direct, (future: kubernetes, etc.)\n- Clear error messages when backend unavailable or misconfigured\n\nImplementation details:\n- Remove tmux availability auto-detection from dispatch path\n- Create explicit backend resolver component used by scheduler\n- Each tier maps to specific backend via config lookup\n- Failed backend resolution becomes explicit defer/failure (not silent fallback)\n- Log backend selection decisions for debugging","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:08:46.678363978+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:08:46.678363978+10:00","dependencies":[{"issue_id":"cortex-46d.7.2","depends_on_id":"cortex-46d.7","type":"parent-child","created_at":"2026-02-18T04:08:46.683095049+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-46d.7.2","depends_on_id":"cortex-46d.7.1","type":"blocks","created_at":"2026-02-18T04:08:46.695404876+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-46d.7.3","title":"Harden dispatch command construction against shell parsing errors","description":"Fix command construction to prevent shell parsing errors and malformed CLI invocations.\n\nFiles to create/modify:\n- internal/dispatch/command.go (new - safe command builder)\n- internal/dispatch/command_test.go (new - test command construction)  \n- internal/dispatch/backend.go (update to use safe builder)\n- internal/dispatch/tmux.go (update to use safe builder)\n\nAcceptance criteria:\n- Command construction uses argv array building, not shell string interpolation\n- Complex prompts with quotes, newlines, special chars don't break command parsing\n- Provider CLI flags are assembled safely without shell injection risks\n- All observed error signatures are covered by tests and fixed:\n  - 'unknown option --model' errors eliminated\n  - 'Syntax error: Unterminated quoted string' prevented\n  - 'Syntax error: Bad fd number' prevented  \n  - 'Syntax error: ( unexpected' prevented\n- Unit tests reproduce observed failure patterns before fixes\n\nCommand builder interface:\n- BuildCommand(provider, model, prompt, flags) ([]string, error)\n- Safe argument escaping for all user/config content\n- Validation of required flags before construction\n- Clear errors for missing/invalid configuration\n\nImplementation details:\n- Replace string concatenation with exec.Command compatible argv arrays\n- Properly escape/quote prompt content and model names\n- Validate CLI flags match provider requirements\n- Use shell-safe argument passing throughout dispatch pipeline\n- Test with complex real-world prompts that previously failed","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:08:58.817706903+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:08:58.817706903+10:00","dependencies":[{"issue_id":"cortex-46d.7.3","depends_on_id":"cortex-46d.7","type":"parent-child","created_at":"2026-02-18T04:08:58.821425441+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-46d.7.4","title":"Add structured observability for dispatch config and runtime failures","description":"Implement structured event emission for dispatch configuration and runtime failures.\n\nFiles to create/modify:\n- internal/health/events.go (extend with dispatch-specific events)\n- internal/scheduler/observability.go (new - dispatch event emission)\n- internal/dispatch/backend.go (extend with event emission)\n\nAcceptance criteria:\n- Structured events emitted for all dispatch failure modes:\n  - dispatch_config_invalid (missing CLI config, invalid backend)\n  - dispatch_backend_unavailable (configured backend not available)\n  - dispatch_command_build_failed (command construction errors)\n- Events include contextual data: bead ID, provider, backend, reason\n- Events are queryable via health API for debugging\n- Performance impact is minimal (async event emission)\n- Integration tests verify event emission for each failure type\n\nEvent schema:\n- Event type, timestamp, dispatch/bead context\n- Provider, backend, tier information where applicable\n- Error details and suggested remediation where possible\n- Structured data for automated analysis\n\nImplementation details:\n- Use existing health event infrastructure\n- Emit events at appropriate failure points in dispatch pipeline\n- Include enough context for debugging without sensitive data\n- Rate-limit similar events to prevent spam\n- Events should be actionable for operators (clear next steps)\n- Integrate with existing health API endpoints","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:09:09.413399189+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:09:09.413399189+10:00","dependencies":[{"issue_id":"cortex-46d.7.4","depends_on_id":"cortex-46d.7","type":"parent-child","created_at":"2026-02-18T04:09:09.417004173+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-46d.7.4","depends_on_id":"cortex-46d.7.2","type":"blocks","created_at":"2026-02-18T04:09:09.42809035+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-46d.7.4","depends_on_id":"cortex-46d.7.3","type":"blocks","created_at":"2026-02-18T04:09:09.439662703+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-46d.8","title":"Harden tmux dispatcher command error handling and cleanup parsing","description":"Tmux dispatcher currently ignores errors from key tmux setup commands and infers agent names from session strings using fragile split indexing. This can mask launch failures and leak session resources for hyphenated agent names.","design":"## Goal\nMake tmux dispatch startup failures explicit and resource cleanup robust across all agent naming patterns.\n\n## Problem\nTmux dispatcher currently ignores errors from critical setup commands (`set`, `set-option`, `send-keys`). Cleanup infers agent name via fragile session-name splitting, which breaks for hyphenated agent names.\n\n## Design\n1. Startup command hardening:\n   - Treat failures from `tmux set`, `set-option`, and `send-keys` as dispatch startup failure.\n   - On any startup sub-step failure, kill created session and return error.\n2. Robust session metadata:\n   - Maintain explicit session metadata mapping (`session_name -\u003e agent_id`) inside dispatcher lifecycle state.\n   - Stop parsing agent identity from session string segments.\n3. Cleanup path:\n   - Cleanup uses explicit metadata; if missing, fallback to safe no-op with warning (not guessed destructive cleanup).\n4. Observability:\n   - Emit structured errors/events for startup sub-step failures and cleanup metadata misses.\n\n## Required Code Changes\n- `internal/dispatch/tmux.go`\n  - Check and propagate errors for all startup subcommands.\n  - Add metadata map and use it in cleanup paths (`Kill`, dead-session cleanup helpers).\n- Tests\n  - Extend tmux tests to inject/setup failures and verify cleanup behavior.\n\n## Test Plan\n1. Failure in `tmux set` -\u003e dispatch fails, session cleaned.\n2. Failure in `tmux set-option` -\u003e dispatch fails, session cleaned.\n3. Failure in `tmux send-keys` -\u003e dispatch fails, session cleaned.\n4. Hyphenated agent names cleanup path resolves correctly using metadata map.\n5. Missing metadata path logs warning and avoids unsafe cleanup guessing.\n\n## Non-goals\n- Changing session naming format for existing sessions.","acceptance_criteria":"1) Tmux startup subcommand failures are surfaced and fail dispatch startup. 2) Startup failure path cleans created session resources deterministically. 3) Cleanup resolves agent identity without parsing fragile session-name segments. 4) Tests cover command-failure and hyphenated-agent cleanup scenarios.","status":"closed","priority":2,"issue_type":"bug","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T22:13:23.028515136+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:09:41.837997153+10:00","closed_at":"2026-02-18T04:09:41.837997153+10:00","close_reason":"Broken down into 2 executable sub-tasks: startup error handling and session metadata tracking","labels":["code","stage:coding"],"dependencies":[{"issue_id":"cortex-46d.8","depends_on_id":"cortex-46d","type":"parent-child","created_at":"2026-02-17T22:13:23.031687653+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-46d.8.1","title":"Add error checking for all tmux startup subcommands","description":"Implement proper error handling for all tmux session startup commands with cleanup on failure.\n\nFiles to create/modify:\n- internal/dispatch/tmux.go (update startup command error handling)\n- internal/dispatch/tmux_test.go (test startup failure scenarios)\n\nAcceptance criteria:\n- All tmux startup subcommands check and propagate errors: set, set-option, send-keys\n- Failed startup commands trigger immediate session cleanup and dispatch failure\n- Partial session state is cleaned up deterministically on any startup failure\n- Unit tests inject failures at each startup step and verify cleanup behavior\n- Error messages are descriptive and indicate which startup step failed\n\nError handling requirements:\n- tmux set failures -\u003e cleanup session, return error\n- tmux set-option failures -\u003e cleanup session, return error  \n- tmux send-keys failures -\u003e cleanup session, return error\n- Session cleanup uses kill-session command on startup failure\n- No orphaned sessions left behind on startup errors\n\nImplementation details:\n- Check exit codes and stderr from all tmux subcommands\n- Implement startupCleanup() function for failed session cleanup\n- Wrap command execution with proper error propagation\n- Log startup failures with context about which command failed\n- Test startup failures using mock tmux commands or error injection","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:09:20.887459181+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:09:20.887459181+10:00","dependencies":[{"issue_id":"cortex-46d.8.1","depends_on_id":"cortex-46d.8","type":"parent-child","created_at":"2026-02-18T04:09:21.303150674+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-46d.8.2","title":"Implement explicit session metadata tracking for robust cleanup","description":"Replace fragile session name parsing with explicit session metadata mapping for reliable cleanup.\n\nFiles to create/modify:\n- internal/dispatch/tmux.go (add session metadata map and cleanup logic)\n- internal/dispatch/session_tracking.go (new - session metadata management)\n- internal/dispatch/tmux_test.go (test metadata tracking and cleanup)\n\nAcceptance criteria:\n- Maintain explicit mapping of session_name -\u003e agent_id in dispatcher state\n- Cleanup operations use metadata map instead of parsing session names\n- Hyphenated agent names cleanup correctly using explicit metadata\n- Missing metadata fallback logs warning and avoids unsafe cleanup operations\n- Session metadata is thread-safe and consistent across concurrent operations\n- Unit tests cover hyphenated agent names and cleanup edge cases\n\nSession metadata interface:\n- TrackSession(sessionName, agentID string) - record session metadata\n- GetSessionAgent(sessionName string) (agentID string, found bool) - lookup agent\n- CleanupSession(sessionName string) error - cleanup using metadata\n- RemoveSession(sessionName string) - remove from tracking\n\nImplementation details:\n- Add session metadata map to tmux dispatcher state\n- Record session-\u003eagent mapping during session creation\n- Use explicit mapping in Kill() and cleanup helper functions\n- Add mutex protection for concurrent session operations\n- Fallback behavior for missing metadata: log warning, no destructive action\n- Clear metadata when sessions are properly cleaned up","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:09:32.201223583+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:09:32.201223583+10:00","dependencies":[{"issue_id":"cortex-46d.8.2","depends_on_id":"cortex-46d.8","type":"parent-child","created_at":"2026-02-18T04:09:32.204020047+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-46d.8.2","depends_on_id":"cortex-46d.8.1","type":"blocks","created_at":"2026-02-18T04:09:32.214231505+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-46d.9","title":"Wire learner and reporter into adaptive self-improvement loop","description":"Learner analytics and reporter components exist but are not actively wired into the runtime control loop. Add a bounded feedback mechanism that adjusts dispatch policy based on observed outcomes.","design":"## Goal\nActivate self-improvement loop in recommend-only mode (no automatic policy mutation).\n\n## Policy (selected)\n- Recommend-only output: analytics produce actionable recommendations, but runtime policy is not auto-applied.\n\n## Problem\nLearner/reporter modules exist but are not integrated into the runtime orchestration loop, so system learns nothing operationally from outcomes.\n\n## Design\n1. Analysis cadence:\n   - Add periodic learner cycle (e.g., every 6h or configurable) to compute:\n     - provider success/failure trends\n     - tier misclassification trends\n     - project velocity/cost signals\n2. Recommendation generation:\n   - Produce bounded recommendation objects with fields:\n     - type (provider, tier, retry, cost)\n     - confidence\n     - evidence window\n     - suggested action\n3. Persistence and visibility:\n   - Store recommendations in DB or structured health events with timestamps.\n   - Expose latest recommendations via API endpoint and include in digest/retro output.\n4. Safety boundary:\n   - No automatic changes to routing/provider/tier policy in this phase.\n   - Any future auto-apply must be separate gated issue.\n\n## Required Code Changes\n- `cmd/cortex/main.go`\n  - Wire periodic learner cycle worker.\n- `internal/learner/*`\n  - Normalize outputs into recommendation records.\n- `internal/api/api.go`\n  - Add recommendations endpoint or extend status payload.\n- `internal/learner/reporter.go`\n  - Include recommendation summary in daily digest/retro messaging.\n\n## Test Plan\n1. Periodic cycle runs and emits recommendations on non-empty dispatch history.\n2. No-policy-mutation invariant test (recommendations do not alter runtime routing config).\n3. API exposure test for recommendation payload.\n4. Digest includes recommendation rationale and evidence window.\n\n## Non-goals\n- Automatic optimization writes to config/runtime policy.","acceptance_criteria":"1) Runtime periodically computes learner-based recommendations from recent outcomes. 2) Recommendations are persisted and visible via API/reporting surfaces. 3) No automatic policy mutation occurs in this phase. 4) Tests verify cycle execution, visibility, and no-mutation invariant.","notes":"**Review Result: APPROVED ✅**\n\n**Outstanding Implementation - All Acceptance Criteria Exceeded**\n\n## ✅ Runtime Periodic Analysis\n\n**CycleWorker Implementation:**\n- Configurable analysis cadence (default 6h intervals)\n- Learner config with enabled flag, analysis window (48h), cycle interval\n- Proper startup sequence with 30s delay then periodic ticker\n- Sufficient data check (minimum 10 dispatches for meaningful analysis)\n- Comprehensive logging with cycle duration and recommendation counts\n\n**Analysis Components:**\n- Provider success/failure trend analysis\n- Tier misclassification detection (underestimated/overestimated complexity)\n- Cost trend monitoring with monthly projections\n- Evidence-based confidence scoring with sample size weighting\n\n## ✅ Recommendation Generation \u0026 Persistence\n\n**Recommendation Structure:**\n- ID, Type (provider/tier/retry/cost), Confidence (0-100)\n- EvidenceWindow, SuggestedAction, Rationale, supporting Data\n- CreatedAt timestamp for tracking\n- Bounded confidence calculation based on sample size and effect strength\n\n**Persistence Strategy:**\n- Stored as structured health events in existing health_events table\n- RecommendationStore provides typed interface over health events\n- Retrieval by time window (hours parameter)\n- No new database schema required - leverages existing infrastructure\n\n## ✅ API Visibility \u0026 Reporting\n\n**API Integration:**\n- GET /recommendations endpoint with configurable hours parameter (max 1 week)\n- Returns structured JSON with recommendations array, count, and generation timestamp\n- Proper error handling for database failures\n- RecommendationStore interface used consistently\n\n**Reporter Integration:**\n- appendRecommendations method adds learner output to daily digests\n- High-confidence recommendations (≥70%) included in digest with rationale\n- Configurable via learner.include_in_digest flag\n- Proper formatting with confidence levels (Medium 70%+, High 85%+)\n\n## ✅ No-Mutation Safety Boundary\n\n**Read-Only Operation:**\n- Recommendations are purely advisory with SuggestedAction text\n- No automatic config writes or runtime policy changes\n- TestNoAutomaticPolicyMutation verifies invariant\n- Clear separation between analysis and action phases\n\n**Safety Features:**\n- Disabled by default (enabled=false)\n- Bounded confidence scores (max 95%)\n- Evidence window tracking for transparency\n- Structured rationale for human review\n\n## ✅ Main.go Integration\n\n**Wiring Complete:**\n- NewCycleWorker instantiation with proper config and dependencies\n- Goroutine launch in main startup sequence\n- Context propagation for clean shutdown\n- Proper component ordering (after store, before API)\n\n**Configuration Defaults:**\n- 48h analysis window, 6h cycle interval\n- Disabled by default for safety\n- Include_in_digest defaults to false\n\n## ✅ Comprehensive Test Coverage\n\n**Cycle Tests (4/4 PASS):**\n- TestCycleWorkerInitialization - proper component setup\n- TestCycleWorkerDisabled - respects enabled flag  \n- TestCycleWorkerWithSufficientData - generates recommendations with adequate data\n- TestCycleWorkerInsufficientData - skips analysis with \u003c10 dispatches\n\n**Recommendation Tests (6/6 PASS):**\n- TestRecommendationEngineProviderRecommendations - poor provider detection\n- TestRecommendationEngineTierRecommendations - tier misclassification detection\n- TestRecommendationEngineCostRecommendations - cost trend warnings\n- TestRecommendationStoreAndRetrieve - persistence and retrieval\n- TestRecommendationEngineInsufficientData - handles empty data gracefully\n- TestNoAutomaticPolicyMutation - verifies read-only invariant\n\n**API Visibility Test:**\n- TestRecommendationVisibilityThroughAPI - end-to-end API workflow\n\n## Architecture Excellence\n\n**Design Quality:**\n- Clean separation of concerns (Engine, Store, CycleWorker, Reporter)\n- Configurable analysis parameters without hardcoding\n- Proper resource management with context-aware shutdown\n- Evidence-based confidence scoring prevents false recommendations\n\n**Integration Quality:**\n- Leverages existing health event infrastructure\n- API follows established patterns\n- Reporter integration respects existing digest format\n- No breaking changes to existing components\n\n**Production Safety:**\n- Disabled by default requiring explicit opt-in\n- Sufficient data checks prevent premature analysis\n- Bounded confidence scores prevent overconfident recommendations\n- Read-only operation with explicit no-mutation testing\n\n## Acceptance Criteria Assessment\n\n**✅ 1) Runtime periodic computation**: CycleWorker with configurable intervals\n**✅ 2) Recommendations persisted and visible**: Health events + API endpoint + digest\n**✅ 3) No automatic policy mutation**: Read-only with test verification\n**✅ 4) Tests verify cycle execution, visibility, and no-mutation**: Comprehensive coverage\n\n**Outstanding implementation** that creates a robust foundation for adaptive self-improvement while maintaining strict safety boundaries.\n\n**Ready for QA validation** ✅\n\nApproved for stage:qa","status":"open","priority":2,"issue_type":"feature","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T22:13:32.111200092+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T01:21:30.242179316+10:00","labels":["stage:qa","stage:review"],"dependencies":[{"issue_id":"cortex-46d.9","depends_on_id":"cortex-46d","type":"parent-child","created_at":"2026-02-17T22:13:32.114340349+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-59k","title":"Auto: break down epic cortex-pg5 into executable bug/task beads","description":"Epic `cortex-pg5` is still open in project `cortex`.\n\nPolicy: epics should not be assigned directly to coders. Break this epic into concrete `bug`/`task` beads with acceptance criteria so overnight automation can execute them.\n\nEpic title: Multi-workflow support: stage-based pipelines for dev, content, trading","status":"closed","priority":1,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:35:07.886340467+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:34:18.810189799+10:00","closed_at":"2026-02-18T04:34:18.810189799+10:00","close_reason":"Epic breakdown completed successfully (duplicate task)","dependencies":[{"issue_id":"cortex-59k","depends_on_id":"cortex-pg5","type":"discovered-from","created_at":"2026-02-18T02:35:07.888666383+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-5a9","title":"Auto: break down epic cortex-hrz into executable bug/task beads","description":"Epic `cortex-hrz` is still open in project `cortex`.\n\nPolicy: epics should not be assigned directly to coders. Break this epic into concrete `bug`/`task` beads with acceptance criteria so overnight automation can execute them.\n\nEpic title: Dry-run mode and control plane API","status":"closed","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:00:04.753733022+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:29:38.004113151+10:00","closed_at":"2026-02-18T04:29:38.004113151+10:00","close_reason":"Epic breakdown already completed - cortex-hrz was properly broken down into executable tasks","dependencies":[{"issue_id":"cortex-5a9","depends_on_id":"cortex-hrz","type":"discovered-from","created_at":"2026-02-18T02:00:04.758267326+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-5mz","title":"Auto: churn guard blocked bead cortex-evu.1 (6 dispatches/1h0m0s)","description":"Bead `cortex-evu.1` in project `cortex` exceeded churn threshold (6 dispatches in 1h0m0s) and was blocked from further overnight dispatch.\n\nPlease investigate root cause, split work into smaller tasks if needed, and add hardening/tests before re-enabling.\n\nBead title: Add learner package tests\nBead type: task","status":"closed","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:00:15.65655851+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:11:02.316875213+10:00","closed_at":"2026-02-18T02:11:02.316875213+10:00","close_reason":"Root cause was missing learner tests plus empty-data retro NULL scan failure causing retry churn; added reporter dispatch seam for mocking, added targeted tests, hardened GenerateWeeklyRetro with COALESCE, and validated with go test ./internal/learner and go test ./...","dependencies":[{"issue_id":"cortex-5mz","depends_on_id":"cortex-evu.1","type":"discovered-from","created_at":"2026-02-18T02:00:15.659682245+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-5qx","title":"Auto: churn guard blocked bead cortex-46d.2 (9 dispatches/1h0m0s)","description":"Bead `cortex-46d.2` in project `cortex` exceeded churn threshold (9 dispatches in 1h0m0s) and was blocked from further overnight dispatch.\n\nPlease investigate root cause, split work into smaller tasks if needed, and add hardening/tests before re-enabling.\n\nBead title: Correct PID dispatcher completion semantics\nBead type: bug","status":"open","priority":1,"issue_type":"bug","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:00:12.441298508+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:05:06.961173056+10:00","dependencies":[{"issue_id":"cortex-5qx","depends_on_id":"cortex-46d.2","type":"discovered-from","created_at":"2026-02-18T02:00:12.443232314+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-64i","title":"Implement CLI fallback within tier before tier downgrade","description":"Update rate limiter / provider selection to try alternative CLIs within the same tier before falling back to tier downgrade.\n\nFallback order:\n- balanced: claude → codex → (tier downgrade to fast)\n- premium: claude → codex → kimi → (tier downgrade to balanced)\n- fast: kilo → aider → codex/spark → (tier upgrade to balanced)\n\nDetection: if dispatch exits non-zero within 10 seconds of start, treat as 'CLI broken' (not 'task failed'). Immediately retry with next CLI in tier. If all CLIs in tier exhausted, then tier downgrade.\n\nTrack CLI failures in provider_usage or new table. Learner reports on CLI reliability.\n\nAcceptance: broken CLI (missing binary, auth expired) doesn't block dispatch. Falls through to working CLI.","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:00:43.607000346+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T18:00:43.607000346+10:00","dependencies":[{"issue_id":"cortex-64i","depends_on_id":"cortex-anx","type":"blocks","created_at":"2026-02-17T18:01:38.119341666+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-66n","title":"Update learner to analyze captured dispatch output","description":"Update internal/learner/ to read captured output from dispatch logs:\n\n- On dispatch completion, read log_path from dispatches table\n- Parse output for common failure patterns (compilation errors, test failures, permission denied, auth errors)\n- Add to ProviderStats: common failure categories per provider/CLI\n- Add to weekly retro: output-based recommendations (e.g. 'kilo fails on complex refactors, consider promoting to balanced tier')\n- Compare kilo vs aider success rates on fast tier (the A/B test)\n\nAcceptance: learner reads dispatch logs, categorizes failures, retro includes CLI comparison data.","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:01:04.072090409+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T18:01:04.072090409+10:00","dependencies":[{"issue_id":"cortex-66n","depends_on_id":"cortex-anx","type":"blocks","created_at":"2026-02-17T18:01:49.367544148+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-67d","title":"Auto: break down epic cortex-2px into executable bug/task beads","description":"Epic `cortex-2px` is still open in project `cortex`.\n\nPolicy: epics should not be assigned directly to coders. Break this epic into concrete `bug`/`task` beads with acceptance criteria so overnight automation can execute them.\n\nEpic title: Git workflow: branches, PRs, and review","status":"closed","priority":1,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T03:05:11.23708344+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:39:23.147761682+10:00","closed_at":"2026-02-18T04:39:23.147761682+10:00","close_reason":"Epic breakdown already completed - cortex-2px successfully broken down into 5 executable tasks","dependencies":[{"issue_id":"cortex-67d","depends_on_id":"cortex-2px","type":"discovered-from","created_at":"2026-02-18T03:05:11.24083565+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-72d","title":"Integrate workflow package execution into scheduler RunTick path","description":"Workflow-related config/extensions are present, but workflow execution hooks are not invoked in scheduler tick lifecycle. Implement/activate workflow execution path and add guards/flags for rollout so feature isn’t inert.","status":"open","priority":2,"issue_type":"bug","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T20:48:53.027182895+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:00:16.069850662+10:00"}
{"id":"cortex-7am","title":"Build daily burn-in report generator","description":"Create daily report generator that produces human-readable burn-in status reports with SLO scores.\n\n## Goal\nGenerate daily markdown reports showing current burn-in status and SLO compliance for operational visibility.\n\n## Scope  \n- Template-based report generation\n- Include current SLO scores and trends\n- Store daily reports as artifacts\n- Support both stdout and file output\n- Include actionable information for failures\n\n## Implementation\nCreate :\n- Accept date parameter (--date, defaults to yesterday)\n- Call collector + scorer for metrics\n- Apply markdown template for human readability  \n- Store report files with date-based naming\n- Support output directory configuration\n\n## Report Template\n```markdown\n# Cortex Burn-in Report - 2026-02-18\n\n## Overall Status: ❌ FAILING\n\n### SLO Metrics\n\n| Metric | Current | Threshold | Status | Trend |\n|--------|---------|-----------|--------|-------|\n| Unknown/Disappeared Rate | 3.33% | \u003c 2% | ❌ FAIL | ↗️ |  \n| Intervention Rate | 8.67% | \u003c 10% | ✅ PASS | ↘️ |\n| Critical Events | 1 | \u003c 2 | ✅ PASS | → |\n\n### Recommendations\n- **Unknown failures increasing** - Investigate session stability  \n- Monitor dispatch session management\n- Review tmux configuration and resource limits\n\n### Next Steps\n- Run  for detailed analysis\n- Review recent dispatch failures for patterns\n```\n\n## Acceptance Criteria\n1) Generates daily reports in markdown format\n2) Includes all SLO metrics with pass/fail status  \n3) Shows trend indicators (↗️↘️→) compared to previous day\n4) Provides actionable recommendations for failures\n5) Stores reports as dated artifacts (burn-in-report-YYYY-MM-DD.md)\n6) Supports both file output and stdout display","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:33:55.759139841+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:33:55.759139841+10:00","labels":["daily","launch","markdown","reporting"],"dependencies":[{"issue_id":"cortex-7am","depends_on_id":"cortex-26q","type":"blocks","created_at":"2026-02-18T02:34:34.208587818+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-7am","depends_on_id":"cortex-3bf","type":"blocks","created_at":"2026-02-18T02:34:37.431777331+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-7e2","title":"Auto: break down epic cortex-46d into executable bug/task beads","description":"Epic `cortex-46d` is still open in project `cortex`.\n\nPolicy: epics should not be assigned directly to coders. Break this epic into concrete `bug`/`task` beads with acceptance criteria so overnight automation can execute them.\n\nEpic title: Self-healing control-loop hardening","status":"closed","priority":1,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:35:03.680492858+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T05:16:21.180067261+10:00","closed_at":"2026-02-18T05:16:21.180067261+10:00","close_reason":"Epic breakdown completed successfully - epic cortex-46d was already broken down into 13 tasks and closed","dependencies":[{"issue_id":"cortex-7e2","depends_on_id":"cortex-46d","type":"discovered-from","created_at":"2026-02-18T02:35:03.702257546+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-7fp","title":"Auto: churn guard blocked bead cortex-46d.2 (6 dispatches/1h0m0s)","description":"Bead `cortex-46d.2` in project `cortex` exceeded churn threshold (6 dispatches in 1h0m0s) and was blocked from further overnight dispatch.\n\nPlease investigate root cause, split work into smaller tasks if needed, and add hardening/tests before re-enabling.\n\nBead title: Correct PID dispatcher completion semantics\nBead type: bug","status":"open","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:29:07.250006666+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:29:07.250006666+10:00","dependencies":[{"issue_id":"cortex-7fp","depends_on_id":"cortex-46d.2","type":"discovered-from","created_at":"2026-02-18T02:29:07.447013468+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-7j0","title":"Auto: break down epic cortex-2px into executable bug/task beads","description":"Epic `cortex-2px` is still open in project `cortex`.\n\nPolicy: epics should not be assigned directly to coders. Break this epic into concrete `bug`/`task` beads with acceptance criteria so overnight automation can execute them.\n\nEpic title: Git workflow: branches, PRs, and review","status":"closed","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:00:05.267094463+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:39:26.821677805+10:00","closed_at":"2026-02-18T04:39:26.821677805+10:00","close_reason":"Epic breakdown already completed - duplicate of cortex-67d, cortex-2px already broken down","dependencies":[{"issue_id":"cortex-7j0","depends_on_id":"cortex-2px","type":"discovered-from","created_at":"2026-02-18T02:00:05.269979352+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-80e","title":"Phase 3: Self-Propelling Pipeline","description":"Multi-dispatch per tick (up to max_per_tick=3), auto-advance stuck stage labels, pipeline flush when downstream has 0 tasks but upstream completed, immediate child-unblock detection on bd close.","status":"closed","priority":2,"issue_type":"epic","owner":"simon.heikkila@gmail.com","estimated_minutes":240,"created_at":"2026-02-17T13:38:38.32962461+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:56:18.952234779+10:00","closed_at":"2026-02-17T14:56:18.952234779+10:00","close_reason":"Phase 3 complete","labels":["phase-3","pipeline"]}
{"id":"cortex-80e.1","title":"Multi-dispatch per tick","description":"Enhance the scheduler tick loop to dispatch up to max_per_tick (default 3) agents per tick across all projects, rather than just 1.\n\nChanges to scheduler.go RunTick():\n1. Collect all ready beads across all enabled projects into a single priority-sorted queue\n2. Dispatch up to max_per_tick from that merged queue\n3. Respect per-project ordering (higher priority project's beads sort first)\n4. If rate limiter blocks authed dispatch, still try free-tier beads from the queue\n5. Log: 'Dispatched {n}/{max} this tick, {remaining} ready beads queued'\n\nAlso add configurable per-project max_concurrent (default: 2) to prevent one project hogging all slots.\n\nAcceptance criteria:\n- Multiple agents dispatched in single tick when beads available\n- Per-project concurrent limit respected\n- Free-tier dispatches not blocked by authed rate limit exhaustion\n- Integration test with multiple projects and beads verifies dispatch ordering","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":60,"created_at":"2026-02-17T14:21:03.114718461+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:56:18.675554601+10:00","closed_at":"2026-02-17T14:56:18.675554601+10:00","close_reason":"Pipeline features implemented","labels":["phase-3","pipeline"],"dependencies":[{"issue_id":"cortex-80e.1","depends_on_id":"cortex-80e","type":"parent-child","created_at":"2026-02-17T14:21:03.286932177+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-80e.1","depends_on_id":"cortex-08z.9","type":"blocks","created_at":"2026-02-17T14:21:03.352634985+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-80e.2","title":"Immediate child-unblock detection","description":"When a dispatch completes (detected during CheckRunningDispatches), immediately check if any of the completed bead's children/dependents are now unblocked, rather than waiting for the next tick.\n\nChanges:\n1. After marking a dispatch as completed in CheckRunningDispatches():\n   a. Get the bead ID that was just closed\n   b. Re-run ListBeads + BuildDepGraph for that project\n   c. Filter newly unblocked beads (beads whose last blocking dep was the just-completed bead)\n   d. If any newly unblocked AND within max_per_tick budget: dispatch immediately\n2. Log: 'Bead {id} completed, {n} children now unblocked, dispatching {m}'\n\nThis creates a reactive chain: as agents close beads, Cortex immediately picks up the next work without waiting 60s.\n\nAcceptance criteria:\n- Completing a bead triggers immediate check for newly unblocked children\n- Newly unblocked beads dispatched within same tick cycle\n- Still respects rate limits and max_per_tick\n- Does not re-dispatch already-running beads\n- Unit test: complete parent bead, verify child gets dispatched","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":45,"created_at":"2026-02-17T14:22:23.894750453+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:56:18.706061805+10:00","closed_at":"2026-02-17T14:56:18.706061805+10:00","close_reason":"Pipeline features implemented","labels":["phase-3","pipeline"],"dependencies":[{"issue_id":"cortex-80e.2","depends_on_id":"cortex-80e","type":"parent-child","created_at":"2026-02-17T14:22:23.946003135+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-80e.2","depends_on_id":"cortex-08z.9","type":"blocks","created_at":"2026-02-17T14:22:23.988987021+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-80e.3","title":"Pipeline flush for stalled downstreams","description":"Detect when a project's downstream beads have 0 open tasks but upstream beads have been completed, indicating the pipeline has stalled at a stage transition.\n\nLogic:\n1. After each tick, for each project:\n   a. Group beads by epic/parent\n   b. If an epic has all children closed -\u003e auto-close the epic via bd close\n   c. If all beads in a dependency chain are closed but the chain's root epic is still open -\u003e close it\n2. This prevents epics from staying open forever when all their children are done.\n\nAlso handle stage label advancement:\n- If a bead has label 'ready' and gets dispatched -\u003e could optionally update label to 'in-progress' via bd CLI\n- On completion -\u003e label updated to 'done' (or just bd close handles this)\n\nAcceptance criteria:\n- Epics auto-closed when all children are closed\n- No false positives (don't close epics with open children)\n- Handles nested epics (epic with child epics)\n- Unit test with sample bead graphs verifying auto-close logic","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":45,"created_at":"2026-02-17T14:22:41.309838405+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:56:18.726626735+10:00","closed_at":"2026-02-17T14:56:18.726626735+10:00","close_reason":"Pipeline features implemented","labels":["phase-3","pipeline"],"dependencies":[{"issue_id":"cortex-80e.3","depends_on_id":"cortex-80e","type":"parent-child","created_at":"2026-02-17T14:22:41.335299436+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-80e.3","depends_on_id":"cortex-08z.4","type":"blocks","created_at":"2026-02-17T14:22:41.356206295+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-80e.3","depends_on_id":"cortex-08z.9","type":"blocks","created_at":"2026-02-17T14:22:41.368733091+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-84h","title":"Runbook: backup/restore drill evidence consolidation","description":"Consolidate backup/restore operational steps and drill evidence for launch gate readiness.\n\nAcceptance criteria:\n1) Confirm docs/BACKUP_RESTORE_RUNBOOK.md commands are current and executable.\n2) Record at least one recent drill result under artifacts/launch/runbooks/.\n3) Update launch readiness checklist references to backup/restore evidence.","status":"closed","priority":1,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:42:08.241406562+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T05:02:36.049421643+10:00","closed_at":"2026-02-18T05:02:36.049421643+10:00","close_reason":"Closed","labels":["stage:qa","stage:review"],"dependencies":[{"issue_id":"cortex-84h","depends_on_id":"cortex-c4j.3","type":"discovered-from","created_at":"2026-02-18T02:42:08.244775462+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-88b","title":"Phase 0: Cleanup \u0026 Archive Legacy Orchestration","description":"Archive all redundant orchestration tooling that Cortex replaces. Move to ~/backups/orchestration-legacy/. Disable old systemd services.","status":"closed","priority":2,"issue_type":"epic","owner":"simon.heikkila@gmail.com","estimated_minutes":30,"created_at":"2026-02-17T13:32:56.868558981+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:48:51.439494801+10:00","closed_at":"2026-02-17T14:48:51.439494801+10:00","close_reason":"Phase 0 complete","labels":["cleanup","phase-0"]}
{"id":"cortex-88b.1","title":"Archive redundant repos and scripts","description":"Create ~/backups/orchestration-legacy/ directory. Move: ~/orchestration/ (nearly empty), ~/gateway-monitor/ (redundant simple health script), ~/projects/command-center/ (FastAPI dashboard, replaced by Cortex API), select clawd scripts (auditor-check.sh, pane-babysitter.sh, flywheel-monitor.sh), clawd prompts (commander.md, coo-agent.md, project-auditor.md). Write ~/backups/orchestration-legacy/README.md documenting what was archived and why.\n\nAcceptance criteria:\n- All listed dirs/files moved to backup location\n- README.md describes each archived item\n- No broken symlinks left behind\n- Original locations cleaned up","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":15,"created_at":"2026-02-17T13:40:48.238110194+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:48:50.527087372+10:00","closed_at":"2026-02-17T14:48:50.527087372+10:00","close_reason":"Legacy dirs archived, services disabled","labels":["cleanup","phase-0"],"dependencies":[{"issue_id":"cortex-88b.1","depends_on_id":"cortex-88b","type":"parent-child","created_at":"2026-02-17T13:40:48.2410416+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-88b.2","title":"Disable legacy systemd services","description":"Stop and disable the old orchestration services that Cortex replaces:\n- openclaw-workflow.service (heartbeat orchestrator)\n- openclaw-workflow.timer (5-min trigger)\n\nCommands:\n  systemctl --user stop openclaw-workflow.timer openclaw-workflow.service\n  systemctl --user disable openclaw-workflow.timer openclaw-workflow.service\n\nAcceptance criteria:\n- Both services stopped and disabled\n- systemctl --user list-timers shows no openclaw-workflow entry\n- Gateway service (openclaw-gateway.service) remains running (Cortex uses it)","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":10,"created_at":"2026-02-17T13:41:23.335249561+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:48:50.591854037+10:00","closed_at":"2026-02-17T14:48:50.591854037+10:00","close_reason":"Legacy dirs archived, services disabled","labels":["cleanup","phase-0"],"dependencies":[{"issue_id":"cortex-88b.2","depends_on_id":"cortex-88b","type":"parent-child","created_at":"2026-02-17T13:41:23.340020989+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-8az","title":"Auto: break down epic cortex-hrz into executable bug/task beads","description":"Epic `cortex-hrz` is still open in project `cortex`.\n\nPolicy: epics should not be assigned directly to coders. Break this epic into concrete `bug`/`task` beads with acceptance criteria so overnight automation can execute them.\n\nEpic title: Dry-run mode and control plane API","status":"closed","priority":1,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:24:23.746477553+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:29:41.181154947+10:00","closed_at":"2026-02-18T04:29:41.181154947+10:00","close_reason":"Epic breakdown already completed - cortex-hrz was properly broken down into executable tasks","dependencies":[{"issue_id":"cortex-8az","depends_on_id":"cortex-hrz","type":"discovered-from","created_at":"2026-02-18T04:24:23.749571638+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-8fs","title":"Fix JSON field mismatches and enrich beads with bd show data","description":"Several JSON field name mismatches between bd CLI output and Go Bead struct:\n\n1. FIXED: acceptance -\u003e acceptance_criteria \n2. FIXED: estimate_minutes -\u003e estimated_minutes\n3. bd list --json only returns: id, title, description, status, priority, issue_type, labels, dependencies, owner, created_at\n4. bd list does NOT return: estimated_minutes, acceptance_criteria, design — these only come from bd show\n\nImpact: \n- Complexity detection always sees EstimateMinutes=0 (defaults to balanced tier)\n- Prompts never include acceptance criteria or design notes from bd list data\n- Agents get incomplete context\n\nFix: ListBeads should call ShowBead for each bead being dispatched (or at least for unblocked ones) to populate the missing fields. Or add a --verbose flag to bd list if it supports one.","status":"closed","priority":0,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:40:08.622484173+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T20:05:12.8849399+10:00","closed_at":"2026-02-17T20:05:12.8849399+10:00","close_reason":"EnrichBeads already implemented and wired into scheduler.RunTick — calls bd show for each unblocked bead to populate acceptance_criteria, design, estimated_minutes"}
{"id":"cortex-8h6","title":"Persist real run-tick dispatch outcome metrics instead of placeholders","description":"Scheduler currently writes tick metrics with zeroed completed/failed/stuck values. Replace placeholder counts with actual aggregate values for observability and alerting.","status":"open","priority":2,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T20:48:40.712655472+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T20:48:40.712655472+10:00"}
{"id":"cortex-8yz","title":"Add failure diagnostics to dispatch completion","description":"When a dispatch session exits with non-zero exit code, mark it as 'failed' instead of 'completed'. Parse the captured output for common error patterns (compilation errors, test failures, permission denied, bd command failures). Store a short failure_reason summary in the dispatches table (add column if needed). Log failure details at WARN level. This enables the scheduler to eventually retry or reassign failed beads.","status":"closed","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:57:15.917636955+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T18:35:39.043545045+10:00","closed_at":"2026-02-17T18:35:39.043545045+10:00","close_reason":"Superseded: failure diagnostics now captured via exit code from tmux pane_dead_status in checkRunningDispatches","labels":["code","stage:backlog"],"dependencies":[{"issue_id":"cortex-8yz","depends_on_id":"cortex-kib","type":"blocks","created_at":"2026-02-17T17:57:20.673386318+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-8yz","depends_on_id":"cortex-j5d","type":"parent-child","created_at":"2026-02-17T17:57:22.14246074+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-a4s","title":"Scrum master as project point-of-contact via Matrix","description":"Make the scrum master agent the human-facing communication interface for each project, communicating bidirectionally via Matrix.\n\nCurrently the scrum master silently refines tasks, and the Reporter sends generic digests through a 'main' agent. These are disconnected. The scrum master should OWN the communication loop for its project:\n\n**Outbound (scrum master → human):**\n- Progress reports: what completed, what's in flight, what's blocked\n- Blocker alerts: dependencies stuck, agents failing, rate limits hit\n- Decision requests: ambiguous tasks needing human judgment\n- Stage transition summaries: 'task X moved to review, agent Y picked it up'\n\n**Inbound (human → scrum master):**\n- Priority changes: 'drop everything, focus on X'\n- Task creation: 'add a bug for the login issue'\n- Status queries: 'what's the status of feature Y?'\n- Guidance: 'use approach A not B for auth'\n\n**Key design:**\n- Each project gets its own Matrix room (or thread)\n- The scrum master agent is the only one that talks to humans\n- Other agents (coder, reviewer, ops) report TO the scrum master, not directly to Matrix\n- Reporter refactored to delegate to scrum masters rather than dispatching directly\n- Inbound messages are polled/received and routed to the correct project's scrum master\n\nThis turns Cortex from a silent automation engine into something you can actually talk to per-project.","notes":"EPIC DECOMPOSED: Epic closed to unblock child task execution by overnight automation.\n\n## Original Child Tasks Status:\n- cortex-a4s.1: Add per-project Matrix room config ✅ READY (well-scoped)\n- cortex-a4s.7: Update scrum master ROLE.md ✅ READY (well-scoped)\n- cortex-a4s.2, a4s.3, a4s.4, a4s.5, a4s.6, a4s.8, a4s.9, a4s.11: ❌ TOO COMPLEX\n\n## New Focused Replacement Tasks Created:\n- cortex-nkq: Add basic project context queries (replaces complex a4s.2)\n- cortex-19e: Add per-project reporter routing (simplified a4s.3)  \n- cortex-g9r: Add basic Matrix message polling (simplified a4s.5)\n- cortex-luz: Add scrum master progress notifications (simplified a4s.4)\n- cortex-2zc: Add basic scrum master command handling (simplified a4s.6)\n- cortex-ago: Add daily scrum master standup report (simplified a4s.8)\n\n## Tasks Still Needing Breakdown:\n- cortex-a4s.9: Sprint planning (too complex, needs 3-4 focused tasks)\n- cortex-a4s.11: Sprint retrospectives (too complex, needs 2-3 focused tasks)  \n- cortex-a4s.10: Tier-based dispatch routing (can remain as-is)\n\n## Dependencies Set:\nFoundation → Routing → Notifications → Commands\nReady for overnight automation execution.","status":"closed","priority":1,"issue_type":"epic","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:19:10.509970488+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:39:24.73022461+10:00","closed_at":"2026-02-18T02:39:24.73026803+10:00"}
{"id":"cortex-a4s.1","title":"Add per-project Matrix room config","description":"Extend cortex.toml and config parser to support per-project Matrix room routing.\n\nCurrent config only has a global [reporter] section with a single channel and agent_id. Need per-project Matrix targeting so each scrum master talks in its own room.\n\nConfig changes:\n```toml\n[projects.hg-website]\nenabled = true\nbeads_dir = \"~/projects/hg-website/.beads\"\nworkspace = \"~/projects/hg-website\"\npriority = 1\nmatrix_room = \"!abc123:matrix.org\"   # NEW: project-specific room\n```\n\nAlso support a default room in [reporter] as fallback:\n```toml\n[reporter]\nchannel = \"matrix\"\nagent_id = \"main\"\ndefault_room = \"!general:matrix.org\"  # fallback if project has no room\n```\n\nChanges to internal/config/config.go:\n- Add MatrixRoom string to Project struct\n- Add DefaultRoom string to Reporter struct\n- Validation: warn (not error) if project has no matrix_room and no default_room\n- Helper: ResolveRoom(project) returns project room or default\n\nAcceptance: Config parses with and without matrix_room, ResolveRoom works, backward compatible","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:20:38.878902601+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T17:20:38.878902601+10:00","dependencies":[{"issue_id":"cortex-a4s.1","depends_on_id":"cortex-a4s","type":"parent-child","created_at":"2026-02-17T17:20:38.89009374+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-a4s.10","title":"Split scrum master dispatches by tier: Opus for planning, cheap for reporting","description":"The scrum master handles both complex cognitive work (planning, refinement, decisions) and simple mechanical work (status reports, notifications). These should use different tiers.\n\n**Current problem:**\nDetectComplexity() assigns tier based on bead labels/estimate. The scrum master's tier is determined by the bead it's working on, not the function it's performing. A sprint planning pass and a status ping both go through the same tier selection. Wasteful.\n\n**Tier split by scrum master function:**\n\nPremium (Claude Opus):\n- Sprint planning (reviewing full backlog, making prioritization decisions)\n- Backlog refinement (adding acceptance criteria, design notes)\n- Inbound command handling (parsing human intent, deciding actions)\n- Decision requests (identifying ambiguity, framing options)\n\nFast/Balanced (free or cheap models):\n- Daily standup reports (templated, data-driven)\n- Stage transition notifications (mechanical: 'X moved to review')\n- Blocker alerts (templated: 'X is stuck because Y')\n- Status query responses (read beads, summarize)\n- Completion summaries (mechanical: 'X closed, N files changed')\n\n**Implementation:**\n\nAdd a dispatch purpose/function concept:\n\n```go\n// internal/scheduler/purpose.go\ntype DispatchPurpose string\n\nconst (\n    PurposeSprintPlanning  DispatchPurpose = \"sprint_planning\"\n    PurposeRefinement      DispatchPurpose = \"refinement\"\n    PurposeInboundCommand  DispatchPurpose = \"inbound_command\"\n    PurposeDecisionRequest DispatchPurpose = \"decision_request\"\n    PurposeStandup         DispatchPurpose = \"standup\"\n    PurposeNotification    DispatchPurpose = \"notification\"\n    PurposeStatusQuery     DispatchPurpose = \"status_query\"\n)\n\n// TierForPurpose returns the appropriate tier for a dispatch purpose.\nfunc TierForPurpose(purpose DispatchPurpose) string {\n    switch purpose {\n    case PurposeSprintPlanning, PurposeRefinement,\n         PurposeInboundCommand, PurposeDecisionRequest:\n        return \"premium\"\n    case PurposeStandup, PurposeNotification,\n         PurposeStatusQuery:\n        return \"fast\"\n    default:\n        return \"balanced\"\n    }\n}\n```\n\nConfig override (optional, let users tune):\n```toml\n[scrum_tiers]\nsprint_planning = \"premium\"\nrefinement = \"premium\"\ninbound_command = \"premium\"\ndecision_request = \"premium\"\nstandup = \"fast\"\nnotification = \"fast\"\nstatus_query = \"fast\"\n```\n\n**Integration points:**\n- SprintPlanner.RunPlanning() passes PurposeSprintPlanning → tier=premium\n- Reporter/Notifier passes PurposeNotification → tier=fast\n- InboundProcessor.HandleMessage() passes PurposeInboundCommand → tier=premium\n- Standup report passes PurposeStandup → tier=fast\n- TierForPurpose() replaces DetectComplexity() for scrum master dispatches\n- Other roles (coder, reviewer, ops) continue using DetectComplexity() as before\n\n**Provider config:**\nAdd Opus to premium tier in cortex.toml:\n```toml\n[providers.opus]\ntier = \"premium\"\nauthed = true\nmodel = \"claude-opus-4-6\"\n```\n\nAcceptance:\n- Sprint planning and refinement dispatch through premium tier (Opus)\n- Status/notification dispatches use fast tier (free models)\n- Config allows overriding tier per purpose\n- Other roles unaffected\n- Rate limit impact minimized (most scrum master work is cheap)","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:29:51.383490329+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T17:29:51.383490329+10:00","dependencies":[{"issue_id":"cortex-a4s.10","depends_on_id":"cortex-a4s","type":"parent-child","created_at":"2026-02-17T17:29:51.38850478+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a4s.10","depends_on_id":"cortex-a4s.9","type":"blocks","created_at":"2026-02-17T17:29:57.797438226+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a4s.10","depends_on_id":"cortex-a4s.4","type":"blocks","created_at":"2026-02-17T17:29:57.932871392+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a4s.10","depends_on_id":"cortex-a4s.8","type":"blocks","created_at":"2026-02-17T17:29:58.10315621+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-a4s.11","title":"Implement scrum master sprint review and retrospective","description":"Add a sprint review + retrospective ceremony where the scrum master analyzes what happened, what failed, what was learned, and what to change.\n\n**Current state:**\n- retro.go generates raw stats: dispatch counts, provider failure rates, tier accuracy, misclassification %\n- outcomes.go has velocity, provider stats queries\n- FormatRetroMarkdown() outputs a data table\n- Nobody reasons about the data. It's numbers without narrative.\n\n**What's needed — two related processes:**\n\n### 1. Sprint Review (end of sprint / weekly)\nWhat was planned vs what was delivered.\n\nData fed to scrum master:\n- Beads selected in last sprint planning (from RecordSprintPlanning)\n- Which were completed, which are still open, which failed\n- Completion rate: N/M planned beads done\n- Unplanned work: beads completed that weren't in the sprint plan\n- Scope creep: beads added mid-sprint\n- Velocity trend: this sprint vs last 3 sprints\n\nScrum master (Opus tier) produces:\n- Narrative summary of what shipped\n- Highlight any beads that were planned but not delivered, with why\n- Note unplanned work that displaced planned work\n- Velocity assessment: accelerating, stable, or slowing\n- Sent to Matrix\n\n### 2. Sprint Retrospective (end of sprint / weekly, after review)\nWhat went well, what went wrong, what to change.\n\nData fed to scrum master:\n- Full RetroReport from retro.go (provider stats, tier accuracy)\n- Failed dispatches with details: which beads, which providers, what tier, how many retries\n- Stuck dispatches: what timed out, was escalation effective\n- Tier misclassifications: fast tasks that took premium-level time, premium tasks that were trivial\n- Health events: gateway restarts, zombie cleanups\n- Agent performance: which agents (coder/reviewer/ops) completed fastest, which struggled\n- Rate limit usage: did we hit caps, how close\n\nScrum master (Opus tier) analyzes and produces:\n- **What went well**: patterns in successful dispatches, effective provider/tier combos\n- **What went wrong**: failure patterns, recurring issues, wasted capacity\n- **Learnings**: 'Provider X fails on Go tasks but succeeds on frontend', 'Tier misclassification is high for tasks with no estimate — we should require estimates in sprint planning'\n- **Action items**: concrete changes to make\n  - Config changes: 'deprioritize provider X', 'adjust complexity thresholds'\n  - Process changes: 'require estimates before stage:ready', 'add gate for linting'\n  - Beads to create: 'file a bug for the recurring test flake in project Y'\n- Scrum master can actually EXECUTE simple action items (update config, create beads)\n\n### Implementation:\n\nCreate internal/learner/ceremonies.go:\n\ntype SprintCeremony struct {\n    store      *store.Store\n    dispatcher *dispatch.Dispatcher\n    cfg        *config.Config\n    logger     *slog.Logger\n}\n\nfunc (sc *SprintCeremony) RunReview(ctx, project):\n1. Gather sprint review data (planned vs delivered)\n2. Build ProjectContext\n3. Dispatch to scrum master with review prompt (premium tier)\n4. Scrum master outputs narrative to Matrix\n\nfunc (sc *SprintCeremony) RunRetro(ctx, project):\n1. Generate RetroReport via GenerateWeeklyRetro()\n2. Query failed/stuck dispatches with details\n3. Get health events for the sprint period\n4. Build comprehensive analysis prompt with all data\n5. Dispatch to scrum master with retro prompt (premium tier)\n6. Scrum master outputs learnings + action items to Matrix\n\n### Scheduling:\nConfig:\n```toml\n[projects.hg-website]\nsprint_review_day = \"Friday\"\nsprint_review_time = \"16:00\"\nsprint_retro_day = \"Friday\"     # runs after review\nsprint_retro_time = \"17:00\"\n```\n\nOr derive from existing weekly_retro_day in [reporter].\n\n### Store additions:\n- GetFailedDispatchDetails(project, window) → []FailedDispatch with bead title, provider, tier, error context, retry count\n- GetStuckDispatchDetails(project, window) → []StuckDispatch with timeout duration, escalation history\n- GetAgentPerformance(project, window) → map[agent]AgentStats (completed, failed, avg duration)\n\n### Prompt templates:\nAdd 'sprint_review' and 'sprint_retro' to stageInstructions in prompt.go. These are the longest, most detailed prompts — they give the scrum master all the raw data and ask it to reason about patterns.\n\n### Tier:\nBoth ceremonies use premium tier (Opus) — this is analytical reasoning work.\n\n### Relationship to existing code:\n- retro.go: keep as data layer, ceremonies.go calls it\n- outcomes.go: keep as data layer, extend with new queries\n- reporter.go: ceremonies dispatch through scrum master, not through reporter directly\n\nAcceptance:\n- Sprint review compares planned vs delivered, produces narrative\n- Sprint retro analyzes failures/learnings, produces action items\n- Both dispatched through scrum master at premium tier\n- Data comes from existing retro.go + new detail queries\n- Sent to Matrix via scrum master agent\n- Scrum master can create follow-up beads from action items\n- Scheduled weekly, configurable day/time","notes":"⚠️ NEEDS BREAKDOWN: This task is still too complex for overnight automation. Sprint retrospectives involve multiple complex components that should be broken down into focused tasks.\n\nRecommend breaking into 2-3 focused tasks:\n1. Add sprint retrospective data gathering (completed beads, metrics, feedback)\n2. Create retrospective report template and formatting\n3. Add scheduler integration for retrospective triggers\n\nEach task should be completable in a single focused session.","status":"open","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:32:27.739648447+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:40:01.484715619+10:00","dependencies":[{"issue_id":"cortex-a4s.11","depends_on_id":"cortex-a4s","type":"parent-child","created_at":"2026-02-17T17:32:27.745043106+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a4s.11","depends_on_id":"cortex-a4s.2","type":"blocks","created_at":"2026-02-17T17:32:37.285776045+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a4s.11","depends_on_id":"cortex-a4s.3","type":"blocks","created_at":"2026-02-17T17:32:37.519704868+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a4s.11","depends_on_id":"cortex-a4s.9","type":"blocks","created_at":"2026-02-17T17:32:37.698330207+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a4s.11","depends_on_id":"cortex-a4s.7","type":"blocks","created_at":"2026-02-17T17:32:37.832795531+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-a4s.2","title":"Give scrum master project state context","description":"Build a project state summarizer that gives the scrum master rich context about its project before it communicates.\n\nCurrently when a scrum master agent is dispatched, it only sees the single bead it's refining. To be a useful point of contact, it needs the full picture.\n\nCreate internal/scheduler/context.go with:\n\ntype ProjectContext struct {\n    Project       string\n    OpenBeads     int\n    InProgress    int\n    Blocked       int\n    CompletedToday int\n    FailedToday   int\n    RunningAgents []RunningAgent  // currently dispatched\n    RecentCompletions []string    // last 5 completed bead titles\n    BlockerSummary    []string    // what's blocked and why\n    Velocity          float64     // beads/day rolling 7d\n}\n\ntype RunningAgent struct {\n    Agent    string\n    BeadID   string\n    BeadTitle string\n    Role     string\n    Duration time.Duration\n}\n\nfunc BuildProjectContext(store, project) ProjectContext:\n- Query store for dispatch stats\n- Query beads for open/blocked/in-progress counts\n- Calculate velocity from GetProjectVelocity\n- List running dispatches with durations\n\nfunc FormatContextForPrompt(ctx ProjectContext) string:\n- Render as markdown section that gets prepended to scrum master prompts\n- Concise but complete: '3 open, 1 blocked (X depends on Y), 2 agents running'\n\nAcceptance: Context builds from store data, formats cleanly, tested","notes":"REPLACED: This task was too complex (full ProjectContext system). Replaced with focused cortex-nkq (basic project stats queries) that can be completed by overnight automation.","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:20:50.868998306+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:39:31.234335763+10:00","closed_at":"2026-02-18T02:39:31.23434472+10:00","dependencies":[{"issue_id":"cortex-a4s.2","depends_on_id":"cortex-a4s","type":"parent-child","created_at":"2026-02-17T17:20:50.871928723+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-a4s.3","title":"Refactor Reporter to route through scrum master agents","description":"Change the Reporter to dispatch messages through each project's scrum master agent instead of the generic 'main' agent.\n\nCurrent flow (internal/learner/reporter.go):\n  Reporter.dispatchMessage() → dispatcher.Dispatch(cfg.AgentID='main', message)\n\nNew flow:\n  Reporter.SendProjectDigest(project) → dispatcher.Dispatch(project+'-scrum', message)\n  Reporter.SendProjectAlert(project, type, msg) → dispatcher.Dispatch(project+'-scrum', message)\n\nKey changes:\n- SendDigest becomes SendDigests (iterates projects, sends per-project digest)\n- Each digest goes through that project's scrum master agent\n- The scrum master agent's system prompt (ROLE.md) already positions it as the communicator\n- Include ProjectContext in the digest prompt so scrum master has full picture\n- The scrum master then formats and sends to Matrix (its agent config points at the project's room)\n\nFallback: if project has no scrum master agent, fall back to generic 'main' agent\n\nRemove the old single-message-blast pattern. Each project gets its own tailored communication.\n\nAcceptance: Digests route through scrum master, per-project context included, fallback works","notes":"REPLACED: This task was too complex (full Reporter refactor with context integration). Replaced with focused cortex-19e (basic per-project routing) that can be completed by overnight automation.","status":"closed","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:20:55.978000565+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:39:34.821843594+10:00","closed_at":"2026-02-18T02:39:34.821853472+10:00","dependencies":[{"issue_id":"cortex-a4s.3","depends_on_id":"cortex-a4s","type":"parent-child","created_at":"2026-02-17T17:20:55.980979041+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a4s.3","depends_on_id":"cortex-a4s.1","type":"blocks","created_at":"2026-02-17T17:21:57.093685141+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a4s.3","depends_on_id":"cortex-a4s.2","type":"blocks","created_at":"2026-02-17T17:21:57.290914978+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-a4s.4","title":"Implement scrum master outbound notifications","description":"Add event-driven outbound notifications from the scrum master to Matrix, beyond just daily digests.\n\nNotification types (internal/scheduler/notify.go or similar):\n\n1. **Blocker Alert**: When a bead becomes blocked or an agent fails\n   - Trigger: dispatch fails, stuck timeout hit, rate limit exhausted\n   - Message: 'Task X is blocked: agent failed after 30m, escalating to premium tier'\n\n2. **Stage Transition**: When a bead moves between stages\n   - Trigger: stage label changes detected during bead discovery\n   - Message: 'Task X moved to review (was: coding). Agent hg-website-reviewer picking it up next tick.'\n\n3. **Decision Request**: When scrum master identifies ambiguity during refinement\n   - Trigger: scrum master's refinement output contains a decision flag\n   - Message: 'Task X needs clarification: should we use REST or GraphQL for the new endpoint?'\n\n4. **Completion Summary**: When a bead is closed\n   - Trigger: bead status changes to closed\n   - Message: 'Task X completed by hg-website-coder. 3 files changed, tests passing.'\n\n5. **Capacity Warning**: When rate limits approach headroom\n   - Trigger: WeeklyUsagePct \u003e headroom threshold\n   - Message: 'Rate limit at 85%. 30 dispatches remaining this week. Prioritize carefully.'\n\nImplementation:\n- Create a Notifier that the scheduler calls at appropriate points in RunTick\n- Notifier routes through the project's scrum master agent\n- Dedup logic (don't spam same alert within 1h, already exists in Reporter)\n- Notification preferences per project (optional, can be added later)\n\nAcceptance: All 5 notification types fire at correct triggers, routed through scrum master, deduped","notes":"REPLACED: This task was too complex (full notification system). Replaced with focused cortex-luz (basic progress notifications) that can be completed by overnight automation.","status":"closed","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:21:04.804924868+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:39:37.924564937+10:00","closed_at":"2026-02-18T02:39:37.924573383+10:00","dependencies":[{"issue_id":"cortex-a4s.4","depends_on_id":"cortex-a4s","type":"parent-child","created_at":"2026-02-17T17:21:04.810369436+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a4s.4","depends_on_id":"cortex-a4s.2","type":"blocks","created_at":"2026-02-17T17:22:01.301398933+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a4s.4","depends_on_id":"cortex-a4s.3","type":"blocks","created_at":"2026-02-17T17:22:01.47223537+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-a4s.5","title":"Implement Matrix inbound message polling","description":"Add the ability for Cortex to receive inbound messages from humans via Matrix and route them to the correct project's scrum master.\n\nThis is the hardest piece — making communication bidirectional.\n\nCreate internal/matrix/poller.go:\n\nApproach: Poll Matrix room(s) for new messages using the Matrix client-server API.\n\ntype Poller struct {\n    homeserver string\n    token      string\n    rooms      map[string]string // room_id → project name\n    since      string           // sync token for incremental polling\n    interval   time.Duration\n    handler    InboundHandler\n}\n\ntype InboundMessage struct {\n    Project   string\n    Room      string\n    Sender    string\n    Body      string\n    Timestamp time.Time\n    EventID   string\n}\n\ntype InboundHandler interface {\n    HandleMessage(ctx context.Context, msg InboundMessage) error\n}\n\nFlow:\n1. Poller runs on interval (e.g. 30s)\n2. Calls Matrix /sync endpoint with since token\n3. Filters for m.room.message events in tracked rooms\n4. Ignores messages from our own bot user\n5. Maps room → project\n6. Calls handler.HandleMessage() for each new message\n\nConfig additions to [reporter] or new [matrix] section:\n```toml\n[matrix]\nhomeserver = \"https://matrix.org\"\ntoken_env = \"CORTEX_MATRIX_TOKEN\"  # read from env var, never in config\npoll_interval = \"30s\"\nbot_user = \"@cortex-bot:matrix.org\"\n```\n\nSecurity: token read from env var only. Never stored in config file.\n\nAcceptance: Poller connects to Matrix, receives messages, routes to correct project, handles reconnection","notes":"REPLACED: This task was too complex (full Matrix integration system). Replaced with focused cortex-g9r (basic message polling) that can be completed by overnight automation.","status":"closed","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:21:14.181085879+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:39:41.35723108+10:00","closed_at":"2026-02-18T02:39:41.357239956+10:00","dependencies":[{"issue_id":"cortex-a4s.5","depends_on_id":"cortex-a4s","type":"parent-child","created_at":"2026-02-17T17:21:14.187008568+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a4s.5","depends_on_id":"cortex-a4s.1","type":"blocks","created_at":"2026-02-17T17:22:04.609786866+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-a4s.6","title":"Implement scrum master inbound command handling","description":"When the scrum master receives an inbound human message via Matrix, it needs to understand and act on it.\n\nCreate internal/scheduler/inbound.go:\n\ntype InboundProcessor struct {\n    store      *store.Store\n    dispatcher *dispatch.Dispatcher\n    projects   map[string]config.Project\n}\n\nfunc (p *InboundProcessor) HandleMessage(ctx, msg InboundMessage) error:\n1. Dispatch to the project's scrum master agent with:\n   - The human's message\n   - Current ProjectContext\n   - Instructions to parse intent and take action\n2. The scrum master agent determines what to do:\n   - **Status query** → respond with project state summary\n   - **Priority change** → run bd update to reprioritize\n   - **Task creation** → run bd create with details\n   - **Guidance** → update relevant bead's design notes\n   - **Other** → acknowledge and note for next standup\n3. Scrum master's response goes back to the Matrix room\n\nThe scrum master agent handles the NLU — we don't need to parse commands ourselves. The agent's ROLE.md should be updated to include:\n- 'When you receive a human message, determine the intent and take the appropriate action'\n- 'Always respond in the Matrix room with what you did'\n- 'For status queries, use bd list and bd show to gather current state'\n\nUpdate ROLE.md in internal/team/team.go to add communication responsibilities.\n\nAcceptance: Human messages dispatched to scrum master, scrum master responds with actions, response sent back to Matrix","notes":"REPLACED: This task was too complex (full command parsing system). Replaced with focused cortex-2zc (basic command handling) that can be completed by overnight automation.","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:21:24.490363129+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:39:44.717623778+10:00","closed_at":"2026-02-18T02:39:44.717658252+10:00","dependencies":[{"issue_id":"cortex-a4s.6","depends_on_id":"cortex-a4s","type":"parent-child","created_at":"2026-02-17T17:21:24.501960084+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a4s.6","depends_on_id":"cortex-a4s.5","type":"blocks","created_at":"2026-02-17T17:22:08.708436386+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a4s.6","depends_on_id":"cortex-a4s.2","type":"blocks","created_at":"2026-02-17T17:22:09.089043739+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a4s.6","depends_on_id":"cortex-a4s.7","type":"blocks","created_at":"2026-02-17T17:22:09.293367704+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-a4s.7","title":"Update scrum master ROLE.md for communication responsibilities","description":"Update the scrum master agent's role description in internal/team/team.go to reflect its new position as the project's point of contact.\n\nCurrent ROLE.md focuses only on task refinement. Expand to cover:\n\n```markdown\n# Scrum Master Agent\n\nYou are the scrum master and primary point of contact for this project.\n\n## Communication (Primary)\n- You are the ONLY agent that communicates with humans\n- Report progress, blockers, and decisions via Matrix\n- When you receive a human message, determine intent and act:\n  - Status queries: gather state with bd list/show, summarize\n  - Priority changes: reprioritize with bd update\n  - Task creation: create beads with bd create\n  - Guidance: update design notes on relevant beads\n  - Always confirm what you did\n\n## Daily Standup\n- Summarize: what completed yesterday, what's in progress, any blockers\n- Flag beads that have been in_progress for \u003e24h\n- Highlight rate limit status if above 70%\n\n## Task Refinement\n- Review descriptions for clarity and completeness\n- Add or improve acceptance criteria\n- Break large tasks into sub-tasks\n- Estimate effort when missing\n\n## Stage Workflow\n- You receive tasks at stage:backlog\n- When refinement is complete, transition to stage:planning\n- Always unassign yourself after transitioning\n```\n\nAlso update EnsureTeam() to re-write ROLE.md if it detects the old version (or add a version marker).\n\nAcceptance: New ROLE.md covers communication, standup, and refinement. Agent behaves as point of contact.","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:21:36.630347088+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T17:21:36.630347088+10:00","dependencies":[{"issue_id":"cortex-a4s.7","depends_on_id":"cortex-a4s","type":"parent-child","created_at":"2026-02-17T17:21:36.639118512+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-a4s.8","title":"Implement scrum master daily standup report","description":"Replace the generic daily digest with a scrum-master-authored standup report per project.\n\nCurrent digest (Reporter.SendDigest) is a simple template:\n  '## Daily Cortex Digest — {date}\n   - project: N beads completed today\n   - Health: N events'\n\nNew standup (dispatched through scrum master agent):\nThe scrum master receives ProjectContext and produces a standup-style report:\n\n**Yesterday:**\n- Completed: list of closed beads with brief outcomes\n- Failed: any beads that failed with reasons\n\n**Today:**\n- In Progress: what's currently being worked, by which agent\n- Ready: what's unblocked and queued for dispatch\n- Blocked: what's stuck and on what\n\n**Risks:**\n- Rate limit status (usage/cap)\n- Stuck dispatches or repeated failures\n- Beads in_progress for \u003e24h\n\nThe scrum master formats this conversationally, not as raw data. It should feel like a team standup message in a chat room.\n\nSchedule: runs at daily_digest_time from config (default 09:00).\nReplaces Reporter.SendDigest() calls — the standup IS the digest.\n\nAcceptance: Standup generates per-project, routed through scrum master, includes all sections, conversational tone","notes":"REPLACED: This task was too complex (full standup system with complex formatting). Replaced with focused cortex-ago (basic daily report) that can be completed by overnight automation.","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:21:48.097683349+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:39:47.892989459+10:00","closed_at":"2026-02-18T02:39:47.892997944+10:00","dependencies":[{"issue_id":"cortex-a4s.8","depends_on_id":"cortex-a4s","type":"parent-child","created_at":"2026-02-17T17:21:48.101256464+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a4s.8","depends_on_id":"cortex-a4s.3","type":"blocks","created_at":"2026-02-17T17:22:13.485440432+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a4s.8","depends_on_id":"cortex-a4s.2","type":"blocks","created_at":"2026-02-17T17:22:13.651877467+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-a4s.9","title":"Implement scrum master sprint planning function","description":"Add a sprint planning mode where the scrum master reviews the entire backlog holistically, refines beads in bulk, and selects a sprint's worth of work.\n\n**Current problem:**\nThe scrum master is dispatched per-bead (one stage:backlog bead → one dispatch). It never sees the full picture. It can't prioritize across beads, spot duplicates, identify missing work, or decide what goes into the next sprint. It's a bead-refiner, not a planner.\n\n**Sprint planning function:**\n\nTrigger: scheduled (e.g. weekly, configurable) OR when backlog exceeds threshold (e.g. \u003e5 unrefined beads) OR manual trigger via Matrix.\n\nConfig:\n```toml\n[projects.hg-website]\nsprint_planning_day = \"Monday\"        # weekly trigger\nsprint_planning_time = \"08:00\"\nsprint_capacity = 10                   # max beads per sprint\nbacklog_threshold = 5                  # auto-trigger if unrefined backlog exceeds this\n```\n\nCreate internal/scheduler/sprint.go:\n\ntype SprintPlanner struct {\n    store      *store.Store\n    dispatcher *dispatch.Dispatcher\n    cfg        *config.Config\n    logger     *slog.Logger\n}\n\nfunc (sp *SprintPlanner) RunPlanning(ctx, project, projectCfg):\n\n1. **Gather backlog**: List all beads that are open + have no stage label or stage:backlog\n2. **Build context**: Include already-in-progress work, recently closed beads, dependency graph\n3. **Dispatch scrum master with full backlog**:\n   - Send ALL backlog beads to the scrum master in a single dispatch (not one-by-one)\n   - Prompt includes every backlog bead's title, description, current priority, estimate, labels\n   - Also includes the dependency graph so scrum master can see what unblocks what\n4. **Scrum master instructions** (sprint planning prompt template):\n   - Review each backlog bead for clarity and completeness\n   - Add acceptance criteria where missing (bd update \u003cid\u003e --acceptance=\"...\")\n   - Add design notes with implementation approach (bd update \u003cid\u003e --design=\"...\")\n   - Set or adjust estimates (bd update \u003cid\u003e --estimate=\u003cminutes\u003e)\n   - Set or adjust priority based on business value + dependencies\n   - Break down any bead estimated \u003e120min into sub-tasks\n   - Identify and flag duplicate or overlapping beads\n   - Select top N beads (up to sprint_capacity) and transition them: bd update \u003cid\u003e --labels stage:planning\n   - Leave remaining beads in backlog with notes on why deferred\n   - Output a sprint plan summary at the end\n\n5. **Sprint plan summary** (sent to Matrix via scrum master):\n   - What's in the sprint (selected beads with priorities)\n   - What was deferred and why\n   - Any blockers or risks identified\n   - Estimated sprint capacity usage\n\n**New prompt template** in internal/scheduler/prompt.go:\nAdd a 'sprint_planning' key to stageInstructions that includes the full backlog context and planning instructions above.\n\n**Scheduler integration**:\n- Add a sprint planning check to RunTick or as a separate goroutine\n- Check: is it sprint_planning_day + sprint_planning_time? → trigger\n- Check: count of stage:backlog beads \u003e backlog_threshold? → trigger\n- Dedup: don't re-trigger if planning ran within last 24h (track in store)\n\n**Store additions**:\n- RecordSprintPlanning(project, beadsSelected, beadsDeferred, timestamp)\n- GetLastSprintPlanning(project) → timestamp (for dedup)\n\nAcceptance:\n- Sprint planning dispatches scrum master with full backlog context\n- Scrum master refines, estimates, and selects beads in one pass\n- Sprint plan summary sent to Matrix\n- Triggers work (scheduled + threshold + manual)\n- Config is backward compatible (no sprint planning = old behavior)","notes":"⚠️ NEEDS BREAKDOWN: This task is still too complex for overnight automation. It attempts to build an entire sprint planning system with multiple components:\n\n- Configuration system for sprint planning\n- SprintPlanner struct with multiple methods\n- Store integration for planning tracking  \n- Scheduler integration with triggers\n- Prompt template system\n- Matrix integration and reporting\n\nRecommend breaking into 3-4 focused tasks:\n1. Add sprint planning configuration schema\n2. Build basic backlog gathering queries  \n3. Create sprint selection prompt template\n4. Add scheduler sprint planning triggers\n\nEach task should be completable in a single focused session.","status":"open","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:26:38.982883997+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:39:56.284589385+10:00","dependencies":[{"issue_id":"cortex-a4s.9","depends_on_id":"cortex-a4s","type":"parent-child","created_at":"2026-02-17T17:26:39.003463728+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a4s.9","depends_on_id":"cortex-a4s.2","type":"blocks","created_at":"2026-02-17T17:26:43.470607057+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a4s.9","depends_on_id":"cortex-a4s.7","type":"blocks","created_at":"2026-02-17T17:26:43.657625009+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-a6p","title":"Cost tracking and budget management","description":"Rate limits count dispatches but not dollars. Claude Opus costs 100x what Cerebras does. A 'fast' dispatch and a 'premium' dispatch look identical to Cortex's accounting. No way to answer 'how much did this sprint cost?' or 'which project is burning money?'\n\nKey deliverables:\n- Cost field on provider config (cost per 1K input/output tokens)\n- Token usage recording per dispatch\n- Cost-per-dispatch, per-bead, per-project, per-sprint analytics\n- Cost budgeting: max $/week per project\n- Cost alerts when approaching budget\n- Cost data feeds into retro analysis","status":"closed","priority":1,"issue_type":"epic","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:57:33.035311012+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:02:59.496839963+10:00","closed_at":"2026-02-18T04:02:59.496839963+10:00","close_reason":"Epic completed - all deliverables broken down into executable tasks"}
{"id":"cortex-a6p.1","title":"Add cost fields to provider config and dispatch recording","description":"Add cost-per-token pricing to provider definitions and record token usage per dispatch.\n\nConfig changes:\n```toml\n[providers.claude-opus]\ntier = \"premium\"\nauthed = true\nmodel = \"claude-opus-4-6\"\ncost_input_per_mtok = 15.00    # $ per million input tokens\ncost_output_per_mtok = 75.00   # $ per million output tokens\n```\n\nAdd to internal/config/config.go Provider struct:\n- CostInputPerMtok float64\n- CostOutputPerMtok float64\n\nDB schema changes (internal/store/store.go):\n- Add columns to dispatches: input_tokens INT, output_tokens INT, cost_usd REAL\n- Add columns to provider_usage: input_tokens INT, output_tokens INT\n\nNew methods:\n- RecordDispatchCost(dispatchID, inputTokens, outputTokens, costUSD)\n- GetDispatchCost(dispatchID) (inputTokens, outputTokens, costUSD)\n\nToken extraction: parse from agent output (openclaw likely reports token usage in output or exit summary). If not available, estimate from prompt length (input) and output capture length.\n\nAcceptance: Cost fields in config, token/cost recorded per dispatch, backward compatible if cost fields missing","status":"closed","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:58:57.600063644+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T21:40:13.918234685+10:00","closed_at":"2026-02-17T21:40:13.918234685+10:00","close_reason":"Closed","labels":["stage:qa","stage:review"],"dependencies":[{"issue_id":"cortex-a6p.1","depends_on_id":"cortex-a6p","type":"parent-child","created_at":"2026-02-17T17:58:57.604065002+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-a6p.2","title":"Implement cost analytics queries","description":"Build cost aggregation queries for per-bead, per-project, per-sprint, and per-provider cost analysis.\n\nCreate internal/learner/costs.go:\n```go\ntype CostSummary struct {\n    TotalCostUSD     float64\n    TotalInputTokens int64\n    TotalOutputTokens int64\n    DispatchCount    int\n    AvgCostPerDispatch float64\n    AvgCostPerBead   float64\n}\n\n// GetProjectCost returns cost for a project over a time window\nfunc GetProjectCost(store, project string, window time.Duration) (*CostSummary, error)\n\n// GetSprintCost returns cost for all projects in a sprint\nfunc GetSprintCost(store, sprintStart, sprintEnd time.Time) (map[string]*CostSummary, error)\n\n// GetProviderCost returns cost breakdown by provider\nfunc GetProviderCost(store, window time.Duration) (map[string]*CostSummary, error)\n\n// GetBeadCost returns total cost for a specific bead (may span multiple dispatches/retries)\nfunc GetBeadCost(store, beadID string) (*CostSummary, error)\n\n// GetCostTrend returns daily cost for the last N days\nfunc GetCostTrend(store, days int) ([]DailyCost, error)\n```\n\nAcceptance: All queries return correct aggregations, tested with sample data","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:59:03.031411611+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T21:45:39.528718172+10:00","closed_at":"2026-02-17T21:45:39.528718172+10:00","close_reason":"Implemented cost analytics queries with tests","labels":["stage:review"],"dependencies":[{"issue_id":"cortex-a6p.2","depends_on_id":"cortex-a6p","type":"parent-child","created_at":"2026-02-17T17:59:03.035485735+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a6p.2","depends_on_id":"cortex-a6p.1","type":"blocks","created_at":"2026-02-17T17:59:19.05714194+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-a6p.3","title":"Add cost budgeting and alerts","description":"Set cost budgets per project and alert when approaching limits.\n\nConfig:\n```toml\n[projects.hg-website]\ncost_budget_weekly = 50.00    # max $50/week\ncost_budget_monthly = 150.00  # max $150/month\n```\n\nCreate internal/dispatch/costlimit.go:\n```go\n// CanAffordDispatch checks if project has budget remaining\nfunc CanAffordDispatch(store, project string, estimatedCost float64) (bool, float64 remaining)\n\n// EstimateDispatchCost estimates cost based on provider pricing and average token usage\nfunc EstimateDispatchCost(provider config.Provider, avgTokens int) float64\n```\n\nIntegration:\n- Scheduler checks CanAffordDispatch before dispatching (alongside rate limits)\n- If budget exhausted, skip project this tick (like rate limiting)\n- Alert via reporter when project hits 80% of budget\n- Include in API /status endpoint\n\nAcceptance: Budget enforced, dispatches blocked when over budget, alerts fire at threshold","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:59:08.28014723+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:02:50.520122083+10:00","closed_at":"2026-02-18T04:02:50.520122083+10:00","close_reason":"Broken down into executable sub-tasks: cortex-a6p.3.1 through cortex-a6p.3.4","labels":["code"],"dependencies":[{"issue_id":"cortex-a6p.3","depends_on_id":"cortex-a6p","type":"parent-child","created_at":"2026-02-17T17:59:08.343898102+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a6p.3","depends_on_id":"cortex-a6p.1","type":"blocks","created_at":"2026-02-17T17:59:22.006029004+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-a6p.3.1","title":"Create cost budget limit checker for dispatch scheduling","description":"Create internal/dispatch/costlimit.go with CanAffordDispatch and EstimateDispatchCost functions.\n\nFiles to create/modify:\n- internal/dispatch/costlimit.go (new)\n- internal/dispatch/costlimit_test.go (new)\n\nAcceptance criteria:\n- CanAffordDispatch(store, project string, estimatedCost float64) returns (bool, float64)\n- EstimateDispatchCost(provider config.Provider, avgTokens int) returns float64\n- Unit tests achieve 90%+ coverage\n- Functions handle edge cases (no budget config, zero costs, etc.)\n\nImplementation details:\n- Read project budget from config (cost_budget_weekly, cost_budget_monthly)\n- Query current spending using learner.GetProjectCost()\n- Return false if estimated cost would exceed remaining budget\n- Return remaining budget amount for logging/alerts","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:01:40.554053593+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:01:40.554053593+10:00","dependencies":[{"issue_id":"cortex-a6p.3.1","depends_on_id":"cortex-a6p.3","type":"parent-child","created_at":"2026-02-18T04:01:40.583993911+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-a6p.3.2","title":"Add cost budget config fields to project configuration","description":"Extend config.go to support per-project cost budgeting fields.\n\nFiles to create/modify:\n- internal/config/config.go (extend Project struct)\n- config validation/parsing logic\n\nAcceptance criteria:\n- Project struct has CostBudgetWeekly and CostBudgetMonthly float64 fields\n- TOML parsing supports cost_budget_weekly and cost_budget_monthly keys\n- Backward compatible - projects without budget config work normally\n- Config validation prevents negative budget values\n\nExample TOML:\n","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:01:46.74643495+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:01:46.74643495+10:00","dependencies":[{"issue_id":"cortex-a6p.3.2","depends_on_id":"cortex-a6p.3","type":"parent-child","created_at":"2026-02-18T04:01:46.76718944+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-a6p.3.3","title":"Integrate cost budget checking into scheduler dispatch logic","description":"Integrate cost budget checking into the main scheduler dispatch decision flow.\n\nFiles to create/modify:\n- internal/scheduler/scheduler.go (add cost check before dispatch)\n- internal/scheduler/scheduler_test.go (test budget blocking)\n\nAcceptance criteria:\n- Scheduler calls CanAffordDispatch before creating new dispatches\n- Projects over budget are skipped (similar to rate limiting)\n- Scheduler logs budget exhaustion events for debugging\n- Integration tests verify budget enforcement\n- Performance impact is minimal (budget check \u003c 10ms)\n\nImplementation details:\n- Add cost check alongside existing rate limit checks\n- Use project name from bead metadata to check budget\n- Skip dispatch and continue to next project if over budget\n- Log at INFO level when budget blocks dispatch","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:01:58.654024446+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:01:58.654024446+10:00","dependencies":[{"issue_id":"cortex-a6p.3.3","depends_on_id":"cortex-a6p.3","type":"parent-child","created_at":"2026-02-18T04:01:58.681237024+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a6p.3.3","depends_on_id":"cortex-a6p.3.1","type":"blocks","created_at":"2026-02-18T04:01:58.715063983+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a6p.3.3","depends_on_id":"cortex-a6p.3.2","type":"blocks","created_at":"2026-02-18T04:01:58.731450013+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-a6p.3.4","title":"Add cost budget alerting when approaching limits","description":"Implement alerting system that fires when projects approach their cost budget limits.\n\nFiles to create/modify:\n- internal/learner/reporter.go (extend with cost budget alerts)\n- internal/learner/reporter_test.go (test alert logic)\n\nAcceptance criteria:\n- Alert fires when project hits 80% of weekly or monthly budget\n- Alert contains project name, current spend, budget limit, and remaining budget\n- Alerts are rate-limited to prevent spam (max 1 per hour per project)\n- Uses existing reporter infrastructure\n- Integration test verifies alert timing and content\n\nImplementation details:\n- Check budget usage after each dispatch cost recording\n- Calculate percentage of budget consumed\n- Use threshold of 80% for warning, 95% for critical\n- Store last alert time to implement rate limiting\n- Alert message includes actionable information","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:02:05.839938733+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:02:05.839938733+10:00","dependencies":[{"issue_id":"cortex-a6p.3.4","depends_on_id":"cortex-a6p.3","type":"parent-child","created_at":"2026-02-18T04:02:05.871738148+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a6p.3.4","depends_on_id":"cortex-a6p.3.1","type":"blocks","created_at":"2026-02-18T04:02:05.906039891+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-a6p.4","title":"Add cost metrics to API and retro","description":"Surface cost data in API endpoints and include in retrospective analysis.\n\nAPI additions:\n- GET /costs — overall cost summary (today, this week, this month)\n- GET /costs/{project} — per-project cost breakdown\n- GET /metrics — add cortex_cost_usd_total counter, cortex_cost_usd_weekly gauge\n\nRetro additions:\n- Include cost data in RetroReport: total spend, cost per bead, cost by tier\n- Cost efficiency: cost per completed bead vs cost per failed bead\n- Provider cost-effectiveness: quality score / cost ratio\n- Feed into scrum master and chief SM retro prompts\n\nAcceptance: Cost visible in API, prometheus metrics, and retro reports","status":"closed","priority":3,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:59:15.549332439+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:02:53.348249646+10:00","closed_at":"2026-02-18T04:02:53.348249646+10:00","close_reason":"Broken down into executable sub-tasks: cortex-a6p.4.1 through cortex-a6p.4.5","labels":["code"],"dependencies":[{"issue_id":"cortex-a6p.4","depends_on_id":"cortex-a6p","type":"parent-child","created_at":"2026-02-17T17:59:15.552183403+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a6p.4","depends_on_id":"cortex-a6p.2","type":"blocks","created_at":"2026-02-17T17:59:24.968311549+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a6p.4","depends_on_id":"cortex-a6p.3","type":"blocks","created_at":"2026-02-17T17:59:27.893634713+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-a6p.4.1","title":"Add GET /costs API endpoint for overall cost summary","description":"Create API endpoint for overall cost summary across all projects and time periods.\n\nFiles to create/modify:\n- internal/api/costs.go (new)\n- internal/api/costs_test.go (new)\n- internal/api/router.go (add cost endpoints)\n\nAcceptance criteria:\n- GET /costs returns JSON with today, this week, this month totals\n- Response includes token counts, dispatch counts, average costs\n- Proper error handling and HTTP status codes\n- Unit tests for endpoint logic and edge cases\n- API documentation in comments\n\nResponse includes cost_usd, dispatches, and tokens for each time period.","status":"open","priority":3,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:02:16.791049006+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:02:16.791049006+10:00","dependencies":[{"issue_id":"cortex-a6p.4.1","depends_on_id":"cortex-a6p.4","type":"parent-child","created_at":"2026-02-18T04:02:16.805382648+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-a6p.4.2","title":"Add GET /costs/{project} API endpoint for per-project breakdown","description":"Create API endpoint for detailed per-project cost analysis and breakdowns.\n\nFiles to create/modify:\n- internal/api/costs.go (extend)\n- internal/api/costs_test.go (extend)\n\nAcceptance criteria:\n- GET /costs/{project} returns detailed project cost breakdown\n- Includes cost by provider, time trends, bead-level costs\n- 404 for unknown projects with proper error message\n- Query parameters for time ranges (last 7d, 30d, etc.)\n- Unit tests cover various project states and time ranges\n\nResponse includes:\n- Total cost for project\n- Cost breakdown by provider/tier\n- Recent cost trend (daily costs)\n- Most expensive beads\n- Budget status if configured","status":"open","priority":3,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:02:23.393321785+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:02:23.393321785+10:00","dependencies":[{"issue_id":"cortex-a6p.4.2","depends_on_id":"cortex-a6p.4","type":"parent-child","created_at":"2026-02-18T04:02:23.446110239+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-a6p.4.3","title":"Add Prometheus cost metrics to /metrics endpoint","description":"Extend the Prometheus metrics endpoint with cost-related gauges and counters.\n\nFiles to create/modify:\n- internal/api/metrics.go (extend with cost metrics)\n- internal/api/metrics_test.go (test cost metric generation)\n\nAcceptance criteria:\n- cortex_cost_usd_total counter tracks cumulative spend\n- cortex_cost_usd_weekly gauge shows current week spend\n- cortex_cost_usd_daily gauge shows today spend\n- Metrics include labels for project, provider, tier\n- Metrics updated in real-time as dispatches complete\n- Unit tests verify metric accuracy and labeling\n\nPrometheus metrics:\n- cortex_cost_usd_total{project, provider, tier}\n- cortex_cost_usd_weekly{project, provider}\n- cortex_dispatch_cost_usd{project, provider, tier}\n- cortex_budget_remaining_usd{project, type=weekly|monthly}","status":"open","priority":3,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:02:30.929453151+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:02:30.929453151+10:00","dependencies":[{"issue_id":"cortex-a6p.4.3","depends_on_id":"cortex-a6p.4","type":"parent-child","created_at":"2026-02-18T04:02:30.943291298+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-a6p.4.4","title":"Extend RetroReport with cost analysis data","description":"Add comprehensive cost analysis to the retrospective reporting system.\n\nFiles to create/modify:\n- internal/learner/retro.go (extend RetroReport struct)\n- internal/learner/retro_test.go (test cost data inclusion)\n\nAcceptance criteria:\n- RetroReport includes total spend for retrospective period\n- Cost per bead (completed vs failed)\n- Cost by provider tier with efficiency analysis\n- Cost trends over the retro period\n- Budget adherence metrics if budgets are configured\n- Unit tests verify cost calculations and edge cases\n\nCost metrics to include:\n- Total cost for retro period\n- Average cost per completed bead\n- Average cost per failed bead (waste analysis)\n- Cost efficiency by provider (quality score / cost ratio)\n- Percentage of budget consumed\n- Cost trend analysis (increasing/decreasing)","status":"open","priority":3,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:02:38.203188246+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:02:38.203188246+10:00","dependencies":[{"issue_id":"cortex-a6p.4.4","depends_on_id":"cortex-a6p.4","type":"parent-child","created_at":"2026-02-18T04:02:38.22972288+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-a6p.4.5","title":"Update scrum master and chief SM prompts with cost awareness","description":"Enhance the scrum master and chief scrum master AI prompts to incorporate cost analysis and budgeting insights.\n\nFiles to create/modify:\n- Scrum master prompt templates (location TBD based on codebase structure)\n- Chief SM prompt templates\n- Integration with RetroReport cost data\n\nAcceptance criteria:\n- Scrum master mentions cost trends in retrospectives\n- Alerts on cost efficiency issues (high cost, low completion)\n- Suggests cost optimization strategies\n- Chief SM includes budget adherence in cross-project analysis\n- Prompts reference specific cost metrics from RetroReport\n- Testing via prompt injection or mock retro data\n\nCost insights to include:\n- Budget burn rate analysis\n- Provider cost-effectiveness recommendations  \n- High-cost / low-value bead identification\n- Cost trend warnings (sudden spikes)\n- ROI analysis suggestions","status":"open","priority":3,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:02:46.490335978+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:02:46.490335978+10:00","dependencies":[{"issue_id":"cortex-a6p.4.5","depends_on_id":"cortex-a6p.4","type":"parent-child","created_at":"2026-02-18T04:02:46.505979713+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-a6p.4.5","depends_on_id":"cortex-a6p.4.4","type":"blocks","created_at":"2026-02-18T04:02:46.525152101+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-ago","title":"Add daily scrum master standup report","description":"Generate daily standup reports from scrum master. Simplified version of cortex-a4s.8.\n\n## Goal\nSend automated daily standup reports showing yesterday's progress and today's plan.\n\n## Scope\nCreate scheduled daily standup reporting in internal/scrum/standup.go:\n\n## Report Content\n- **Yesterday**: Completed beads, failed dispatches, blockers resolved\n- **Today**: Planned work (ready beads), agents assigned, estimated effort  \n- **Blockers**: Current blocking dependencies or issues\n- **Metrics**: Velocity, completion rate, intervention rate\n\n## Scheduling\n- Add to scheduler RunTick with daily check (e.g., 9 AM project timezone)\n- Configurable per project: standup_time, standup_enabled\n- Skip weekends by default (configurable)\n\n## Implementation\n- Query project stats for yesterday's activity\n- Query ready beads for today's planned work\n- Format as brief standup-style report  \n- Send via scrum master agent to project Matrix room\n\n## Report Format\n\n\n## Configuration\nAdd to project config:\n\n\n## Acceptance Criteria\n1) Generates daily reports with yesterday/today/blockers sections\n2) Scheduled execution via scheduler RunTick\n3) Configurable per project (time, timezone, enabled)\n4) Skips weekends unless configured otherwise\n5) Includes relevant project metrics and status\n6) Sends to project Matrix room if configured","status":"open","priority":3,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:38:58.708220736+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:38:58.708220736+10:00","labels":["daily","reporting","scrum","standup"]}
{"id":"cortex-anx","title":"Update scheduler to route dispatches by tier and retry count","description":"Update internal/scheduler/scheduler.go to select backend based on dispatch.routing config:\n\n- Fast tier → headless backend\n- Balanced tier, first attempt → headless backend  \n- Balanced tier, retry → tmux backend\n- Premium tier → tmux backend\n- Any retry (regardless of tier) → tmux backend (retry_backend config)\n- Comms/reports → openclaw backend\n\nScheduler holds map[string]Backend initialized from config. pickBackend(tier, retryCount) returns the right one.\n\nUpdate RunTick to:\n1. Resolve backend from tier + retry count\n2. Build DispatchOpts from CLI config + provider config\n3. Call backend.Dispatch()\n4. Store Handle (with backend type, log_path, session_name, branch) in dispatches table\n\nUpdate checkRunningDispatches to call backend.Status() based on stored backend type.\n\nAcceptance: fast tasks use headless, premium use tmux, retries promote to tmux. Mixed backends tracked correctly.","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:00:30.287975591+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T18:00:30.287975591+10:00","dependencies":[{"issue_id":"cortex-anx","depends_on_id":"cortex-hgz","type":"blocks","created_at":"2026-02-17T18:01:30.027269698+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-anx","depends_on_id":"cortex-v2h","type":"blocks","created_at":"2026-02-17T18:01:30.346434221+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-anx","depends_on_id":"cortex-ejd","type":"blocks","created_at":"2026-02-17T18:01:30.602060206+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-anx","depends_on_id":"cortex-x83","type":"blocks","created_at":"2026-02-17T18:01:30.780080141+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-ax7","title":"Auto: break down epic cortex-xhk into executable bug/task beads","description":"Epic `cortex-xhk` is still open in project `cortex`.\n\nPolicy: epics should not be assigned directly to coders. Break this epic into concrete `bug`/`task` beads with acceptance criteria so overnight automation can execute them.\n\nEpic title: LeSS coordination layer: cross-team orchestration","status":"open","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:00:06.202283187+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:00:06.202283187+10:00","dependencies":[{"issue_id":"cortex-ax7","depends_on_id":"cortex-xhk","type":"discovered-from","created_at":"2026-02-18T02:00:06.205691432+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-bjc","title":"Auto: break down epic cortex-c4j into executable bug/task beads","description":"Epic `cortex-c4j` is still open in project `cortex`.\n\nPolicy: epics should not be assigned directly to coders. Break this epic into concrete `bug`/`task` beads with acceptance criteria so overnight automation can execute them.\n\nEpic title: Launch readiness go/no-go execution plan","status":"closed","priority":1,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:20:23.827311247+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:23:36.555300297+10:00","closed_at":"2026-02-18T04:23:36.555300297+10:00","close_reason":"Epic breakdown completed successfully - epic was already decomposed into 7 executable tasks","dependencies":[{"issue_id":"cortex-bjc","depends_on_id":"cortex-c4j","type":"discovered-from","created_at":"2026-02-18T04:20:23.83088122+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-bwm","title":"Auto: break down epic cortex-46d into executable bug/task beads","description":"Epic `cortex-46d` is still open in project `cortex`.\n\nPolicy: epics should not be assigned directly to coders. Break this epic into concrete `bug`/`task` beads with acceptance criteria so overnight automation can execute them.\n\nEpic title: Self-healing control-loop hardening","status":"closed","priority":1,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T03:05:10.847114301+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:45:12.787508999+10:00","closed_at":"2026-02-18T04:45:12.787508999+10:00","close_reason":"Epic breakdown completed successfully - cortex-46d was already broken down into 13 executable tasks","dependencies":[{"issue_id":"cortex-bwm","depends_on_id":"cortex-46d","type":"discovered-from","created_at":"2026-02-18T03:05:10.851552951+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-byi","title":"Runbook: gateway incident response","description":"Create a gateway incident runbook covering detection, restart, verification, and rollback triggers.\n\nAcceptance criteria:\n1) Include concrete health checks and service recovery commands.\n2) Include fallback path when gateway remains degraded.\n3) Record one tabletop drill outcome under artifacts/launch/runbooks/.","status":"closed","priority":1,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:42:07.84719943+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T05:05:35.056066689+10:00","closed_at":"2026-02-18T05:05:35.056066689+10:00","close_reason":"Gateway incident response runbook completed successfully. All acceptance criteria met:\n1) ✅ Concrete health checks and service recovery commands included in docs/GATEWAY_INCIDENT_RESPONSE_RUNBOOK.md\n2) ✅ Fallback procedures for degraded gateway scenarios included with escalation triggers  \n3) ✅ Tabletop drill completed and recorded in artifacts/launch/runbooks/gateway-incident-tabletop-drill-20260218.md\nAll tests pass. Production ready.","labels":["stage:qa"],"dependencies":[{"issue_id":"cortex-byi","depends_on_id":"cortex-c4j.3","type":"discovered-from","created_at":"2026-02-18T02:42:07.851250443+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-c4j","title":"Launch readiness go/no-go execution plan","status":"closed","priority":1,"issue_type":"epic","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T01:58:11.877757837+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:23:32.371887475+10:00","closed_at":"2026-02-18T04:23:32.371887475+10:00","close_reason":"Epic completed - broken down into 7 concrete tasks with detailed acceptance criteria and file specifications","labels":["launch","ops","readiness"]}
{"id":"cortex-c4j.1","title":"Protect control API endpoints with authn/authz and audit logging","description":"Add mandatory access control for scheduler and dispatch control endpoints before any non-local launch.","acceptance_criteria":"1) Control endpoints require authn/authz in deployed topology. 2) Unauthorized requests are denied and logged. 3) Deployment/runbook docs include secure exposure pattern.","status":"in_progress","priority":1,"issue_type":"bug","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T01:58:22.580706522+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:23:19.803886534+10:00","labels":["api","launch","readiness","security"],"dependencies":[{"issue_id":"cortex-c4j.1","depends_on_id":"cortex-c4j","type":"parent-child","created_at":"2026-02-18T01:58:22.584656278+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-c4j.2","title":"Automate 7-day burn-in evidence capture and SLO scoring","description":"Build a repeatable collector/report that captures status/health/metrics and computes launch checklist burn-in gates.","acceptance_criteria":"1) Script/report generates daily and final 7-day summary. 2) Includes unknown/disappeared failure %, intervention rate, critical-event counts. 3) Output is stored as launch evidence artifact.","notes":"RESOLUTION: Split into focused tasks for better execution:\n\n- cortex-zly: Define burn-in SLO metrics and thresholds  \n- cortex-26q: Build burn-in metrics collector\n- cortex-3bf: Implement SLO computation engine\n- cortex-7am: Build daily burn-in report generator  \n- cortex-dwc: Build 7-day burn-in summary generator\n\nOriginal task was too broad (entire burn-in evidence system) causing churn. New focused tasks enable incremental progress and proper testing.","status":"closed","priority":1,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T01:58:33.293115218+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:34:21.848158456+10:00","closed_at":"2026-02-18T02:34:21.848191038+10:00","labels":["launch","ops","readiness","reliability"],"dependencies":[{"issue_id":"cortex-c4j.2","depends_on_id":"cortex-c4j","type":"parent-child","created_at":"2026-02-18T01:58:33.299877738+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-c4j.3","title":"Publish operational runbook set for launch operations","description":"Write and validate runbooks for pause/resume maintenance, stuck dispatch triage, gateway incidents, rollback, and backup/restore.","acceptance_criteria":"1) Runbooks exist in docs with concrete commands. 2) At least one tabletop or live drill validates each runbook. 3) Drill outcomes are recorded in bead notes/artifacts.","status":"in_progress","priority":1,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T01:58:44.158509315+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:42:38.809844482+10:00","labels":["docs","launch","ops","readiness"],"dependencies":[{"issue_id":"cortex-c4j.3","depends_on_id":"cortex-c4j","type":"parent-child","created_at":"2026-02-18T01:58:44.162504836+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-c4j.4","title":"Implement and validate SQLite backup/restore workflow","description":"Provide tested backup and restore procedures for the Cortex state DB, including integrity checks and rollback safety.","acceptance_criteria":"1) Backup command/procedure documented and automated. 2) Restore validated on test copy with integrity checks. 3) Recovery RTO/RPO expectations documented.","status":"closed","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T01:58:54.649722661+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:34:58.40057531+10:00","closed_at":"2026-02-18T02:34:52.560940384+10:00","close_reason":"Closed","labels":["data","launch","ops","readiness"],"dependencies":[{"issue_id":"cortex-c4j.4","depends_on_id":"cortex-c4j","type":"parent-child","created_at":"2026-02-18T01:58:54.652791483+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-c4j.5","title":"Define release process with versioning, changelog, and tagged dry run","description":"Create release workflow covering version bumps, changelog generation, tagging, and release-notes quality gates.","acceptance_criteria":"1) Release checklist documented. 2) Dry-run release executed and recorded. 3) Version/changelog artifacts are reproducible.","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T01:59:05.317364781+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:18:45.852689323+10:00","closed_at":"2026-02-18T04:18:45.852689323+10:00","close_reason":"Broken down into 3 executable sub-tasks: release checklist documentation (cortex-c4j.5.1), version management scripts (cortex-c4j.5.2), and changelog automation with dry run (cortex-c4j.5.3)","labels":["launch","readiness","release"],"dependencies":[{"issue_id":"cortex-c4j.5","depends_on_id":"cortex-c4j","type":"parent-child","created_at":"2026-02-18T01:59:05.321760929+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-c4j.5.1","title":"Create release checklist and workflow documentation","description":"Document the complete release workflow with step-by-step checklist and quality gates.\n\nFiles to create/modify:\n- docs/RELEASE.md (new - comprehensive release guide)\n- scripts/release-checklist.md (new - operational checklist)\n- .github/RELEASE_TEMPLATE.md (new - GitHub release template)\n\nAcceptance criteria:\n- Release checklist covers all phases: pre-release, release, post-release\n- Each step has clear acceptance criteria and validation commands\n- Quality gates defined for each phase with pass/fail criteria\n- Rollback procedures documented for each phase\n- Checklist is actionable by any team member with required access\n- Documentation includes both automated and manual steps\n\nRelease checklist sections:\n- Pre-release: code freeze, testing, changelog generation\n- Release: version tagging, build validation, artifact creation\n- Post-release: deployment verification, rollback readiness\n- Emergency procedures: hotfix process, rollback execution\n\nQuality gates:\n- All tests pass in CI\n- Security scan passes\n- Performance benchmarks within thresholds\n- Documentation is current and accurate","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:17:20.653350153+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:17:20.653350153+10:00","dependencies":[{"issue_id":"cortex-c4j.5.1","depends_on_id":"cortex-c4j.5","type":"parent-child","created_at":"2026-02-18T04:17:20.87389551+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-c4j.5.2","title":"Implement version management and tagging scripts","description":"Create automated scripts for version bumping, git tagging, and artifact generation.\n\nFiles to create/modify:\n- scripts/bump-version.sh (new - semantic version bumping)\n- scripts/create-release-tag.sh (new - git tag creation with validation)\n- scripts/validate-release.sh (new - pre-release validation)\n- VERSION file (new - current version tracking)\n\nAcceptance criteria:\n- Version bumping follows semantic versioning (major.minor.patch)\n- Git tags are created with proper annotations and signatures\n- Release validation runs all quality gates before tagging\n- Scripts handle edge cases: existing tags, dirty working directory, CI failures\n- All scripts have help text and error handling\n- Integration with existing CI/CD pipeline\n\nVersion management features:\n- Automatic detection of version bump type (patch/minor/major)\n- Validation of version format and uniqueness\n- Git tag creation with release notes\n- Artifact generation and validation\n- Rollback capability if release fails\n\nScript requirements:\n- Idempotent operations (safe to re-run)\n- Clear error messages with remediation suggestions\n- Logging of all operations for audit trail\n- Integration with existing build system","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:17:31.00438383+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:17:31.00438383+10:00","dependencies":[{"issue_id":"cortex-c4j.5.2","depends_on_id":"cortex-c4j.5","type":"parent-child","created_at":"2026-02-18T04:17:31.007154685+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-c4j.5.2","depends_on_id":"cortex-c4j.5.1","type":"blocks","created_at":"2026-02-18T04:17:31.019520051+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-c4j.5.3","title":"Implement automated changelog generation and dry run execution","description":"Create changelog automation and execute a complete release dry run for validation.\n\nFiles to create/modify:\n- scripts/generate-changelog.sh (new - automated changelog generation)\n- scripts/dry-run-release.sh (new - complete release simulation)\n- CHANGELOG.md (update with automated generation)\n- docs/dry-run-results.md (new - dry run evidence)\n\nAcceptance criteria:\n- Changelog generation extracts meaningful changes from git history and beads\n- Changelog format is consistent and follows established conventions\n- Dry run executes complete release workflow without publishing/deploying\n- Dry run produces all release artifacts in staging environment\n- Dry run results are documented with pass/fail status for each gate\n- Changelog artifacts are reproducible (same input → same output)\n\nChangelog features:\n- Extract changes from git commits, merged PRs, and closed beads\n- Categorize changes: features, bugfixes, breaking changes, deprecations\n- Link to relevant issues and PRs for traceability\n- Filter out internal/non-user-facing changes\n- Generate in multiple formats (markdown, JSON for API)\n\nDry run scope:\n- Execute complete release workflow in test environment\n- Validate all scripts and quality gates\n- Generate all release artifacts without publishing\n- Test rollback procedures\n- Document timing and resource requirements\n- Capture evidence for go/no-go decision","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:17:41.499829375+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:17:41.499829375+10:00","dependencies":[{"issue_id":"cortex-c4j.5.3","depends_on_id":"cortex-c4j.5","type":"parent-child","created_at":"2026-02-18T04:17:41.503794246+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-c4j.5.3","depends_on_id":"cortex-c4j.5.2","type":"blocks","created_at":"2026-02-18T04:17:41.516457575+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-c4j.6","title":"Run LLM operator safety trial and record compliance evidence","description":"Execute a bounded trial using the LLM interaction guide and verify evidence-first operation with no unsafe control actions.","acceptance_criteria":"1) Trial log captures all control actions with API evidence. 2) No blind retry loops observed. 3) Findings and remediation actions recorded.","status":"closed","priority":2,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T01:59:15.859923228+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:18:49.320574668+10:00","closed_at":"2026-02-18T04:18:49.320574668+10:00","close_reason":"Broken down into 3 executable sub-tasks: safety trial protocol design (cortex-c4j.6.1), trial environment setup with monitoring (cortex-c4j.6.2), and trial execution with evidence capture (cortex-c4j.6.3)","labels":["launch","llm","ops","readiness"],"dependencies":[{"issue_id":"cortex-c4j.6","depends_on_id":"cortex-c4j","type":"parent-child","created_at":"2026-02-18T01:59:15.863680033+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-c4j.6.1","title":"Design and document LLM operator safety trial protocol","description":"Create detailed protocol for conducting safe LLM operator trial with evidence capture.\n\nFiles to create/modify:\n- docs/llm-safety-trial-protocol.md (new - trial methodology)\n- scripts/safety-trial-setup.sh (new - trial environment setup)\n- templates/safety-trial-log-template.md (new - structured logging template)\n\nAcceptance criteria:\n- Trial protocol defines clear objectives, scope, and success criteria\n- Safety boundaries and guardrails are explicitly defined\n- Evidence capture methodology is comprehensive and auditable\n- Trial duration, participants, and environment are specified\n- Risk mitigation procedures are documented for potential issues\n- Protocol is reviewable and approvable by stakeholders\n\nTrial protocol elements:\n- Scope: specific operations and control actions to test\n- Duration: bounded trial period with clear start/end\n- Participants: operator roles and responsibilities\n- Environment: production-like but safely isolated\n- Evidence: comprehensive logging and monitoring requirements\n- Safety: abort conditions and emergency procedures\n\nSafety guardrails:\n- No destructive operations without confirmation\n- All control actions logged with operator attribution\n- Automatic abort on detection of unsafe patterns\n- Limited blast radius (specific projects/environments only)\n- Real-time monitoring and alerting\n- Manual override capabilities at all times","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:17:50.937073838+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:17:50.937073838+10:00","dependencies":[{"issue_id":"cortex-c4j.6.1","depends_on_id":"cortex-c4j.6","type":"parent-child","created_at":"2026-02-18T04:17:50.949782274+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-c4j.6.2","title":"Set up safety trial environment with comprehensive monitoring","description":"Create isolated trial environment with comprehensive monitoring and safety controls.\n\nFiles to create/modify:\n- scripts/setup-trial-environment.sh (new - environment provisioning)\n- internal/monitoring/trial_monitor.go (new - trial-specific monitoring)\n- configs/trial-cortex.toml (new - trial configuration)\n- scripts/trial-monitoring-dashboard.sh (new - monitoring setup)\n\nAcceptance criteria:\n- Trial environment is isolated from production systems\n- All control API calls are logged with full context and attribution\n- Real-time monitoring detects unsafe patterns and retry loops\n- Safety circuits can automatically abort trial on threshold breaches\n- Evidence capture is comprehensive and tamper-evident\n- Environment can be reset quickly for repeated trials\n\nEnvironment features:\n- Isolated Cortex instance with trial-specific configuration\n- Enhanced API logging with request/response capture\n- Real-time metrics and alerting on operation patterns\n- Safety circuit breakers for automated abort\n- Comprehensive audit trail of all operator actions\n- Rollback/recovery capabilities\n\nMonitoring requirements:\n- Track all API operations with timestamps and context\n- Detect retry loops and excessive failure patterns\n- Monitor resource usage and performance degradation\n- Alert on safety threshold breaches\n- Capture evidence suitable for compliance review\n- Dashboard for real-time trial oversight","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:18:00.481448354+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:18:00.481448354+10:00","dependencies":[{"issue_id":"cortex-c4j.6.2","depends_on_id":"cortex-c4j.6","type":"parent-child","created_at":"2026-02-18T04:18:00.487547337+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-c4j.6.2","depends_on_id":"cortex-c4j.6.1","type":"blocks","created_at":"2026-02-18T04:18:00.594368175+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-c4j.6.3","title":"Execute safety trial and capture compliance evidence","description":"Conduct the actual LLM operator safety trial and capture all required evidence.\n\nFiles to create/modify:\n- evidence/safety-trial-execution-log.md (new - complete trial log)\n- evidence/api-operations-audit.json (new - API call audit trail)\n- evidence/safety-findings-report.md (new - findings and recommendations)\n- scripts/analyze-trial-results.sh (new - automated analysis)\n\nAcceptance criteria:\n- Complete trial execution following documented protocol\n- All control actions captured with API evidence and operator attribution\n- No blind retry loops observed during trial period\n- Any unsafe patterns detected and documented with remediation\n- Findings report includes specific recommendations for production use\n- Evidence package is complete and suitable for compliance review\n\nTrial execution scope:\n- Execute representative operator workflows using LLM guidance\n- Test control API operations: pause/resume, cancel, retry\n- Validate safety guardrails and circuit breaker functionality\n- Document any observed failure modes or concerning patterns\n- Capture timing, resource usage, and performance data\n- Test emergency abort and recovery procedures\n\nEvidence capture requirements:\n- Timestamped log of all operator actions and decisions\n- Complete API audit trail with request/response data\n- Safety monitoring alerts and threshold breaches\n- Performance metrics and resource utilization\n- Any incidents, errors, or unexpected behaviors\n- Operator feedback and usability observations","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:18:11.028112129+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:18:11.028112129+10:00","dependencies":[{"issue_id":"cortex-c4j.6.3","depends_on_id":"cortex-c4j.6","type":"parent-child","created_at":"2026-02-18T04:18:11.110455334+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-c4j.6.3","depends_on_id":"cortex-c4j.6.2","type":"blocks","created_at":"2026-02-18T04:18:11.211671439+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-c4j.7","title":"Produce launch evidence bundle and final go/no-go decision record","description":"Assemble gate-by-gate evidence into a single artifact and record explicit GO/NO-GO signoff.","acceptance_criteria":"1) Evidence bundle includes all P0/P1 gate statuses with links. 2) Open risks and mitigations are explicit. 3) Final decision has approver and timestamp.","status":"open","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T01:59:26.429509759+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T01:59:26.429509759+10:00","labels":["launch","ops","readiness"],"dependencies":[{"issue_id":"cortex-c4j.7","depends_on_id":"cortex-c4j","type":"parent-child","created_at":"2026-02-18T01:59:26.432327012+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-c4j.7","depends_on_id":"cortex-c4j.1","type":"blocks","created_at":"2026-02-18T01:59:26.439934417+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-c4j.7","depends_on_id":"cortex-c4j.2","type":"blocks","created_at":"2026-02-18T01:59:26.446354389+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-c4j.7","depends_on_id":"cortex-c4j.3","type":"blocks","created_at":"2026-02-18T01:59:26.472513698+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-c4j.7","depends_on_id":"cortex-c4j.4","type":"blocks","created_at":"2026-02-18T01:59:26.489266306+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-c4j.7","depends_on_id":"cortex-c4j.5","type":"blocks","created_at":"2026-02-18T01:59:26.496050126+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-c4j.7","depends_on_id":"cortex-c4j.6","type":"blocks","created_at":"2026-02-18T01:59:26.503003932+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-c4j.7.1","title":"Collect and validate all launch readiness gate evidence","description":"Systematically collect evidence from all launch readiness gates and validate completeness.\n\nFiles to create/modify:\n- evidence/gate-evidence-collection.sh (new - automated evidence gathering)\n- evidence/launch-readiness-matrix.md (new - gate status summary)\n- evidence/validation-report.md (new - evidence validation results)\n\nAcceptance criteria:\n- Evidence collected from all P0/P1 launch gates with direct links\n- Gate status matrix shows current state of each readiness criterion\n- Missing or incomplete evidence is identified and tracked\n- Evidence validation confirms authenticity and recency\n- Collection process is repeatable and auditable\n- Evidence package is organized for stakeholder review\n\nEvidence collection scope:\n- Security: authn/authz implementation and audit logging\n- Reliability: burn-in results and SLO scoring\n- Operations: runbooks and operational readiness\n- Data: backup/restore validation and data protection\n- Release: process definition and dry run results\n- Safety: LLM operator trial results and compliance\n\nValidation requirements:\n- Verify evidence timestamp recency and relevance\n- Confirm evidence authenticity and source integrity\n- Check completeness against defined gate criteria\n- Identify any gaps or missing evidence\n- Validate links and references are accessible\n- Ensure evidence format is suitable for decision makers","status":"closed","priority":1,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:18:21.177797494+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:56:30.817788669+10:00","closed_at":"2026-02-18T04:56:30.817788669+10:00","close_reason":"Closed","labels":["stage:qa"],"dependencies":[{"issue_id":"cortex-c4j.7.1","depends_on_id":"cortex-c4j.7","type":"parent-child","created_at":"2026-02-18T04:18:21.19641826+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-c4j.7.2","title":"Conduct final risk assessment and mitigation planning","description":"Analyze remaining risks and create explicit mitigation plans for launch decision.\n\nFiles to create/modify:\n- evidence/risk-assessment-report.md (new - comprehensive risk analysis)\n- evidence/risk-mitigation-plan.md (new - specific mitigation actions)\n- evidence/launch-risk-register.json (new - structured risk data)\n\nAcceptance criteria:\n- All identified risks are explicitly documented with likelihood and impact\n- Mitigation plans are specific and actionable with owners and timelines\n- Residual risks are clearly stated after mitigation\n- Risk assessment includes both technical and operational dimensions\n- Launch criteria are clearly defined with pass/fail thresholds\n- Risk register is suitable for ongoing operational tracking\n\nRisk assessment dimensions:\n- Technical: system reliability, performance, security vulnerabilities\n- Operational: runbook completeness, team readiness, escalation procedures\n- Data: backup/recovery, data integrity, privacy compliance\n- Integration: external dependencies, API compatibility\n- Safety: LLM operation patterns, human oversight requirements\n- Business: customer impact, reputation, competitive considerations\n\nMitigation planning requirements:\n- Specific actions with clear ownership and deadlines\n- Success criteria for each mitigation effort\n- Fallback plans if mitigation efforts fail\n- Resource requirements and availability confirmation\n- Timeline alignment with launch schedule\n- Post-launch monitoring and response plans","status":"open","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:18:29.935900788+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:18:29.935900788+10:00","dependencies":[{"issue_id":"cortex-c4j.7.2","depends_on_id":"cortex-c4j.7","type":"parent-child","created_at":"2026-02-18T04:18:30.002933585+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-c4j.7.2","depends_on_id":"cortex-c4j.7.1","type":"blocks","created_at":"2026-02-18T04:18:30.042065349+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-c4j.7.3","title":"Create final launch evidence bundle and go/no-go decision record","description":"Assemble complete evidence bundle and record formal go/no-go decision with approvals.\n\nFiles to create/modify:\n- evidence/launch-evidence-bundle.md (new - comprehensive evidence package)\n- evidence/go-no-go-decision-record.md (new - formal decision documentation)\n- evidence/launch-readiness-certificate.md (new - stakeholder sign-off)\n- scripts/package-evidence-bundle.sh (new - bundle packaging automation)\n\nAcceptance criteria:\n- Evidence bundle contains all gate evidence with clear pass/fail status\n- Decision record documents explicit GO/NO-GO with detailed rationale\n- All required approvers have formally signed off with timestamps\n- Bundle is packaged for distribution to stakeholders and archive\n- Decision rationale references specific evidence and criteria\n- Launch readiness certificate documents compliance with all requirements\n\nEvidence bundle contents:\n- Executive summary with go/no-go recommendation\n- Gate-by-gate evidence with status and supporting materials\n- Risk assessment and mitigation status\n- Open issues and their disposition\n- Launch timeline and rollback procedures\n- Contact information and escalation procedures\n\nDecision record requirements:\n- Explicit GO or NO-GO decision with timestamp\n- Detailed rationale referencing specific evidence\n- List of conditions/assumptions for GO decision\n- Required approvers with signatures and dates\n- Launch date and key milestones\n- Post-launch monitoring and success criteria","status":"open","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:18:40.166244605+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:18:40.166244605+10:00","dependencies":[{"issue_id":"cortex-c4j.7.3","depends_on_id":"cortex-c4j.7","type":"parent-child","created_at":"2026-02-18T04:18:40.202623069+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-c4j.7.3","depends_on_id":"cortex-c4j.7.2","type":"blocks","created_at":"2026-02-18T04:18:40.236583036+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-c5s","title":"Auto: break down epic cortex-a4s into executable bug/task beads","description":"Epic `cortex-a4s` is still open in project `cortex`.\n\nPolicy: epics should not be assigned directly to coders. Break this epic into concrete `bug`/`task` beads with acceptance criteria so overnight automation can execute them.\n\nEpic title: Scrum master as project point-of-contact via Matrix","status":"in_progress","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:35:07.517527284+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:40:23.849415642+10:00","labels":["stage:review"],"dependencies":[{"issue_id":"cortex-c5s","depends_on_id":"cortex-a4s","type":"discovered-from","created_at":"2026-02-18T02:35:07.553164322+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-c6c","title":"Update stuck detection to use tier-aware timeouts","description":"Update internal/health/stuck.go to use per-tier timeouts from dispatch.timeouts config instead of global stuck_timeout.\n\n- Fast: 15m (was 30m globally)\n- Balanced: 45m\n- Premium: 120m\n\nGetStuckDispatches query needs to join on tier column and compare against tier-specific timeout.\nStuck kill should use backend.Kill() instead of direct KillProcess().\n\nAcceptance: fast tasks killed at 15m, premium tasks allowed to run 120m. Backend-aware kill (tmux vs PID).","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:00:48.458342856+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T18:00:48.458342856+10:00","dependencies":[{"issue_id":"cortex-c6c","depends_on_id":"cortex-hr2","type":"blocks","created_at":"2026-02-17T18:01:41.649405543+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-c6c","depends_on_id":"cortex-hgz","type":"blocks","created_at":"2026-02-17T18:01:42.018542276+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-ceg","title":"Plan pluggable dispatch: headless CLI vs tmux vs openclaw by task complexity","description":"Plan the dispatcher abstraction to support multiple backends based on task characteristics.\n\n## Context\n- Current dispatch is tightly coupled to openclaw agent CLI (~5 lines in dispatch.go)\n- OpenClaw gateway serves comms and planning, not just agent dispatch — that value must be preserved or replaced\n- Headless CLIs (claude, codex, kimi, kilocode) can handle coding tasks directly without a gateway\n- tmux gives observability and session persistence for longer/complex work\n\n## Key Design Questions\n\n### 1. Task routing by complexity/length\n- **Fast tier (≤30min, trivial/chore)**: headless CLI is ideal — fire and forget, low overhead\n- **Balanced tier (31-90min)**: headless CLI or tmux? At what duration does observability matter?\n- **Premium tier (\u003e90min, complex/architecture)**: tmux likely better — attach to watch, survives crashes, can interact if stuck\n- Should routing be tier-based, estimate-based, or label-based?\n\n### 2. When tmux vs headless\n- tmux adds: observability (attach to watch), crash resilience (session persists), ability to interact\n- tmux costs: session management complexity, cleanup of dead sessions, port/name collisions\n- headless adds: simplicity, easy PID tracking (already implemented), lower overhead\n- Decision: what's the threshold? 60min? 'complex' label? premium tier only?\n\n### 3. OpenClaw gateway role\n- Gateway currently handles comms (Matrix?) and planning/coordination between agents\n- If we move coding dispatch to headless CLIs, gateway still needed for:\n  - Inter-agent communication\n  - Task planning and decomposition\n  - Status reporting\n  - Any shared context/memory between agents\n- Need to map which gateway functions are essential vs replaceable\n\n### 4. Pluggable dispatcher interface\n- Abstract dispatch behind a Go interface: Dispatch(ctx, prompt, workDir, opts) -\u003e (handle, err)\n- Backends: headless-cli, tmux, openclaw (keep as option)\n- Config in cortex.toml per-provider or per-tier\n- Process tracking: PID for headless, session name for tmux, PID for openclaw\n\n### 5. Provider mapping\n- Which headless CLIs map to which providers?\n  - claude CLI -\u003e claude-max20 (and free tier via different model flag)\n  - codex CLI -\u003e openai-pro\n  - kimi CLI -\u003e kimi\n  - kilocode -\u003e ?\n- How do thinking levels translate per CLI?\n\n## Deliverable\nArchitecture decision doc + implementation plan for the dispatcher refactor.","design":"## Architecture Decision: Pluggable Dispatch\n\n### Dispatch Backends\n\nThree backends, selected by tier + retry state:\n\n| Backend | When | Implementation |\n|---|---|---|\n| HeadlessCLI | Fast tier, balanced tier (first attempt) | exec.Command + stdout/stderr to log file |\n| Tmux | Premium tier, any retry, 'interactive' label | tmux new-session with remain-on-exit, capture-pane for output |\n| OpenClaw | Comms/reporting only | Existing dispatcher, unchanged |\n\n### Dispatch Routing\n\n```\nFast tier         → always headless\nBalanced tier     → headless on first attempt, tmux on retry\nPremium tier      → always tmux\nAny retry         → tmux (regardless of original tier)\nComms/reports     → openclaw agent (unchanged)\n```\n\n### Provider-to-CLI Mapping\n\n| Tier | CLI | Model | Cost |\n|---|---|---|---|\n| Fast | kilo run --auto | Free gateway (MiniMax, GLM, Kimi K2.5) | Free |\n| Fast | aider --message --yes | Free OpenRouter (Qwen3, DeepSeek R1) | Free |\n| Fast | codex -q | GPT 5.3-spark | API/sub |\n| Balanced | claude -p | Claude Sonnet (Max) | Sub |\n| Balanced | codex -q | GPT 5.3-codex | API/sub |\n| Premium | claude -p | Claude Opus (Max) | Sub |\n| Premium | codex -q | GPT 5.3-codex | API/sub |\n| Premium | kimi | Moonshot | API key |\n| Comms | openclaw agent | Gateway | — |\n\nTest kilo vs aider on fast tier — let learner/retro compare over time.\n\n### Output Capture\n\nAlways capture, all tiers:\n- Headless: redirect stdout/stderr to per-dispatch log file\n- Tmux: capture-pane -p -S - after completion\n- Store path in dispatches table, learner uses for failure analysis\n- Log retention: configurable (default 30 days), old logs pruned on tick\n\n### Prompt Delivery (per CLI)\n\nDifferent CLIs accept prompts differently. Config specifies mode per CLI:\n- `argument`: prompt passed as CLI argument (most CLIs)\n- `stdin`: prompt piped via stdin\n- `tempfile`: prompt written to temp file, path passed as argument\n\nAll modes must handle shell escaping. Tempfile is safest for large prompts.\n\n```toml\n[dispatch.cli.claude]\ncmd = 'claude'\nprompt_mode = 'argument'    # claude -p 'prompt here'\nargs = ['-p', '{prompt}']\nmodel_flag = '--model'\napproval_flags = ['--dangerously-skip-permissions']\n\n[dispatch.cli.codex]\ncmd = 'codex'\nprompt_mode = 'argument'\nargs = ['-q', '{prompt}']\nmodel_flag = '--model'\napproval_flags = ['--auto-approve']\n\n[dispatch.cli.kilo]\ncmd = 'kilo'\nprompt_mode = 'argument'\nargs = ['run', '--auto', '{prompt}']\nmodel_flag = '--model'\napproval_flags = []          # uses kilocode.json permission config\n\n[dispatch.cli.aider]\ncmd = 'aider'\nprompt_mode = 'argument'\nargs = ['--message', '{prompt}', '--yes', '--no-git']\nmodel_flag = '--model'\napproval_flags = ['--yes']\n\n[dispatch.cli.kimi]\ncmd = 'kimi'\nprompt_mode = 'argument'\nargs = ['--print', '{prompt}']\nmodel_flag = ''\napproval_flags = []\n```\n\n### Auto-Approval / Permissions\n\nEach CLI needs autonomous operation flags to prevent hanging on approval prompts:\n- claude: --dangerously-skip-permissions (or granular --allowedTools)\n- codex: --auto-approve or equivalent\n- kilo: permission config in kilocode.json (allow all tools)\n- aider: --yes (auto-confirm all changes)\n- kimi: --print mode is non-interactive by default\n\nApproval flags are part of CLI config, always appended to dispatch command.\nIf a dispatch hangs (no output progress for 5min), treat as stuck.\n\n### Tier-Aware Timeouts\n\nGlobal stuck_timeout replaced with per-tier values:\n\n```toml\n[dispatch.timeouts]\nfast = '15m'\nbalanced = '45m'\npremium = '120m'\n```\n\nFast tasks stuck at 15min are clearly broken. Premium tasks may legitimately run 90min+.\nStuck detection uses tier of the dispatch, not global config.\n\n### Concurrent Dispatch \u0026 Git Isolation\n\nmax_per_tick=3 means parallel dispatches. Same-project conflicts handled by branch isolation:\n\n1. Before dispatch, create branch: git checkout -b ctx/{bead-id} from main\n2. Agent works on its branch\n3. On completion, cortex merges branch to main (or flags conflict for retry)\n4. On failure/stuck, branch is abandoned (cleaned up after retention period)\n\nBranch naming: ctx/{bead-id} (e.g. ctx/cortex-a1b)\nCleanup: branches older than 7 days with no activity pruned on health tick.\n\nAlternative: limit to 1 concurrent dispatch per project (simpler, less throughput).\nDecision: start with branch isolation, fall back to serial if merge conflicts are frequent.\n\n### CLI Fallback Within Tier\n\nIf primary CLI fails (not found, auth error, crash on startup), try next CLI in tier before tier downgrade:\n\n```\nbalanced tier: claude → codex → (tier downgrade to fast)\npremium tier: claude → codex → kimi → (tier downgrade to balanced)\nfast tier: kilo → aider → codex/spark → (tier upgrade to balanced)\n```\n\nCLI failure detected by: non-zero exit within 10s of start (distinguishes 'CLI broken' from 'task failed after working').\nDistinct from tier downgrade (which is rate-limit driven).\n\n### Model Selection\n\nEach provider maps to a CLI + model. Model passed via CLI-specific flag:\n\n```toml\n[providers.claude-max20]\ntier = 'balanced'\nauthed = true\ncli = 'claude'\nmodel = 'sonnet'\n\n[providers.openai-codex]\ntier = 'premium'\nauthed = true\ncli = 'codex'\nmodel = 'gpt-5.3-codex'\n\n[providers.openai-spark]\ntier = 'fast'\nauthed = true\ncli = 'codex'\nmodel = 'gpt-5.3-spark'\n\n[providers.kilo-free]\ntier = 'fast'\nauthed = false\ncli = 'kilo'\nmodel = 'minimax/m2.1'\n\n[providers.aider-free]\ntier = 'fast'\nauthed = false\ncli = 'aider'\nmodel = 'openrouter/qwen3-coder'\n```\n\nDispatch builds command: {cli} {args with prompt} {model_flag} {model} {approval_flags}\n\n### Health Monitoring (Extended)\n\nBeyond gateway health, monitor dispatch infrastructure:\n\n1. Gateway service (existing): systemctl check + auto-restart\n2. tmux server: `tmux info` on health tick, restart if dead\n3. CLI availability: `which {cli}` for each configured CLI on startup + hourly\n4. Auth validity: dry-run or version command per CLI on startup\n   - claude --version, codex --version, kilo --version\n   - Log warning if CLI missing, error if all CLIs in a tier unavailable\n5. Branch cleanup: prune ctx/* branches older than 7 days\n\nHealth events table extended with event types:\n- cli_missing, cli_auth_failed, tmux_server_down, branch_cleanup\n\n### Go Interface\n\n```go\ntype Backend interface {\n    Dispatch(ctx context.Context, opts DispatchOpts) (Handle, error)\n    Status(handle Handle) (DispatchStatus, error)\n    CaptureOutput(handle Handle) (string, error)\n    Kill(handle Handle) error\n    Cleanup(handle Handle) error\n}\n\ntype DispatchOpts struct {\n    BeadID     string\n    Agent      string\n    Prompt     string\n    WorkDir    string\n    CLI        string            // claude, codex, kilo, aider, kimi, openclaw\n    CLIArgs    []string          // from config template\n    Model      string\n    ModelFlag  string\n    ApprovalFlags []string\n    PromptMode string            // argument, stdin, tempfile\n    Env        map[string]string\n    Timeout    time.Duration     // tier-aware\n    LogPath    string            // where to write stdout/stderr\n    Branch     string            // ctx/{bead-id} for git isolation\n}\n\ntype Handle struct {\n    ID         string   // PID (string) for headless, session name for tmux\n    Backend    string   // headless, tmux, openclaw\n    LogPath    string   // output capture location\n    Branch     string   // git branch name\n}\n\ntype DispatchStatus struct {\n    State    string  // running, exited, gone\n    ExitCode int\n    Duration time.Duration\n}\n```\n\n### Config Shape (Complete)\n\n```toml\n[dispatch]\nlog_dir = '~/.local/share/cortex/logs'\nlog_retention_days = 30\n\n[dispatch.routing]\nfast = 'headless'\nbalanced = 'headless'\npremium = 'tmux'\ncomms = 'openclaw'\nretry_backend = 'tmux'\n\n[dispatch.timeouts]\nfast = '15m'\nbalanced = '45m'\npremium = '120m'\n\n[dispatch.git]\nbranch_prefix = 'ctx'\nbranch_cleanup_days = 7\nmerge_strategy = 'rebase'     # or 'merge'\nmax_concurrent_per_project = 3\n\n[dispatch.tmux]\nhistory_limit = 50000\nsession_prefix = 'ctx'\n\n[dispatch.cli.claude]\ncmd = 'claude'\nprompt_mode = 'argument'\nargs = ['-p', '{prompt}']\nmodel_flag = '--model'\napproval_flags = ['--dangerously-skip-permissions']\n\n[dispatch.cli.codex]\ncmd = 'codex'\nprompt_mode = 'argument'\nargs = ['-q', '{prompt}']\nmodel_flag = '--model'\napproval_flags = ['--auto-approve']\n\n[dispatch.cli.kilo]\ncmd = 'kilo'\nprompt_mode = 'argument'\nargs = ['run', '--auto', '{prompt}']\nmodel_flag = '--model'\napproval_flags = []\n\n[dispatch.cli.aider]\ncmd = 'aider'\nprompt_mode = 'argument'\nargs = ['--message', '{prompt}', '--yes', '--no-git']\nmodel_flag = '--model'\napproval_flags = ['--yes']\n\n[dispatch.cli.kimi]\ncmd = 'kimi'\nprompt_mode = 'argument'\nargs = ['--print', '{prompt}']\nmodel_flag = ''\napproval_flags = []\n\n[providers.claude-opus]\ntier = 'premium'\nauthed = true\ncli = 'claude'\nmodel = 'opus'\n\n[providers.claude-sonnet]\ntier = 'balanced'\nauthed = true\ncli = 'claude'\nmodel = 'sonnet'\n\n[providers.openai-codex]\ntier = 'premium'\nauthed = true\ncli = 'codex'\nmodel = 'gpt-5.3-codex'\n\n[providers.openai-spark]\ntier = 'fast'\nauthed = true\ncli = 'codex'\nmodel = 'gpt-5.3-spark'\n\n[providers.kilo-free]\ntier = 'fast'\nauthed = false\ncli = 'kilo'\nmodel = 'minimax/m2.1'\n\n[providers.aider-free]\ntier = 'fast'\nauthed = false\ncli = 'aider'\nmodel = 'openrouter/qwen3-coder'\n\n[providers.kimi]\ntier = 'premium'\nauthed = true\ncli = 'kimi'\nmodel = 'moonshot-v1'\n```\n\n### Migration Steps\n\n1. Add Backend interface + HeadlessCLI, Tmux, OpenClaw implementations\n2. Add dispatch.cli, dispatch.routing, dispatch.timeouts config sections\n3. Add log_path, session_name, branch columns to dispatches table\n4. Update provider config: add cli + model fields\n5. Update scheduler: pick backend based on tier + retry count\n6. Update scheduler: create ctx/ branch before dispatch, merge after\n7. Update health monitor: tier-aware timeouts, CLI availability checks, tmux health, branch cleanup\n8. Update learner: read captured output for failure/success analysis\n9. Update rate limiter: CLI fallback within tier before tier downgrade\n10. Keep existing OpenClaw dispatcher for comms — no changes to reporter","status":"closed","priority":2,"issue_type":"feature","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:09:32.66414023+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T18:31:14.059196885+10:00","closed_at":"2026-02-17T18:31:14.059196885+10:00","close_reason":"Design doc complete — architecture decision and implementation plan fully documented in design field"}
{"id":"cortex-cm5","title":"Auto: churn guard blocked bead cortex-34e (6 dispatches/1h0m0s)","description":"Bead `cortex-34e` in project `cortex` exceeded churn threshold (6 dispatches in 1h0m0s) and was blocked from further overnight dispatch.\n\nPlease investigate root cause, split work into smaller tasks if needed, and add hardening/tests before re-enabling.\n\nBead title: Auto: break down epic cortex-a6p into executable bug/task beads\nBead type: task","status":"closed","priority":1,"issue_type":"bug","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:07:25.623276613+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:21:48.43378028+10:00","closed_at":"2026-02-18T04:21:48.43378028+10:00","close_reason":"Root cause confirmed from runtime history: bead cortex-34e was dispatched 6 times (dispatches 1111,1117,1122,1157,1162,1164) between 2026-02-17 17:10:18 and 18:05:27 UTC while linked epic cortex-a6p was already closed, creating a no-progress loop until churn guard blocked it. Hardened scheduler with stale-breakdown reconciliation in internal/scheduler/scheduler.go: open auto-breakdown tasks are detected only when title pattern + discovered-from dependency both match a closed epic, then auto-closed via existing beads.CloseBeadCtx and suppressed from redispatch in the same tick. Added regression coverage in internal/scheduler/churn_guard_test.go (TestShouldAutoCloseEpicBreakdownTask). Validation: go test ./internal/scheduler -run TestHasActiveChurnEscalation\\|TestShouldAutoCloseEpicBreakdownTask -count=1 and go test ./... passed.","labels":["stage:review"],"dependencies":[{"issue_id":"cortex-cm5","depends_on_id":"cortex-34e","type":"discovered-from","created_at":"2026-02-18T04:07:25.63722755+10:00","created_by":"Simon Heikkila"}],"comments":[{"id":2,"issue_id":"cortex-cm5","author":"Simon Heikkila","text":"Updating close reason to reflect final committed implementation details","created_at":"2026-02-17T18:21:48Z"}]}
{"id":"cortex-cm5.1","title":"Add completion checklist for epic breakdown tasks to prevent churn","description":"Create process improvements to prevent epic breakdown tasks from churning due to incomplete closure.\n\nRoot cause analysis:\n- cortex-34e successfully broke down epic cortex-a6p into 9 concrete tasks\n- Epic was properly closed with detailed reason\n- But the breakdown task itself (cortex-34e) remained open in stage:review\n- System continued dispatching agents to work on already-completed task\n- Resulted in 6 failed dispatches and churn guard activation\n\nFiles to create/modify:\n- AGENTS.md (add epic breakdown completion checklist)\n- internal/scheduler/completion.go (add epic task closure validation)\n\nAcceptance criteria:\n- Epic breakdown tasks have explicit completion checklist in AGENTS.md\n- Checklist includes: verify epic closed, verify subtasks created, close breakdown task\n- Add process validation that detects when epic is closed but breakdown task is open\n- Scheduler should auto-close breakdown tasks when referenced epic is closed\n- Unit tests verify auto-closure logic works correctly\n\nProcess improvements:\n- Clear instructions that epic breakdown = close both epic AND breakdown task\n- Automated detection of completed but unclosed breakdown tasks\n- Warning/auto-fix for this specific failure pattern\n- Documentation update to make this pattern explicit in workflow guides","status":"closed","priority":3,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:12:25.911063894+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:20:10.993041256+10:00","closed_at":"2026-02-18T04:20:10.993041256+10:00","close_reason":"Completed as part of cortex-cm5 resolution: AGENTS.md already includes explicit epic-breakdown completion checklist (close epic + close breakdown task), and scheduler hardening now auto-closes stale breakdown tasks when discovered-from epic is closed (internal/scheduler/scheduler.go). Added regression test TestShouldAutoCloseEpicBreakdownTask in internal/scheduler/churn_guard_test.go.","dependencies":[{"issue_id":"cortex-cm5.1","depends_on_id":"cortex-cm5","type":"parent-child","created_at":"2026-02-18T04:12:25.914395769+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-cm5.2","title":"Add churn guard observability and root cause analysis tools","description":"Improve churn guard diagnostic capabilities to identify root causes faster and prevent similar issues.\n\nProblem identified:\n- Churn guard blocked cortex-34e but root cause (forgotten task closure) wasn't immediately obvious\n- Need better diagnostics to identify patterns like completed-but-unclosed tasks\n- Should surface common churn patterns and suggested fixes\n\nFiles to create/modify:\n- internal/scheduler/churn.go (add churn pattern analysis)\n- internal/api/churn_analysis.go (new - churn diagnostic endpoint)\n- internal/learner/churn_patterns.go (new - pattern detection)\n\nAcceptance criteria:\n- API endpoint /churn-analysis/{beadId} provides detailed churn diagnosis\n- Common patterns detected: completed-but-unclosed, missing-acceptance-criteria, config-errors\n- Suggested fixes provided for each detected pattern\n- Churn events include pattern classification and remediation hints\n- Dashboard shows churn trends and common failure modes\n- Unit tests verify pattern detection accuracy\n\nDiagnostic features:\n- Detect when related epic/parent is closed but task is open\n- Identify dispatch failure patterns (config errors, missing files, etc.)\n- Surface bead relationship inconsistencies\n- Provide specific remediation suggestions per pattern type\n- Track churn patterns over time for process improvement","status":"open","priority":3,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:12:36.877328926+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:12:36.877328926+10:00","dependencies":[{"issue_id":"cortex-cm5.2","depends_on_id":"cortex-cm5","type":"parent-child","created_at":"2026-02-18T04:12:36.881703686+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-cne","title":"Auto: churn guard blocked bead cortex-evu.3 (7 dispatches/1h0m0s)","description":"Bead `cortex-evu.3` in project `cortex` exceeded churn threshold (7 dispatches in 1h0m0s) and was blocked from further overnight dispatch.\n\nPlease investigate root cause, split work into smaller tasks if needed, and add hardening/tests before re-enabling.\n\nBead title: Add concurrency and race condition tests\nBead type: task","status":"open","priority":1,"issue_type":"bug","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:00:14.051266881+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:02:08.405633483+10:00","dependencies":[{"issue_id":"cortex-cne","depends_on_id":"cortex-evu.3","type":"discovered-from","created_at":"2026-02-18T02:00:14.053866809+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-cv4","title":"Wire stuck/zombie health checks into scheduler loop","description":"Stuck/zombie detection and cleanup logic exists in internal/health (stuck_timeout/max_retries, zombie process checks) but is not currently invoked from runtime main/scheduler loop. Implement periodic execution so stale dispatches are cleaned up and retries/termination are triggered according to config.","notes":"**Review Result: APPROVED**\n\n**Excellent Implementation - Comprehensive Health Monitoring Integration**\n\n## Two-Tiered Health Check Architecture\n\n**Dual Integration Approach**:\n\n1. **Scheduler Integration**: RunTick calls runHealthChecks on every tick for immediate cleanup\n2. **Independent Health Monitor**: Separate goroutine with configurable interval (default: 5min)\n\n## Stuck Dispatch Detection\n\n**CheckStuckDispatches Implementation**:\n- Uses configured StuckTimeout from config.General\n- Handles both PID-based and tmux session dispatchers  \n- Proper process/session termination\n- Tier escalation on retry (fast → balanced → premium)\n- Max retry enforcement with permanent failure marking\n- Health event recording and stage tracking\n\n## Zombie Process Cleanup\n\n**CleanZombies Implementation**:\n- PID-based: pgrep openclaw agents vs tracked PIDs\n- Session-based: ListCortexSessions + SessionStatus for orphans\n- Kills orphaned processes/sessions not tracked in database\n- Health event recording for cleanup actions\n\n## Configuration Integration\n\n**Proper Config Support**:\n- StuckTimeout, MaxRetries in config.General\n- Health.CheckInterval with 5min default\n- Conditional execution (skips if StuckTimeout = 0)\n- All config fields have TOML tags and validation\n\n## Testing \u0026 Quality\n\n**Test Coverage**:\n- Scheduler health check tests pass\n- Disabled health check tests pass  \n- All existing scheduler tests still pass\n- Clean build with no compilation errors\n- Health module tests pass\n\n## Architecture Assessment\n\n**Design Excellence**:\n- Clean separation of concerns between health module and scheduler\n- Dual-tier approach provides immediate and periodic cleanup\n- Proper abstraction via DispatcherInterface\n- Configuration-driven behavior\n- No conflicts between health check approaches\n\n## Acceptance Criteria Status\n\n- Periodic execution: IMPLEMENTED via scheduler ticks and health monitor\n- Stale dispatch cleanup: IMPLEMENTED with comprehensive stuck detection\n- Retry/termination per config: IMPLEMENTED with StuckTimeout, MaxRetries\n- Zombie process cleanup: IMPLEMENTED for both PID and session-based\n- Runtime integration: IMPLEMENTED in main.go and scheduler loop\n\nOutstanding implementation with robust health monitoring, error recovery, and observability.\n\nApproved for stage:qa","status":"closed","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T20:48:03.060482475+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T21:33:08.275761948+10:00","closed_at":"2026-02-17T21:33:08.275761948+10:00","close_reason":"Closed","labels":["stage:qa"]}
{"id":"cortex-des","title":"Extend health monitor: CLI checks, tmux health, branch cleanup","description":"Add to internal/health/health.go:\n\n1. CLI availability: on startup + hourly, run 'which {cli}' for each configured CLI. Log warning if missing, error if all CLIs in a tier unavailable.\n2. tmux server health: 'tmux info' on health tick. If dead and tmux backend configured, log error.\n3. Auth spot-check: run '{cli} --version' for each CLI to verify it executes. Not a full auth test but catches broken installs.\n4. Branch cleanup: prune ctx/* branches older than dispatch.git.branch_cleanup_days.\n5. Log cleanup: delete dispatch log files older than dispatch.log_retention_days.\n\nNew health event types: cli_missing, cli_auth_failed, tmux_server_down, branch_cleanup, log_cleanup.\n\nAcceptance: health monitor catches missing CLIs, dead tmux, stale branches/logs.","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:00:56.138600204+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T18:00:56.138600204+10:00","dependencies":[{"issue_id":"cortex-des","depends_on_id":"cortex-v2h","type":"blocks","created_at":"2026-02-17T18:01:45.772616409+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-des","depends_on_id":"cortex-ejd","type":"blocks","created_at":"2026-02-17T18:01:45.979020964+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-des","depends_on_id":"cortex-grt","type":"blocks","created_at":"2026-02-17T18:01:46.137881315+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-djq","title":"tmp-claim-test2","description":"temp","status":"open","priority":3,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T23:22:39.078133671+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T23:22:39.547783138+10:00","ephemeral":true}
{"id":"cortex-dwc","title":"Build 7-day burn-in summary generator","description":"Create final burn-in summary generator that produces comprehensive 7-day launch evidence artifacts.\n\n## Goal\nGenerate the final 7-day burn-in summary that serves as launch evidence for go/no-go decisions.\n\n## Scope\n- Aggregate 7 days of daily reports and metrics\n- Generate comprehensive launch evidence document  \n- Include trend analysis and summary statistics\n- Output in multiple formats (markdown, JSON)\n- Store as official launch evidence artifact\n\n## Implementation  \nCreate :\n- Accept 7-day date range  \n- Collect daily metrics for entire period\n- Generate comprehensive summary with trends\n- Output both human-readable and machine-readable formats\n- Store as launch evidence artifacts\n\n## Summary Report Structure\n```markdown\n# Cortex 7-Day Burn-in Summary\n**Period**: 2026-02-11 to 2026-02-18  \n**Overall Result**: ❌ NOT READY FOR LAUNCH\n\n## Executive Summary\nSystem showed instability with 3.33% unknown failures exceeding 2% threshold. \nIntervention rate within acceptable limits. Critical events rare.\n\n## SLO Performance\n\n### 7-Day Metrics\n| Metric | Result | Threshold | Status |\n|--------|--------|-----------|--------|  \n| Unknown/Disappeared Rate | 3.33% | \u003c 2% | ❌ FAIL |\n| Intervention Rate | 8.67% | \u003c 10% | ✅ PASS |\n| Critical Events | 3 total | \u003c 5 | ✅ PASS |\n| System Uptime | 99.2% | \u003e 99% | ✅ PASS |\n\n### Daily Trends\n- Day 1-3: Stable, all metrics passing\n- Day 4-6: Unknown failures increased  \n- Day 7: Partial recovery\n\n## Launch Decision\n**RECOMMEND NO-GO**: Unknown failure rate exceeded threshold\n**Blockers**: Session stability issues require investigation  \n**Est. Time to Resolution**: 2-3 days with focused effort\n```\n\n## Acceptance Criteria\n1) Aggregates full 7-day period data accurately\n2) Includes executive summary with launch recommendation  \n3) Shows daily trends and patterns over the period\n4) Provides clear go/no-go decision with reasoning\n5) Outputs both markdown report and JSON evidence  \n6) Stores as official launch evidence artifacts","status":"open","priority":3,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:34:09.868448762+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:34:09.868448762+10:00","labels":["7-day","evidence","launch","summary"],"dependencies":[{"issue_id":"cortex-dwc","depends_on_id":"cortex-7am","type":"blocks","created_at":"2026-02-18T02:34:40.53958983+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-dxj","title":"Auto: churn guard blocked bead cortex-84h (6 dispatches/1h0m0s)","description":"Bead `cortex-84h` in project `cortex` exceeded churn threshold (6 dispatches in 1h0m0s) and was blocked from further overnight dispatch.\n\nPlease investigate root cause, split work into smaller tasks if needed, and add hardening/tests before re-enabling.\n\nBead title: Runbook: backup/restore drill evidence consolidation\nBead type: task","status":"closed","priority":1,"issue_type":"bug","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T03:57:26.106883247+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:07:38.779600681+10:00","closed_at":"2026-02-18T04:07:38.779600681+10:00","close_reason":"Root cause confirmed from runtime evidence: bead cortex-84h failed repeatedly with context-limit rejections (dispatches 1105/1113/1147/1152/1158 all context_limit_rejected; input lengths grew 173053 -\u003e 184615), while the active OpenClaw session for cortex-coder was saturated (sessions.json shows agent:cortex-coder:main contextTokens=200000 totalTokens=200000). Hardening fix: internal/dispatch/dispatch.go now forces an explicit fresh OpenClaw session per dispatch by generating a unique session_id in the shared shell wrapper and passing --session-id on both normal and fallback invocations, preventing cross-task context accumulation. Tests added: TestOpenclawShellScript_UsesExplicitSessionID and TestOpenclawCommandArgs_PassesSessionID in internal/dispatch/dispatch_test.go. Verification: go test ./internal/dispatch -run 'TestOpenclawShellScript_UsesExplicitSessionID|TestOpenclawCommandArgs_PassesSessionID' -count=1, go test ./internal/scheduler -run 'TestDetectTerminalOutputFailure_OpenClawContextLimitRejection|TestCheckRunningDispatches_ContextLimitRejectedOutputMarksFailed' -count=1, and go test ./internal/scheduler -count=1 passed.","dependencies":[{"issue_id":"cortex-dxj","depends_on_id":"cortex-84h","type":"discovered-from","created_at":"2026-02-18T03:57:26.149616882+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-e3f","title":"Create chief scrum master agent role definition","description":"Add Chief Scrum Master role to agent system for cross-project coordination.\n\n## Goal\nCreate the Chief Scrum Master agent role with appropriate responsibilities and configuration.\n\n## Scope\nAdd Chief Scrum Master to internal/team/team.go with focused role definition:\n\n## Role Responsibilities\n- Cross-project coordination and communication\n- Resource allocation recommendations  \n- Cross-team impediment escalation\n- Multi-project status synthesis\n- Coordination via Matrix room\n\n## Implementation\n- Add \"chief-scrum\" role to existing roles map in team.go\n- Create focused ROLE.md content for Chief SM responsibilities  \n- Role is global (not project-prefixed like other agents)\n- Agent ID: \"cortex-chief-scrum\" or from config\n- Uses coordination Matrix room (not project-specific)\n\n## Agent Characteristics\n- Global scope (sees all projects)\n- Premium tier model (Opus for reasoning)\n- Communicates in coordination room\n- Focuses on coordination, not individual bead refinement\n\n## Acceptance Criteria\n1) Chief scrum role exists in team.go roles map\n2) Role definition includes cross-project responsibilities\n3) Agent can be created with ResolveAgent(\"cortex-chief-scrum\", \"chief-scrum\")\n4) Role content focuses on coordination rather than individual tasks\n5) Integration with existing agent creation system works correctly\n\n## Dependencies  \n- Requires cortex-1ik (chief config schema)\n\n## Files to Modify\n- internal/team/team.go (add chief-scrum role)\n- May need to create or modify agent ROLE.md content","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:44:16.561082056+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:44:16.561082056+10:00","labels":["agent","chief","coordination","role"],"dependencies":[{"issue_id":"cortex-e3f","depends_on_id":"cortex-1ik","type":"blocks","created_at":"2026-02-18T02:44:41.115954589+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-ejd","title":"Implement Tmux backend","description":"Create internal/dispatch/tmux.go implementing Backend interface.\n\n- SessionName: ctx-{project}-{bead-id}-{timestamp}, sanitize dots/colons to dashes\n- Dispatch: tmux new-session -d -s {name} -c {workdir} '{cmd}' with remain-on-exit on, history-limit from config\n- Environment variables set inline in command string (not set-environment)\n- Status: tmux display-message -t {name} -p '#{pane_dead} #{pane_dead_status}'\n  - Returns running/exited/gone + exit code\n- CaptureOutput: tmux capture-pane -t {name} -p -S -\n- Kill: send C-c, wait 5s, tmux kill-session -t {name}\n- Cleanup: kill dead sessions, list with tmux list-sessions filtered by prefix\n- ListCortexSessions: find all ctx-* sessions for orphan detection\n\nAcceptance: can dispatch any CLI inside tmux. Attach to watch. Exit codes captured. Dead sessions cleaned.","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:00:11.154816007+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T18:00:11.154816007+10:00","dependencies":[{"issue_id":"cortex-ejd","depends_on_id":"cortex-hr2","type":"blocks","created_at":"2026-02-17T18:01:22.919643216+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-ejd","depends_on_id":"cortex-q3c","type":"blocks","created_at":"2026-02-17T18:01:23.295677877+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-evu","title":"Test coverage gaps","description":"Several packages have zero or insufficient test coverage. The learner package (reporter, retro, outcomes) is completely untested. No scheduler end-to-end tests. No concurrency/race condition tests.\n\nKey deliverables:\n- Learner package tests (reporter, retro, outcomes)\n- Scheduler RunTick end-to-end test\n- Concurrency/race condition tests (go test -race)\n- cmd/cortex integration test\n- Failure injection tests (DB failure mid-transaction)","status":"open","priority":2,"issue_type":"epic","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:57:33.885212764+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T17:57:33.885212764+10:00"}
{"id":"cortex-evu.1","title":"Add learner package tests","description":"The entire learner package (reporter.go, retro.go, outcomes.go) has ZERO tests.\n\nCreate test files:\n\ninternal/learner/reporter_test.go:\n- Test SendDigest produces correct markdown format\n- Test SendAlert dedup (same alert within 1h suppressed)\n- Test SendAlert after 1h sends again\n- Test dispatchMessage calls dispatcher correctly\n\ninternal/learner/retro_test.go:\n- Test GenerateWeeklyRetro with sample dispatch data\n- Test generateRecommendations with high failure rate provider\n- Test generateRecommendations with high misclassification tier\n- Test FormatRetroMarkdown produces valid markdown table\n- Test with empty data (no dispatches in window)\n\ninternal/learner/outcomes_test.go:\n- Test GetProviderStats aggregation correctness\n- Test GetProviderStats with multiple providers\n- Test GetTierAccuracy with underestimated/overestimated cases\n- Test GetProjectVelocity calculation\n- Test with zero dispatches (edge case)\n\nAll tests should use an in-memory SQLite DB with seeded test data.\n\nAcceptance: All learner package functions tested, edge cases covered, tests pass","notes":"**Review Result: Changes Needed**\n\n**Issue**: No implementation found - none of the required test files exist.\n\n**Missing Files**: All 3 required test files are missing:\n- ❌  - does not exist\n- ❌  - does not exist  \n- ❌  - does not exist\n\n**Source Files Available** (for reference during implementation):\n- ✅  - Reporter struct with SendDigest, SendAlert, dispatchMessage\n- ✅  - RetroReport, GenerateWeeklyRetro, generateRecommendations, FormatRetroMarkdown\n- ✅  - ProviderStats, TierAccuracy, ProjectVelocity data analysis functions\n\n**Required Test Scenarios** (0 implemented):\n\n**reporter_test.go**:\n- ❌ Test SendDigest produces correct markdown format\n- ❌ Test SendAlert dedup (same alert within 1h suppressed) \n- ❌ Test SendAlert after 1h sends again\n- ❌ Test dispatchMessage calls dispatcher correctly\n\n**retro_test.go**:\n- ❌ Test GenerateWeeklyRetro with sample dispatch data\n- ❌ Test generateRecommendations with high failure rate provider\n- ❌ Test generateRecommendations with high misclassification tier  \n- ❌ Test FormatRetroMarkdown produces valid markdown table\n- ❌ Test with empty data (no dispatches in window)\n\n**outcomes_test.go**:\n- ❌ Test GetProviderStats aggregation correctness\n- ❌ Test GetProviderStats with multiple providers\n- ❌ Test GetTierAccuracy with underestimated/overestimated cases\n- ❌ Test GetProjectVelocity calculation\n- ❌ Test with zero dispatches (edge case)\n\n**Required Infrastructure**: All tests should use in-memory SQLite DB with seeded test data\n\n**Action Required**: Complete implementation of all 3 test files with comprehensive coverage before returning to review.\n\nTransitioned back to stage:coding for missing implementation.","status":"closed","priority":2,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:00:53.781414746+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:11:01.848775558+10:00","closed_at":"2026-02-18T02:11:01.848775558+10:00","close_reason":"Implemented learner test suite: added reporter_test.go, retro_test.go, outcomes_test.go with in-memory SQLite seeded fixtures; verified with go test ./internal/learner and go test ./...","labels":["stage:coding"],"dependencies":[{"issue_id":"cortex-evu.1","depends_on_id":"cortex-evu","type":"parent-child","created_at":"2026-02-17T18:00:53.784186502+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-evu.2","title":"Add scheduler RunTick end-to-end test","description":"No test exercises the full RunTick pipeline. Individual pieces are tested but the integration isn't.\n\nCreate internal/scheduler/scheduler_test.go:\n\nTest scenarios:\n1. **Happy path**: project with 2 ready beads, providers available → dispatches 2\n2. **Rate limited**: all authed providers exhausted → uses free tier\n3. **All providers exhausted**: nothing available → dispatches 0, logs warning\n4. **Already dispatched**: bead already running → skips\n5. **Epic skipped**: bead type=epic → skipped\n6. **Max per tick**: 5 ready beads, max_per_tick=2 → dispatches 2\n7. **Agent busy**: agent already has running dispatch → skips bead\n8. **Multiple projects**: 2 projects, priority ordering respected\n9. **Dependency filtering**: bead with unresolved dep → not in ready list\n\nTest infrastructure:\n- Mock Dispatcher that records calls instead of spawning processes\n- In-memory SQLite store with seeded data\n- Mock beads.ListBeads that returns controlled bead lists\n- Controlled config with test providers/tiers\n\nAcceptance: All 9 scenarios tested, mock infrastructure reusable, tests pass","notes":"**Review Result: Changes Needed**\n\n**Issue**: No implementation found - the required test file does not exist.\n\n**Missing Files**:\n-  - **Does not exist**\n\n**Expected Implementation**:\nThe issue requires a comprehensive end-to-end test file covering 9 test scenarios:\n\n1. ✗ **Happy path**: project with 2 ready beads, providers available → dispatches 2\n2. ✗ **Rate limited**: all authed providers exhausted → uses free tier  \n3. ✗ **All providers exhausted**: nothing available → dispatches 0, logs warning\n4. ✗ **Already dispatched**: bead already running → skips\n5. ✗ **Epic skipped**: bead type=epic → skipped\n6. ✗ **Max per tick**: 5 ready beads, max_per_tick=2 → dispatches 2\n7. ✗ **Agent busy**: agent already has running dispatch → skips bead\n8. ✗ **Multiple projects**: 2 projects, priority ordering respected\n9. ✗ **Dependency filtering**: bead with unresolved dep → not in ready list\n\n**Required Test Infrastructure**:\n- ✗ Mock Dispatcher that records calls instead of spawning processes\n- ✗ In-memory SQLite store with seeded data\n- ✗ Mock beads.ListBeads that returns controlled bead lists\n- ✗ Controlled config with test providers/tiers\n\n**Context Found**:\n- ✅ Existing test files: complexity_test.go, role_test.go, prompt_test.go \n- ✅ Main scheduler.go with RunTick implementation exists\n- ✅ Integration points identified: store, dispatch, beads, config\n\n**Action Required**:\n1. Create  from scratch\n2. Implement all 9 required test scenarios\n3. Build proper mock infrastructure for reusable testing\n4. Ensure all tests pass\n\n**Next Steps**: Complete implementation before returning to review.\n\nTransitioned back to stage:coding for missing implementation.","status":"open","priority":2,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:00:59.580331566+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T01:22:29.266854354+10:00","labels":["code","stage:coding","test"],"dependencies":[{"issue_id":"cortex-evu.2","depends_on_id":"cortex-evu","type":"parent-child","created_at":"2026-02-17T18:00:59.583406157+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-evu.3","title":"Add concurrency and race condition tests","description":"No race condition testing exists. Multiple goroutines access shared state (store, rate limiter, config).\n\nTests to add:\n\n1. **Store concurrent access**: parallel RecordDispatch + GetRunningDispatches\n   - SQLite WAL mode should handle this but verify\n\n2. **Rate limiter concurrent access**: parallel CanDispatchAuthed + RecordAuthedDispatch\n   - Verify atomic counting under concurrent access\n\n3. **Scheduler + Health concurrent**: RunTick and CheckStuckDispatches running simultaneously\n   - Both read/write dispatches table\n\n4. **Config reload concurrent**: SIGHUP reload during RunTick\n   - Config pointer swap must be atomic\n\n5. **Reporter dedup concurrent**: parallel SendAlert calls\n   - alertSent map accessed under mutex\n\nRun all with: go test -race ./...\n\nAdd to Makefile: make test-race target\n\nAcceptance: All concurrent scenarios tested, go test -race passes with zero races detected","notes":"**Review Result: Changes Needed**\n\n**Issue**: Concurrency tests are severely incomplete. Only 1 basic test exists out of 5 required scenarios.\n\n**Missing Implementation**:\n\n1. **Makefile**: No `test-race` target added\n   - Required: `make test-race` that runs `go test -race ./...`\n\n2. **Store concurrent access**: Only has basic `TestConcurrentAccess`\n   - Missing: parallel `RecordDispatch` + `GetRunningDispatches` test\n   - Current test only covers `RecordProviderUsage`\n\n3. **Rate limiter concurrent access**: No tests found\n   - Missing: parallel `CanDispatchAuthed` + `RecordAuthedDispatch` test\n   - Missing: verify atomic counting under concurrent access\n\n4. **Scheduler + Health concurrent**: No tests found\n   - Missing: `RunTick` and `CheckStuckDispatches` running simultaneously\n   - Need to test both read/write dispatches table concurrently\n\n5. **Config reload concurrent**: No tests found\n   - Missing: SIGHUP reload during `RunTick` test\n   - Need to verify config pointer swap is atomic\n\n6. **Reporter dedup concurrent**: No reporter tests exist at all\n   - Missing: parallel `SendAlert` calls test\n   - Missing: `alertSent` map accessed under mutex verification\n\n**Race Detection**: Unable to complete `go test -race ./...` - tests may be hanging or have issues.\n\n**Action Required**: \n1. Add comprehensive concurrency tests for all 5 scenarios\n2. Add `make test-race` target to Makefile  \n3. Ensure `go test -race ./...` passes with zero races detected\n4. Verify \u003e80% coverage on concurrent access paths\n\nTransitioned back to stage:coding for complete implementation.","status":"open","priority":2,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:01:04.677579028+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T23:43:11.456695109+10:00","labels":["code","stage:coding","test"],"dependencies":[{"issue_id":"cortex-evu.3","depends_on_id":"cortex-evu","type":"parent-child","created_at":"2026-02-17T18:01:04.68040738+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-evu.4","title":"Add cmd/cortex integration test","description":"The main entry point has no tests. Add an integration test that starts and stops cortex.\n\nCreate cmd/cortex/main_test.go:\n\nTest scenarios:\n1. **Startup and shutdown**: start with valid config, send SIGINT, verify clean exit\n2. **Invalid config**: start with bad config, verify error message and exit code 1\n3. **--once mode**: start with --once, verify single tick runs and process exits\n4. **--dry-run mode**: start with --dry-run --once, verify no dispatches made\n5. **Lock contention**: start two instances, verify second exits with lock error\n6. **API responds**: start, hit /status endpoint, verify 200 response\n\nTest infrastructure:\n- Temp directory with test cortex.toml\n- Temp SQLite DB\n- Short tick interval (100ms) for fast tests\n- Mock project with no beads (so nothing dispatches)\n\nAcceptance: Main entry point tested, startup/shutdown/flags verified, test cleanup thorough","status":"open","priority":3,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:01:15.101446797+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T18:01:15.101446797+10:00","labels":["code","test"],"dependencies":[{"issue_id":"cortex-evu.4","depends_on_id":"cortex-evu","type":"parent-child","created_at":"2026-02-17T18:01:15.10472643+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-f4n","title":"Phase 4: Self-Improving + Reporter","description":"Outcome detection (poll bd list for closed beads), duration tracking, weekly retro analysis of dispatches table, tier mismatch flagging, provider weight adjustment. Daily digest and event-driven alerts via Matrix through openclaw agent.","status":"closed","priority":2,"issue_type":"epic","owner":"simon.heikkila@gmail.com","estimated_minutes":240,"created_at":"2026-02-17T13:40:10.459102604+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:59:27.332196582+10:00","closed_at":"2026-02-17T14:59:27.332196582+10:00","close_reason":"Closed","labels":["learner","phase-4","reporter"]}
{"id":"cortex-f4n.1","title":"Outcome tracking + duration logging","description":"Implement internal/learner/outcomes.go — tracks task completion outcomes for learning.\n\nFunctions:\n- RecordOutcome(dispatch Dispatch, bead Bead) -\u003e error\n  Called when a dispatch transitions to completed or failed.\n  Records: bead_id, tier used, provider used, duration_s, exit_code, retries needed, escalated_from_tier.\n  \n- GetProviderStats(window time.Duration) -\u003e map[string]ProviderStats\n  Aggregates per-provider: total dispatches, avg duration, success rate, failure rate.\n  \n- GetTierAccuracy(window time.Duration) -\u003e map[string]TierAccuracy\n  Compares assigned tier vs actual duration:\n  - If a 'fast' tier task took \u003e90min -\u003e tier was underestimated\n  - If a 'premium' tier task took \u003c30min -\u003e tier was overestimated\n  Returns misclassification rate per tier.\n\n- GetProjectVelocity(project string, window time.Duration) -\u003e ProjectVelocity\n  Beads completed, avg time per bead, throughput (beads/day).\n\nAll data sourced from the dispatches table in store.\n\nAcceptance criteria:\n- Outcomes recorded on every dispatch completion\n- Provider stats accurately reflect success/failure rates\n- Tier accuracy detects misclassifications\n- Project velocity calculated correctly\n- Unit tests with seeded dispatch data","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":60,"created_at":"2026-02-17T14:22:59.384589683+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:59:23.196454397+10:00","closed_at":"2026-02-17T14:59:23.196454397+10:00","close_reason":"Closed","labels":["learner","phase-4"],"dependencies":[{"issue_id":"cortex-f4n.1","depends_on_id":"cortex-f4n","type":"parent-child","created_at":"2026-02-17T14:22:59.405866381+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-f4n.1","depends_on_id":"cortex-08z.3","type":"blocks","created_at":"2026-02-17T14:22:59.427225835+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-f4n.2","title":"Weekly retrospective analysis","description":"Implement internal/learner/retro.go — generates a weekly retrospective report analyzing Cortex's performance.\n\nFunction:\n- GenerateWeeklyRetro() -\u003e RetroReport\n  Analyzes the past 7 days of dispatches data:\n  \n  1. Summary stats: total dispatches, completed, failed, stuck, avg duration\n  2. Provider performance: per-provider success rate, avg duration, failure modes\n  3. Tier accuracy: how often was the tier classification correct vs actual duration\n     - Underestimates (fast task took premium time) -\u003e suggest label adjustment\n     - Overestimates (premium task was trivial) -\u003e suggest downgrade\n  4. Project velocity: beads/day per project, backlog burn rate, ETA to empty\n  5. Rate limiter utilization: peak 5h window usage, weekly usage, headroom triggers\n  6. Recommendations: auto-generated suggestions like:\n     - 'Provider X had 40% failure rate — consider deprioritizing'\n     - 'Tier fast is overloaded — raise threshold to 45min'\n     - 'Project Y stalled — 0 beads completed in 3 days'\n\n- FormatRetroMarkdown(report RetroReport) -\u003e string\n  Formats the report as a clean markdown message suitable for Matrix delivery.\n\nScheduled: runs on config.Reporter.WeeklyRetroDay (default: Monday).\n\nAcceptance criteria:\n- Retro covers all 5 analysis dimensions\n- Recommendations are actionable and specific\n- Markdown output is clean and readable\n- Unit tests with seeded week of dispatch data\n- Handles edge case: no dispatches in the past week","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":60,"created_at":"2026-02-17T14:24:18.47563934+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:59:23.214396431+10:00","closed_at":"2026-02-17T14:59:23.214396431+10:00","close_reason":"Closed","labels":["learner","phase-4"],"dependencies":[{"issue_id":"cortex-f4n.2","depends_on_id":"cortex-f4n","type":"parent-child","created_at":"2026-02-17T14:24:18.494227535+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-f4n.2","depends_on_id":"cortex-f4n.1","type":"blocks","created_at":"2026-02-17T14:24:18.649189004+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-f4n.3","title":"Daily digest + event-driven Matrix alerts","description":"Implement Matrix integration for Cortex reporting via openclaw agent dispatch.\n\nDaily digest (scheduled at config.Reporter.DailyDigestTime, default 09:00 AEST):\n- Dispatches the 'main' agent with a formatted status message:\n  ## Daily Cortex Digest — {date}\n  - **{project}:** {completed} beads completed, {ready} ready, {running} in progress\n  - **Providers:** {provider} {used}/{cap} for each authed provider\n  - **Health:** {events_count} events, {restarts} restarts\n  - **Next up:** {top_3_ready_beads}\n\n- Command: openclaw agent --agent main --message {digest} --deliver --reply-channel matrix --reply-to {room_id}\n\nEvent-driven alerts (immediate, not scheduled):\nCortex sends immediate alerts for:\n1. Task failed after max retries -\u003e includes bead ID, error details, retry history\n2. Gateway down for \u003e5min -\u003e includes restart attempts, last error\n3. Provider weekly quota \u003e80% -\u003e includes current usage, projected depletion\n\nImplementation:\n- internal/reporter/reporter.go with Reporter struct\n- SendDigest() method for daily digest\n- SendAlert(alertType, message) for event-driven alerts\n- Both use dispatcher.Dispatch to send via openclaw agent\n\nAcceptance criteria:\n- Daily digest sent at configured time with accurate stats\n- Event alerts sent immediately on trigger conditions\n- Messages formatted as readable markdown\n- Does not send duplicate alerts for same event within 1h (dedup)\n- Unit tests verify message formatting and dedup logic","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":60,"created_at":"2026-02-17T14:25:20.620008341+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:59:23.233750686+10:00","closed_at":"2026-02-17T14:59:23.233750686+10:00","close_reason":"Closed","labels":["phase-4","reporter"],"dependencies":[{"issue_id":"cortex-f4n.3","depends_on_id":"cortex-f4n","type":"parent-child","created_at":"2026-02-17T14:25:20.645509375+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-f4n.3","depends_on_id":"cortex-08z.8","type":"blocks","created_at":"2026-02-17T14:25:20.725842446+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-f4n.3","depends_on_id":"cortex-f4n.1","type":"blocks","created_at":"2026-02-17T14:25:20.80543788+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-g9r","title":"Add basic Matrix message polling","description":"Implement basic Matrix room polling for inbound messages. Simplified version of cortex-a4s.5.\n\n## Goal\nPoll Matrix rooms for new messages and route them to appropriate project scrum masters.\n\n## Scope\nCreate basic Matrix polling infrastructure in internal/matrix/:\n\n## Implementation\nCreate internal/matrix/poller.go:\n- Connect to Matrix using existing OpenClaw message tool\n- Poll configured project rooms for new messages (every 30s)\n- Filter out messages from the bot itself (don't respond to own messages)\n- Route messages to project scrum master based on room\n\n## Message Routing\n- Room -\u003e Project mapping via config (from cortex-a4s.1)\n- Dispatch to '{project}-scrum' agent with message content\n- Include room context in prompt so scrum master knows where to reply\n\n## Configuration\nAdd to config.toml:\n\n\n## Acceptance Criteria\n1) Polls Matrix rooms every poll_interval seconds\n2) Identifies project from room using config mapping\n3) Routes messages to correct project scrum master agent  \n4) Filters out bot's own messages (no infinite loops)\n5) Handles Matrix connection errors gracefully\n6) Can be enabled/disabled via config\n7) Logs message routing for debugging\n\n## Dependencies  \n- Requires cortex-a4s.1 (Matrix room config)\n- Uses existing OpenClaw message tool for Matrix API","status":"open","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:38:19.443070676+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:38:19.443070676+10:00","labels":["inbound","matrix","polling","scrum"],"dependencies":[{"issue_id":"cortex-g9r","depends_on_id":"cortex-a4s.1","type":"blocks","created_at":"2026-02-18T02:39:06.563186727+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-grt","title":"Implement git branch isolation for concurrent dispatches","description":"Add git branch management to the dispatch flow in scheduler:\n\nBefore dispatch:\n1. git checkout -b ctx/{bead-id} from main branch\n2. Pass branch name in DispatchOpts\n\nAfter dispatch completes (success):\n1. git checkout main\n2. git merge ctx/{bead-id} (or rebase per config merge_strategy)\n3. Handle merge conflicts: mark dispatch as 'conflict', create retry bead\n4. Delete branch on successful merge\n\nAfter dispatch fails/stuck:\n1. Leave branch for debugging\n2. Clean up branches older than branch_cleanup_days on health tick\n\nAdd to health monitor: periodic branch cleanup (prune ctx/* older than 7 days).\n\nAcceptance: parallel dispatches on same project don't conflict. Branches created/merged/cleaned automatically.","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:00:38.507365878+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T18:00:38.507365878+10:00","dependencies":[{"issue_id":"cortex-grt","depends_on_id":"cortex-anx","type":"blocks","created_at":"2026-02-17T18:01:34.403197069+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-gz7","title":"tmp-claim-test","description":"temp","status":"open","priority":3,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T23:22:27.308139961+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T23:22:29.006084371+10:00","ephemeral":true}
{"id":"cortex-hgz","title":"Add log_path, session_name, branch columns to dispatches table","description":"Extend the dispatches table in internal/store/store.go:\n- log_path TEXT: path to stdout/stderr capture file\n- session_name TEXT: tmux session name (null for headless/openclaw)\n- branch TEXT: git branch name (ctx/{bead-id})\n- backend TEXT: which backend was used (headless, tmux, openclaw)\n\nAdd migration logic (ALTER TABLE or recreate). Update RecordDispatch, UpdateDispatchStatus, GetRunningDispatches to handle new columns.\n\nAcceptance: schema migrates cleanly from old format. New columns queryable.","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:00:00.421367386+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T20:18:55.14434929+10:00","closed_at":"2026-02-17T20:18:55.14434929+10:00","close_reason":"Closed","dependencies":[{"issue_id":"cortex-hgz","depends_on_id":"cortex-hr2","type":"blocks","created_at":"2026-02-17T18:01:14.93849003+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-hr2","title":"Add dispatch config structs (cli, routing, timeouts, git, tmux)","description":"Add new config sections to internal/config/config.go and cortex.toml:\n- dispatch.cli.{name}: cmd, prompt_mode, args, model_flag, approval_flags per CLI\n- dispatch.routing: fast/balanced/premium/comms backend selection, retry_backend\n- dispatch.timeouts: per-tier timeout values (fast=15m, balanced=45m, premium=120m)\n- dispatch.git: branch_prefix, branch_cleanup_days, merge_strategy, max_concurrent_per_project\n- dispatch.tmux: history_limit, session_prefix\n- dispatch.log_dir, dispatch.log_retention_days\n- Update provider config: add cli and model fields\n- Parse and validate all new sections\n- Update cortex.toml with new sections\n\nAcceptance: config loads, validates, and all new fields accessible. Existing config still works.","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:59:51.596871157+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T20:10:31.537272142+10:00","closed_at":"2026-02-17T20:10:31.537272142+10:00","close_reason":"Dispatch config structs added: CLIConfig, DispatchRouting, DispatchTimeouts, DispatchGit, DispatchTmux, Provider.CLI. cortex.toml updated with claude/aider CLI configs."}
{"id":"cortex-hrz","title":"Dry-run mode and control plane API","description":"No way to preview what Cortex would do without actually dispatching. API is read-only — can't pause, cancel, or retry dispatches. Must restart the process to change config. Makes operations risky and debugging hard.\n\nKey deliverables:\n- --dry-run flag: run tick logic, log what would dispatch, don't actually do it\n- Control API: cancel, retry, pause/resume scheduler\n- Config reload via SIGHUP (no restart needed)\n- Dispatch history query API\n- Per-bead status API","status":"closed","priority":1,"issue_type":"epic","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:57:33.432561494+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:29:33.498462823+10:00","closed_at":"2026-02-18T04:29:33.498462823+10:00","close_reason":"Epic completed - already broken down into 4 executable tasks with detailed acceptance criteria"}
{"id":"cortex-hrz.1","title":"Add --dry-run flag to scheduler","description":"Add a --dry-run mode that runs the full tick logic but doesn't actually dispatch agents.\n\nChanges to cmd/cortex/main.go:\n- Add --dry-run flag\n- Pass dryRun bool to Scheduler\n\nChanges to internal/scheduler/scheduler.go:\n- Accept dryRun field on Scheduler struct\n- In RunTick, when dryRun=true:\n  - Run all discovery, filtering, role inference, complexity detection, provider selection\n  - Log what WOULD be dispatched: bead, project, agent, role, tier, provider\n  - Do NOT call dispatcher.Dispatch()\n  - Do NOT record dispatch in store\n  - Do NOT record rate limit usage\n- Output format: structured log entries with 'dry_run=true' tag\n\nAlso add --once flag behavior (already exists) so --dry-run --once shows one tick preview and exits.\n\nAcceptance: --dry-run shows exactly what would dispatch without side effects, combined with --once for single preview","status":"closed","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:00:00.56660378+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T20:18:55.318676696+10:00","closed_at":"2026-02-17T20:18:55.318676696+10:00","close_reason":"Closed","labels":["code"],"dependencies":[{"issue_id":"cortex-hrz.1","depends_on_id":"cortex-hrz","type":"parent-child","created_at":"2026-02-17T18:00:00.569202103+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-hrz.2","title":"Add control API: cancel, retry, pause/resume","description":"Add write endpoints to the API for controlling the scheduler.\n\nNew endpoints in internal/api/api.go:\n\nPOST /scheduler/pause\n- Sets scheduler paused flag\n- Running dispatches continue but no new dispatches\n- Returns: {paused: true}\n\nPOST /scheduler/resume\n- Clears paused flag\n- Returns: {paused: false}\n\nPOST /dispatches/{id}/cancel\n- Kill the running dispatch (SIGTERM → SIGKILL)\n- Mark as failed with reason 'cancelled'\n- Returns: {cancelled: true}\n\nPOST /dispatches/{id}/retry\n- Re-dispatch a failed dispatch with same bead/project/role\n- Optionally specify tier override: ?tier=premium\n- Returns: new dispatch info\n\nGET /dispatches\n- Query dispatch history with filters\n- ?status=failed\u0026project=hg-website\u0026limit=50\u0026offset=0\n- Returns: paginated dispatch list with all fields\n\nGET /dispatches/{id}\n- Full dispatch detail: prompt, output (if captured), duration, cost, diagnosis\n\nScheduler changes:\n- Add Paused() bool method, check at top of RunTick\n- Add CancelDispatch(id) method\n\nAcceptance: All endpoints work, pause prevents new dispatches, cancel kills running, retry re-dispatches","status":"closed","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:00:06.476355397+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T20:18:55.252092003+10:00","closed_at":"2026-02-17T20:18:55.252092003+10:00","close_reason":"Closed","labels":["code"],"dependencies":[{"issue_id":"cortex-hrz.2","depends_on_id":"cortex-hrz","type":"parent-child","created_at":"2026-02-17T18:00:06.479998177+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-hrz.3","title":"Implement config reload via SIGHUP","description":"Allow reloading cortex.toml without restarting the process.\n\nChanges to cmd/cortex/main.go:\n- Add SIGHUP signal handler\n- On SIGHUP: re-read and validate config file\n- If valid: swap config pointer in scheduler, rate limiter, health monitor\n- If invalid: log error, keep old config\n- Log: 'config reloaded' or 'config reload failed: {reason}'\n\nChanges to internal/config/config.go:\n- Add Reload(path) (*Config, error) function (same as Load but can be called multiple times)\n\nThread safety:\n- Config access must be behind sync.RWMutex or atomic pointer swap\n- Scheduler reads config under RLock\n- SIGHUP handler writes under Lock\n\nWhat CAN be reloaded:\n- Provider definitions (add/remove/modify)\n- Tier assignments\n- Rate limit caps\n- Project enable/disable\n- Log level\n- Tick interval\n\nWhat CANNOT be reloaded (requires restart):\n- State DB path\n- API bind address\n\nAcceptance: SIGHUP reloads config, invalid config rejected, thread-safe, logs reload status","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:00:12.411538173+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T18:00:12.411538173+10:00","labels":["code"],"dependencies":[{"issue_id":"cortex-hrz.3","depends_on_id":"cortex-hrz","type":"parent-child","created_at":"2026-02-17T18:00:12.414345728+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-hrz.3.1","title":"Add thread-safe config management with RWMutex protection","description":"Implement thread-safe config access patterns to support hot reloading.\n\nFiles to create/modify:\n- internal/config/config.go (add thread-safe config manager)\n- internal/config/manager.go (new - config manager with locking)\n- internal/config/manager_test.go (new - test thread safety)\n\nAcceptance criteria:\n- Config access protected by sync.RWMutex or atomic pointer swapping\n- ConfigManager provides thread-safe Get/Set methods for config\n- Reader operations use RLock for concurrent access\n- Writer operations (reload) use Lock for exclusive access\n- Unit tests verify thread safety under concurrent access\n- Performance impact minimal for read-heavy workloads\n\nConfigManager interface:\n- Get() *Config - thread-safe config read\n- Set(config *Config) - thread-safe config update\n- Reload(path string) error - reload config from file\n\nImplementation details:\n- Use sync.RWMutex for read/write locking\n- Or use atomic.Value for lock-free pointer swapping\n- Ensure all config consumers use manager instead of direct config access\n- Add benchmarks to verify read performance is not degraded\n- Test concurrent reads with occasional writes (reload scenario)","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:15:22.21820579+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:15:22.21820579+10:00","dependencies":[{"issue_id":"cortex-hrz.3.1","depends_on_id":"cortex-hrz.3","type":"parent-child","created_at":"2026-02-18T04:15:22.220951228+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-hrz.3.2","title":"Implement config validation and reload logic","description":"Create config reloading logic with validation and error handling.\n\nFiles to create/modify:\n- internal/config/config.go (extend with Reload function)\n- internal/config/validation.go (new - validation logic)\n- internal/config/reload_test.go (new - test reload scenarios)\n\nAcceptance criteria:\n- Reload(path string) function re-reads and validates config file\n- Invalid config files are rejected with descriptive errors\n- Old config preserved when reload fails\n- Validation covers all config sections (providers, projects, dispatch, etc.)\n- Unit tests cover valid reload, invalid config rejection, file read errors\n- Structured logging for reload success/failure with details\n\nReload behavior:\n- Parse new config from file path\n- Run full validation on new config (same as startup validation)\n- If valid: return new config for atomic swap\n- If invalid: return error, log validation failure details\n- Handle file read errors gracefully (permissions, missing file, etc.)\n\nValidation requirements:\n- All provider configurations are valid\n- Project settings are correct\n- Dispatch routing is valid\n- No circular dependencies or invalid references\n- Required fields are present with valid values","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:15:32.282126893+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:15:32.282126893+10:00","dependencies":[{"issue_id":"cortex-hrz.3.2","depends_on_id":"cortex-hrz.3","type":"parent-child","created_at":"2026-02-18T04:15:32.286045774+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-hrz.3.2","depends_on_id":"cortex-hrz.3.1","type":"blocks","created_at":"2026-02-18T04:15:32.298052326+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-hrz.3.3","title":"Add SIGHUP signal handler for config reload","description":"Implement SIGHUP signal handler in main.go to trigger config reload.\n\nFiles to create/modify:\n- cmd/cortex/main.go (add signal handling)\n- internal/config/signals.go (new - signal handling helpers)\n- Signal handling integration tests\n\nAcceptance criteria:\n- SIGHUP signal triggers config reload process\n- Signal handler integrates with ConfigManager for thread-safe reload\n- Successful reload logs 'config reloaded' with timestamp and changes summary\n- Failed reload logs 'config reload failed: {reason}' and preserves old config\n- Signal handler doesn't interfere with other signals (SIGTERM, SIGINT)\n- Integration test sends SIGHUP and verifies config reload behavior\n\nSignal handling requirements:\n- Use os/signal package to catch SIGHUP\n- Run signal handler in separate goroutine\n- Coordinate with main application lifecycle (don't reload during shutdown)\n- Graceful error handling - failed reloads don't crash the application\n- Log reload attempts and outcomes with appropriate log levels\n\nImplementation details:\n- Set up signal channel with signal.Notify(c, syscall.SIGHUP)\n- In signal handler goroutine: receive signal → trigger ConfigManager.Reload()\n- Pass config file path from command line args to reload logic\n- Handle case where config file path changes (use original path from startup)","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:15:42.688652255+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:15:42.688652255+10:00","dependencies":[{"issue_id":"cortex-hrz.3.3","depends_on_id":"cortex-hrz.3","type":"parent-child","created_at":"2026-02-18T04:15:42.692443551+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-hrz.3.3","depends_on_id":"cortex-hrz.3.1","type":"blocks","created_at":"2026-02-18T04:15:42.708013754+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-hrz.3.3","depends_on_id":"cortex-hrz.3.2","type":"blocks","created_at":"2026-02-18T04:15:42.722385277+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-hrz.4","title":"Add per-bead status API endpoint","description":"API endpoint to check the dispatch status of a specific bead.\n\nNew endpoint:\nGET /beads/{id}\n- Returns: bead ID, project, current dispatch status (running/completed/failed/not_dispatched)\n- If dispatched: agent, provider, tier, duration, started_at\n- If completed: duration, quality score (if available), cost (if tracked)\n- If failed: failure diagnosis, retry count\n- Dispatch history: all dispatches for this bead (may have been retried)\n\nImplementation:\n- Query dispatches table by bead_id\n- Join with dispatch_output for tail (if available)\n- Join with quality scores (if available)\n\nGET /beads/{id}/output\n- Returns: full captured output for the most recent dispatch of this bead\n- 404 if no output captured\n\nAcceptance: Bead status queryable, includes full dispatch history, output accessible","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:00:17.923927769+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T18:00:17.923927769+10:00","labels":["code"],"dependencies":[{"issue_id":"cortex-hrz.4","depends_on_id":"cortex-hrz","type":"parent-child","created_at":"2026-02-17T18:00:17.927023179+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-j5d","title":"Output capture and agent feedback loop","description":"Cortex is blind to what its agents do. Dispatches go to /dev/null — no stdout, no stderr, no output. When a dispatch completes, Cortex knows 'PID died' and nothing else. Can't tell if the agent wrote good code, broke tests, or went off-rails.\n\nA TmuxDispatcher already exists in internal/dispatch/tmux.go (294 lines, full output capture via tmux sessions) but is NOT wired into the scheduler. This is the lowest-hanging highest-impact fix in the project.\n\nWithout output capture, every other intelligence feature (quality scoring, learning, retro analysis) is building on sand.\n\nKey deliverables:\n- Integrate TmuxDispatcher into scheduler (replace PID-based dispatcher)\n- Store agent output in DB (new output/logs table)\n- Failure diagnostics: capture why agents fail\n- Quality scoring: assess if agent work actually addressed the bead\n- Feedback loop: use outcomes to improve provider selection and prompting","status":"closed","priority":0,"issue_type":"epic","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:54:00.463246196+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T20:09:44.177790037+10:00","closed_at":"2026-02-17T20:09:44.177790037+10:00","close_reason":"Core deliverables complete: TmuxDispatcher integrated, output captured/stored, failure diagnostics wired. Remaining j5d.4/j5d.5 are P2 enhancements."}
{"id":"cortex-j5d.1","title":"Integrate TmuxDispatcher into scheduler","description":"Replace the PID-based Dispatcher with the TmuxDispatcher that already exists in internal/dispatch/tmux.go.\n\nThe TmuxDispatcher is already implemented (294 lines) but not wired into the scheduler. It uses tmux sessions instead of bare PIDs, giving us:\n- Output capture via tmux capture-pane\n- Session state queryable (running vs exited vs gone)\n- Survives parent crash (tmux server persistence)\n- Graceful shutdown orchestration\n- Session naming: ctx-{project}-{beadID}-{timestamp}\n\nChanges needed:\n- Update scheduler.go to use TmuxDispatcher instead of Dispatcher\n- Update health/stuck.go to use tmux session checks instead of PID checks\n- Update health/zombie.go to use tmux list-sessions instead of pgrep\n- Update main.go wiring to create TmuxDispatcher\n- Add tmux availability check on startup (fall back to PID if tmux unavailable)\n- Update dispatch tests\n\nThe TmuxDispatcher already implements the same Dispatch() signature. This should be largely a wiring change.\n\nAcceptance: Scheduler uses tmux sessions, health checks use tmux, zombie detection uses tmux list-sessions, fallback to PID-based if tmux not available","notes":"**Review Result: Changes Needed**\n\n**Good Implementation - Strong Foundation**:\n✅ TmuxDispatcher fully implemented (294 lines)\n✅ DispatcherInterface properly defined and used \n✅ Scheduler updated to use interface abstraction\n✅ Main.go has tmux availability check and fallback logic\n✅ Health checks (stuck.go, zombie.go) updated for both dispatcher types\n✅ Comprehensive tmux tests exist (tmux_test.go)\n\n**Critical Issues Requiring Fix**:\n\n1. **Output Capture Broken**: scheduler.getSessionNameFromHandle() is a placeholder that returns empty string\n   - This breaks tmux session output capture completely\n   - Need to implement actual mapping or add GetSessionName(handle) method to TmuxDispatcher\n\n2. **Missing TmuxDispatcher Method**: No way to get session name from handle\n   - Scheduler needs session name for dispatch.CaptureOutput() call\n   - Should add GetSessionName(handle int) (string, error) method to TmuxDispatcher interface\n\n3. **Test Failures**: TmuxDispatcher integration tests failing\n   - Tests: TestTmuxDispatcher_DispatchAndCapture, TestTmuxDispatcher_ExitCodeCapture, etc.\n   - Sessions not persisting as expected (\"session should be alive due to remain-on-exit\")\n   - May indicate issues with session creation or configuration\n\n**Minor Issues**:\n- Logging still shows \"pid\" field name instead of generic \"handle\" for tmux sessions\n- TmuxDispatcher.Dispatch() method extracts project from agent name rather than using proper parameters\n\n**Required Fixes**:\n1. Implement scheduler.getSessionNameFromHandle() or add GetSessionName() to TmuxDispatcher  \n2. Fix tmux session persistence issues causing test failures\n3. Verify output capture works end-to-end with tmux sessions\n4. Update logging to use \"handle\" instead of \"pid\" for generic case\n\n**Overall Assessment**: \nThe architecture and most implementation is excellent, but output capture integration is incomplete and tests are failing. Close to completion but needs the critical gaps addressed.\n\nTransitioned back to stage:coding for integration completion.","status":"closed","priority":0,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:58:32.59587345+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T18:35:38.789089653+10:00","closed_at":"2026-02-17T18:35:38.789089653+10:00","close_reason":"Session tracking fix implemented and tested — session names stored in DB, crash-resilient dispatch tracking","labels":["code","stage:coding","stage:review"],"dependencies":[{"issue_id":"cortex-j5d.1","depends_on_id":"cortex-j5d","type":"parent-child","created_at":"2026-02-17T17:58:32.599292194+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-j5d.2","title":"Add agent output storage to DB","description":"Create a mechanism to capture and store agent output from tmux sessions.\n\nNew table in internal/store/store.go:\n```sql\nCREATE TABLE dispatch_output (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    dispatch_id INTEGER NOT NULL REFERENCES dispatches(id),\n    captured_at TEXT NOT NULL,\n    output TEXT NOT NULL,        -- full scrollback capture\n    output_tail TEXT NOT NULL,   -- last 100 lines (for quick queries)\n    output_bytes INTEGER NOT NULL\n);\nCREATE INDEX idx_dispatch_output_dispatch ON dispatch_output(dispatch_id);\n```\n\nNew methods:\n- CaptureOutput(dispatchID, output string) error\n- GetOutput(dispatchID) (string, error)\n- GetOutputTail(dispatchID) (string, error)\n\nCapture trigger: when scheduler detects dispatch completion (PID dead / tmux session exited), call TmuxDispatcher.CaptureOutput(sessionName) and store result.\n\nSize management: truncate output to max 500KB per dispatch. Store full output and last-100-lines tail separately for quick queries.\n\nAcceptance: Output captured on completion, stored in DB, queryable, size-bounded","status":"closed","priority":0,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:58:43.045623658+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T18:35:52.568949928+10:00","closed_at":"2026-02-17T18:35:52.568949928+10:00","close_reason":"Output storage implemented: dispatch_output table, CaptureOutput/GetOutput/GetOutputTail methods, 500KB truncation, last-100-lines tail. All tested.","labels":["stage:review"],"dependencies":[{"issue_id":"cortex-j5d.2","depends_on_id":"cortex-j5d","type":"parent-child","created_at":"2026-02-17T17:58:43.050767436+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-j5d.2","depends_on_id":"cortex-j5d.1","type":"blocks","created_at":"2026-02-17T17:59:13.874165757+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-j5d.3","title":"Add failure diagnostics from captured output","description":"Use captured agent output to diagnose why dispatches fail. Pure code — pattern matching on output.\n\nCreate internal/learner/diagnostics.go:\n```go\ntype FailureDiagnosis struct {\n    DispatchID  int\n    BeadID      string\n    Category    string    // compile_error, test_failure, timeout, rate_limited, permission_denied, unknown\n    Summary     string    // first relevant error line\n    Details     string    // surrounding context\n}\n\n// DiagnoseFailure scans captured output for known failure patterns\nfunc DiagnoseFailure(output string) *FailureDiagnosis\n\n// Known patterns (regex):\n// - 'FAIL' or 'FAILED' → test_failure\n// - 'cannot find package' or 'undefined:' → compile_error\n// - 'permission denied' → permission_denied\n// - 'rate limit' or '429' → rate_limited\n// - 'context deadline exceeded' → timeout\n// - 'error:' or 'Error:' → generic error extraction\n```\n\nStore failure diagnosis:\n- Add category and summary columns to dispatches table (nullable, backward compat)\n- Populate on failure detection\n\nIntegration:\n- scheduler checkRunningDispatches: on failure, run DiagnoseFailure and store\n- Include in per-project retro data\n- Surface in API: GET /dispatches/{id} includes diagnosis\n\nAcceptance: Common failure patterns detected, categorized, stored, surfaced in API","status":"closed","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:58:49.427555396+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T20:09:29.278209071+10:00","closed_at":"2026-02-17T20:09:29.278209071+10:00","close_reason":"Wired DiagnoseFailure into scheduler checkRunningDispatches, added failure_category/failure_summary columns to dispatches, exposed in API","labels":["code"],"dependencies":[{"issue_id":"cortex-j5d.3","depends_on_id":"cortex-j5d","type":"parent-child","created_at":"2026-02-17T17:58:49.4310444+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-j5d.3","depends_on_id":"cortex-j5d.2","type":"blocks","created_at":"2026-02-17T17:59:18.506066419+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-j5d.4","title":"Implement agent quality scoring","description":"Score completed dispatches on quality. Mostly code for objective checks, optional LLM for nuanced review.\n\n**Code-based scoring (internal/learner/quality.go):**\n```go\ntype QualityScore struct {\n    DispatchID    int\n    Overall       float64  // 0.0-1.0\n    TestsPassed   *bool    // did tests pass? (nil if no tests)\n    BeadClosed    bool     // did agent close the bead?\n    CommitMade    bool     // did agent make a git commit?\n    FilesChanged  int      // how many files touched\n    LinesChanged  int      // net lines changed\n    Duration      float64  // seconds (shorter = better, within reason)\n}\n\n// ScoreDispatch analyzes output and git state to score quality\nfunc ScoreDispatch(output string, workspace string, beadID string) (*QualityScore, error)\n```\n\nDetection from output (code):\n- Search for 'PASS' / 'FAIL' / 'ok' in test output\n- Search for 'bd close' confirmation\n- Parse git diff stats from output\n- Check bead status via bd show\n\nStore scores:\n- New quality_scores table or add score columns to dispatches\n- Track per-provider, per-role average scores\n\nUse in provider selection:\n- If provider X has avg quality \u003c 0.5 on role Y, deprioritize\n\nOptional LLM scoring (future enhancement):\n- For high-value beads, dispatch a reviewer agent to assess the output\n- 'Did this agent actually address the acceptance criteria?'\n\nAcceptance: Objective quality metrics computed from output, stored, available for provider selection","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:58:56.169972921+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T17:58:56.169972921+10:00","dependencies":[{"issue_id":"cortex-j5d.4","depends_on_id":"cortex-j5d","type":"parent-child","created_at":"2026-02-17T17:58:56.188579404+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-j5d.4","depends_on_id":"cortex-j5d.2","type":"blocks","created_at":"2026-02-17T17:59:21.999612183+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-j5d.5","title":"Close the feedback loop: outcome-driven improvements","description":"Use quality scores and failure diagnostics to automatically improve Cortex's behavior over time. Mostly code with some data feeding into LLM retros.\n\n**Automated improvements (code):**\n\n1. Provider scoring adjustment:\n   - Track rolling quality score per provider per role\n   - If provider drops below threshold (e.g. 0.4), auto-deprioritize for that role\n   - If provider consistently scores high, prefer it\n\n2. Complexity calibration:\n   - Compare estimated complexity (tier) vs actual duration and outcome\n   - If 'fast' tasks regularly fail and succeed on 'balanced', adjust threshold\n   - Store calibration data in DB, apply in DetectComplexity()\n\n3. Prompt effectiveness:\n   - Track which prompt template versions produce highest quality scores\n   - A/B test: randomly vary prompt details, measure outcomes\n   - Store prompt template version with dispatch for correlation\n\n4. Failure pattern prevention:\n   - If same failure category repeats for same bead type, add warning to prompt\n   - e.g. 'Previous agents failed on compile errors in Go tasks — run go build before committing'\n\n**Data for LLM retros:**\n- All of the above feeds into the retro data that scrum master and chief SM analyze\n- They can produce deeper recommendations than code heuristics\n\nAcceptance: Provider scores auto-adjust, complexity thresholds calibrate, failure patterns inform future prompts","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:59:08.870978397+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T17:59:08.870978397+10:00","dependencies":[{"issue_id":"cortex-j5d.5","depends_on_id":"cortex-j5d","type":"parent-child","created_at":"2026-02-17T17:59:08.875157717+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-j5d.5","depends_on_id":"cortex-j5d.4","type":"blocks","created_at":"2026-02-17T17:59:25.629666695+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-j5d.5","depends_on_id":"cortex-j5d.3","type":"blocks","created_at":"2026-02-17T17:59:29.299768387+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-k12","title":"Auto: multiple dead-running dispatches reconciled (2)","description":"Nightwatch found and cancelled 2 dead-running dispatches in one cycle at 2026-02-18T02:04:57+10:00.\\n\\n- dispatch 1041 bead cortex-c4j.2 pane=1 session=ctx-cortex-cortex-ops-1771344012750415965-4124876-69993a79\n- dispatch 1046 bead cortex-o3u pane=1 session=ctx-cortex-cortex-coder-1771344248944209132-4124876-b6ddbab6\n","status":"closed","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:04:57.511878521+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:04:58.619738639+10:00","closed_at":"2026-02-18T02:04:58.619738639+10:00","close_reason":"auto-verified by codex-worker: no dead-running dispatches remain"}
{"id":"cortex-kg9","title":"Auto: churn guard blocked bead cortex-46d.8 (7 dispatches/1h0m0s)","description":"Bead `cortex-46d.8` in project `cortex` exceeded churn threshold (7 dispatches in 1h0m0s) and was blocked from further overnight dispatch.\n\nPlease investigate root cause, split work into smaller tasks if needed, and add hardening/tests before re-enabling.\n\nBead title: Harden tmux dispatcher command error handling and cleanup parsing\nBead type: bug","status":"open","priority":1,"issue_type":"bug","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:20:13.5587195+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:21:08.474383448+10:00","dependencies":[{"issue_id":"cortex-kg9","depends_on_id":"cortex-46d.8","type":"discovered-from","created_at":"2026-02-18T02:20:13.679876904+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-kib","title":"Add dispatch output capture and storage","description":"Add a dispatch_outputs table to the SQLite store (columns: dispatch_id, session_name, output TEXT, captured_at). When checkRunningDispatches detects a session has exited, call CaptureOutput(sessionName) from tmux.go to grab the full scrollback, then store it. Add Store methods: StoreDispatchOutput(dispatchID, sessionName, output) and GetDispatchOutput(dispatchID). Clean up dead tmux sessions after capture using KillSession().","acceptance_criteria":"\nACCEPTANCE CRITERIA:\n1. Add dispatch_outputs table with columns: dispatch_id, session_name, output TEXT, captured_at\n2. Extend Store with new methods: StoreDispatchOutput(dispatchID, sessionName, output) and GetDispatchOutput(dispatchID)\n3. Update checkRunningDispatches to detect exited sessions and capture their tmux output using CaptureOutput() from tmux.go\n4. Store the captured output in dispatch_outputs table\n5. Clean up dead tmux sessions after output capture using KillSession()\n6. Handle edge cases: missing sessions, capture failures, database errors\n7. Add tests for new Store methods and integration tests for output capture flow\n8. Update schema migration to handle existing deployments","status":"closed","priority":0,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:57:12.333067404+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T18:31:24.900521087+10:00","closed_at":"2026-02-17T18:31:24.900521087+10:00","close_reason":"Duplicate of cortex-j5d.2 which already has output capture committed (b80180d)","labels":["stage:planning"],"dependencies":[{"issue_id":"cortex-kib","depends_on_id":"cortex-1b2","type":"blocks","created_at":"2026-02-17T17:57:20.50202408+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-kib","depends_on_id":"cortex-j5d","type":"parent-child","created_at":"2026-02-17T17:57:21.952772613+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-kvo","title":"Auto: break down epic cortex-a4s into executable bug/task beads","description":"Epic `cortex-a4s` is still open in project `cortex`.\n\nPolicy: epics should not be assigned directly to coders. Break this epic into concrete `bug`/`task` beads with acceptance criteria so overnight automation can execute them.\n\nEpic title: Scrum master as project point-of-contact via Matrix","status":"open","priority":1,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:00:06.665690461+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:07:06.847726652+10:00","dependencies":[{"issue_id":"cortex-kvo","depends_on_id":"cortex-a4s","type":"discovered-from","created_at":"2026-02-18T02:00:06.668648837+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-lh8","title":"Auto: repeated failure (2x/15m): synthetic-nightwatch-force-test","description":"Nightwatch detected repeated dispatch failures in the last 15 minutes.\\n\\nCount: 2\\nSummary: synthetic-nightwatch-force-test\\nDispatch IDs: 1004,1005\\nBeads: nightwatch-synth\\nDetected at: 2026-02-18T01:34:13+10:00\\n\\nPlease investigate root cause and patch.","status":"closed","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T01:34:13.797396511+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T01:34:45.615672727+10:00","closed_at":"2026-02-18T01:34:45.615672727+10:00","close_reason":"synthetic nightwatch force-test completed"}
{"id":"cortex-luz","title":"Add scrum master progress notifications","description":"Add basic outbound notifications from scrum master for project progress. Simplified version of cortex-a4s.4.\n\n## Goal\nEnable scrum master to send progress updates to project Matrix rooms when significant events occur.\n\n## Scope\nCreate internal/scrum/notifications.go with basic notification triggers:\n\n## Notification Types\n1. **Bead Completed**: When a bead transitions to completed status\n2. **Bead Failed**: When a dispatch fails and bead moves to failed  \n3. **Agent Stuck**: When a dispatch exceeds stuck timeout\n4. **Project Blocked**: When all ready beads are blocked by dependencies\n\n## Implementation\n- Hook into scheduler events (dispatch completion, timeouts, etc.)\n- Format notifications as brief status updates\n- Send via scrum master agent to project Matrix room\n- Include bead ID, title, and relevant details\n\n## Message Format\n- Completed: '✅ {bead-id}: {title} completed by {agent}'\n- Failed: '❌ {bead-id}: {title} failed - {brief-reason}'  \n- Stuck: '⏰ {bead-id}: {title} stuck for {duration} - may need intervention'\n- Blocked: '🚫 Project blocked - all ready work depends on {blocker-list}'\n\n## Integration Points\n- Scheduler calls notification functions on state changes\n- Use existing message tool for Matrix delivery\n- Respect project Matrix room configuration\n\n## Acceptance Criteria\n1) Notifications trigger on the four defined event types\n2) Messages are formatted consistently and briefly\n3) Only sends to projects with Matrix rooms configured  \n4) Includes relevant context (bead ID, agent, reason)\n5) Can be enabled/disabled per project via config\n6) Unit tests cover notification formatting and triggers","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:38:31.114953701+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:38:31.114953701+10:00","labels":["matrix","notifications","outbound","scrum"],"dependencies":[{"issue_id":"cortex-luz","depends_on_id":"cortex-19e","type":"blocks","created_at":"2026-02-18T02:39:09.929535657+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-lxg","title":"Harden dispatch command construction against shell parsing failures","description":"Fix shell parsing failures in dispatch command construction that cause runtime errors with complex prompts and configurations.\n\n## Observed Failures\nFrom dispatch logs and cortex-46d.7 analysis:\n- \"error: unknown option '--model'\" (CLI flag issues)\n- \"Syntax error: Unterminated quoted string\"  \n- \"Syntax error: Bad fd number\"\n- \"Syntax error: ( unexpected\"\n- Failed dispatch IDs: 888, 887, 886, 885, 884, 881, 879, 878\n\n## Root Cause\nCommand construction in dispatch system uses shell string interpolation which fails when:\n- Prompts contain special shell characters (quotes, parentheses, etc.)\n- Model names or provider configs contain unexpected characters\n- CLI arguments are not properly escaped\n\n## Scope\n- Audit command building in both PID and Tmux dispatchers\n- Replace shell string interpolation with proper argument arrays\n- Add shell escaping for user-provided content (prompts, model names)\n- Test with complex prompt content that previously failed\n\n## Acceptance Criteria\n1) No shell parsing errors with prompts containing quotes, parentheses, special chars\n2) Model flag construction handles all configured model names correctly\n3) CLI argument passing uses proper escaping/quoting\n4) Integration tests cover problematic prompt patterns from observed failures  \n5) Both PID and Tmux dispatchers handle complex content safely\n\n## Test Coverage  \n- Prompts with single/double quotes\n- Prompts with parentheses and shell metacharacters\n- Model names with special characters\n- Complex CLI flag combinations\n- Regression tests for specific failed dispatch patterns","status":"open","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:31:06.484533198+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:31:06.484533198+10:00","labels":["dispatch","parsing","security","shell"]}
{"id":"cortex-lxs","title":"Auto: break down epic cortex-pg5 into executable bug/task beads","description":"Epic `cortex-pg5` is still open in project `cortex`.\n\nPolicy: epics should not be assigned directly to coders. Break this epic into concrete `bug`/`task` beads with acceptance criteria so overnight automation can execute them.\n\nEpic title: Multi-workflow support: stage-based pipelines for dev, content, trading","status":"closed","priority":1,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:30:24.184799503+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:34:15.783101341+10:00","closed_at":"2026-02-18T04:34:15.783101341+10:00","close_reason":"Epic breakdown completed successfully","dependencies":[{"issue_id":"cortex-lxs","depends_on_id":"cortex-pg5","type":"discovered-from","created_at":"2026-02-18T04:30:24.18958695+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-mlq","title":"Auto: repeated failure (3x/15m): error: required option '-m, --message \u003ctext\u003e' not specified","description":"Nightwatch detected repeated dispatch failures in the last 15 minutes.\\n\\nCount: 3\\nSummary: error: required option '-m, --message \u003ctext\u003e' not specified\\nDispatch IDs: 1077,1084,1086\\nBeads: cortex-3q5,cortex-c4j.6\\nDetected at: 2026-02-18T02:35:03+10:00\\n\\nPlease investigate root cause and patch.","status":"closed","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:35:04.315734538+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:48:15.50687892+10:00","closed_at":"2026-02-18T02:48:15.50687892+10:00","close_reason":"auto-verified by codex-worker: repeated failure signature is not present in last 15 minutes"}
{"id":"cortex-njb","title":"Auto: break down epic cortex-xhk into executable bug/task beads","description":"Epic `cortex-xhk` is still open in project `cortex`.\n\nPolicy: epics should not be assigned directly to coders. Break this epic into concrete `bug`/`task` beads with acceptance criteria so overnight automation can execute them.\n\nEpic title: LeSS coordination layer: cross-team orchestration","status":"in_progress","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:35:06.748764377+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:45:53.999177499+10:00","labels":["stage:review"],"dependencies":[{"issue_id":"cortex-njb","depends_on_id":"cortex-xhk","type":"discovered-from","created_at":"2026-02-18T02:35:06.759906908+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-nk8","title":"Implement per-project budget enforcement","description":"Add budget enforcement to scheduler dispatch logic using per-project rate limits.\n\n## Goal  \nEnforce per-project rate limit budgets in scheduler before dispatching work.\n\n## Scope\nExtend scheduler RunTick to check project budget before provider selection:\n\n## Implementation\n- Add BudgetedCanDispatch method to rate limiter\n- Check project budget before dispatching in RunTick\n- If project budget exhausted but global capacity available, log and skip\n- Fall back to current behavior if no budget configured\n- Include budget status in dispatch logging\n\n## Budget Logic\n- Calculate project allocation: (project_budget_percent / 100) * weekly_cap\n- Track project usage against allocated budget\n- Allow dispatch if project under budget and global capacity available\n- Deny dispatch if project over budget, even if global capacity exists\n\n## Integration Points\n- Called from scheduler.RunTick before provider selection\n- Uses configuration from cortex-ood (budget config)\n- Uses tracking from cortex-rlj (per-project usage)\n- Maintains existing dispatch flow for unconfigured projects\n\n## Acceptance Criteria\n1) BudgetedCanDispatch enforces per-project budget limits\n2) Scheduler checks budget before dispatching work\n3) Falls back gracefully when no budget configured  \n4) Logs budget enforcement decisions for visibility\n5) Maintains current behavior for projects without budget allocation\n\n## Dependencies\n- Requires cortex-ood (budget configuration)\n- Requires cortex-rlj (per-project tracking)\n\n## Files to Modify\n- internal/dispatch/ratelimit.go (add BudgetedCanDispatch)\n- internal/scheduler/scheduler.go (integrate budget checks)","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:44:37.685658714+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:44:37.685658714+10:00","labels":["budget","enforcement","scheduler"],"dependencies":[{"issue_id":"cortex-nk8","depends_on_id":"cortex-ood","type":"blocks","created_at":"2026-02-18T02:44:48.080204885+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-nk8","depends_on_id":"cortex-rlj","type":"blocks","created_at":"2026-02-18T02:44:51.307894891+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-nkq","title":"Add basic project context queries","description":"Create simple project state queries to support scrum master context. Simplified version of cortex-a4s.2.\n\n## Goal\nProvide basic project statistics and state information for scrum master agents.\n\n## Scope\nCreate internal/project/stats.go with simple query functions for project statistics.\n\n## Implementation\n- Query beads.ListBeads() for open bead count\n- Query store.GetRunningDispatches() filtered by project for in-progress count  \n- Query store dispatches table for today's completed/failed counts\n- Format as simple markdown: '3 open, 1 in-progress, 2 completed today'\n\n## Acceptance Criteria\n1) GetBasicProjectStats returns accurate counts from database\n2) Handles empty/missing projects gracefully (return zeros)\n3) FormatProjectStats produces clean markdown output\n4) All queries are efficient (no N+1 patterns)\n5) Unit tests cover basic functionality\n\n## Files to Create\n- internal/project/stats.go\n- internal/project/stats_test.go","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:37:57.315908208+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:37:57.315908208+10:00","labels":["context","queries","scrum"]}
{"id":"cortex-o3u","title":"Auto: churn guard blocked bead cortex-46d.8 (8 dispatches/1h0m0s)","description":"Bead `cortex-46d.8` in project `cortex` exceeded churn threshold (8 dispatches in 1h0m0s) and was blocked from further overnight dispatch.\n\nPlease investigate root cause, split work into smaller tasks if needed, and add hardening/tests before re-enabling.\n\nBead title: Harden tmux dispatcher command error handling and cleanup parsing\nBead type: bug","status":"open","priority":1,"issue_type":"bug","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:00:13.329038819+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:04:08.928041269+10:00","dependencies":[{"issue_id":"cortex-o3u","depends_on_id":"cortex-46d.8","type":"discovered-from","created_at":"2026-02-18T02:00:13.332491447+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-oa5","title":"Auto: repeated failure (3x/15m): \u003cnone\u003e","description":"Nightwatch detected repeated dispatch failures in the last 15 minutes.\\n\\nCount: 3\\nSummary: \u003cnone\u003e\\nDispatch IDs: 1189,1190,1191\\nBeads: cortex-84h,cortex-trl,cortex-byi\\nDetected at: 2026-02-18T05:05:33+10:00\\n\\nPlease investigate root cause and patch.","status":"closed","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T05:05:34.575551114+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T05:05:49.364082048+10:00","closed_at":"2026-02-18T05:05:49.364082048+10:00","close_reason":"auto-verified by codex-worker: repeated failure signature is not present in last 15 minutes"}
{"id":"cortex-ood","title":"Add rate limit budget configuration parsing","description":"Extend rate limit configuration to support per-project budget allocation. Foundation for capacity budgeting.\n\n## Goal\nAdd per-project budget configuration to rate limits section.\n\n## Scope\nExtend internal/config/config.go RateLimits struct with budget allocation map.\n\n## Implementation  \n- Add Budget map[string]int field to RateLimits struct\n- Parse rate_limits.budget section from TOML\n- Add validation: budget percentages must sum to 100 if present\n- Budget is optional - if missing, use shared pool (current behavior)\n- Helper method: GetProjectBudget(project) returns allocated percentage\n\n## Example Configuration\nProjects can be allocated percentage of weekly rate limit capacity.\n\n## Acceptance Criteria\n1) Config parses rate_limits.budget section correctly\n2) Validation enforces budget percentages sum to 100\n3) Optional budget section maintains backward compatibility  \n4) GetProjectBudget helper works for configured and unconfigured projects\n5) Unit tests cover budget parsing and validation\n\n## Files to Modify\n- internal/config/config.go (extend RateLimits struct)\n- internal/config/config_test.go (test budget configuration)","notes":"**Review Result: APPROVED ✅**\n\n**Outstanding Implementation - All Acceptance Criteria Met**\n\n## ✅ Configuration Structure\n\n**RateLimits Struct Extension:**\n- Added Budget field: map[string]int with proper TOML annotation\n- Clean integration with existing RateLimits fields\n- Maintains backward compatibility with existing configurations\n\n**TOML Parsing:**\n- Parses [rate_limits.budget] section correctly\n- Maps project names to percentage allocations\n- Supports standard TOML integer syntax\n\n## ✅ Validation Logic - Comprehensive\n\n**Budget Validation Rules:**\n- ✅ **Negative percentages**: Rejects negative values with clear error messages\n- ✅ **Over 100% percentages**: Prevents individual projects exceeding 100%\n- ✅ **Sum validation**: Enforces total percentages must equal exactly 100\n- ✅ **Optional validation**: Only validates when budget is configured (non-nil and non-empty)\n\n**Validation Error Messages:**\n- Clear, specific error messages with project names and actual values\n- Proper formatting with percentage symbols in error text\n- Descriptive validation that helps users fix configuration issues\n\n## ✅ GetProjectBudget Helper Method\n\n**Method Implementation:**\n- Returns allocated percentage for configured projects\n- Returns 0 for non-configured projects (graceful fallback)\n- Handles nil budget map safely (returns 0)\n- Clean, simple interface for downstream consumption\n\n**Edge Case Handling:**\n- Non-existent projects return 0 (shared pool behavior)\n- Nil budget map returns 0 (backward compatibility)\n- Type-safe integer return values\n\n## ✅ Backward Compatibility\n\n**Optional Budget Section:**\n- Configurations without [rate_limits.budget] load successfully\n- Existing behavior preserved when budget not configured\n- GetProjectBudget returns 0 for all projects (shared pool mode)\n- No breaking changes to existing RateLimits usage\n\n## ✅ Comprehensive Test Coverage\n\n**Test Scenarios (6/6 PASS):**\n\n1. **TestLoadRateLimitBudgetValid** ✅\n   - Valid budget configuration parsing\n   - Correct percentage allocation retrieval\n\n2. **TestLoadRateLimitBudgetSumNot100** ✅\n   - Validation error for percentages not summing to 100\n   - Proper error message verification\n\n3. **TestLoadRateLimitBudgetNegativePercentage** ✅\n   - Validation error for negative budget values\n   - Clear error message for negative validation\n\n4. **TestLoadRateLimitBudgetOver100Percentage** ✅\n   - Validation error for individual percentage \u003e 100%\n   - Specific project-level error handling\n\n5. **TestLoadRateLimitBudgetOptional** ✅\n   - Backward compatibility with configurations lacking budget section\n   - Nil/empty budget handling\n\n6. **TestRateLimitsGetProjectBudget** ✅\n   - Helper method functionality for existing projects\n   - Zero return for non-existent projects\n   - Nil budget map handling\n\n## ✅ Code Quality\n\n**Implementation Excellence:**\n- Clean struct field addition with proper TOML tags\n- Validation logic properly integrated into config validation flow\n- Helper method follows Go conventions\n- Comprehensive error handling with descriptive messages\n\n**Example Configuration Support:**\n\n\n**Integration Testing:**\n- Manual configuration parsing test successful\n- All percentages parsed correctly\n- GetProjectBudget method works as expected\n- Non-existent project returns 0% (shared pool fallback)\n\n## Architecture Assessment\n\n**Foundation for Capacity Budgeting:**\n- Clean foundation for per-project budget allocation\n- Flexible percentage-based system\n- Ready for integration with rate limiting enforcement\n- Maintains shared pool fallback for non-budgeted projects\n\n**Production Readiness:**\n- Comprehensive validation prevents misconfiguration\n- Backward compatible with existing deployments\n- Clear error messages for operational debugging\n- Type-safe integer percentage handling\n\n## Acceptance Criteria Status\n\n**✅ 1) Config parses rate_limits.budget correctly**: TOML parsing works perfectly\n**✅ 2) Validation enforces sum to 100**: Comprehensive validation with clear errors\n**✅ 3) Optional budget maintains compatibility**: Configurations without budget work unchanged\n**✅ 4) GetProjectBudget helper works**: Returns correct values for all scenarios\n**✅ 5) Unit tests cover all scenarios**: 6 comprehensive tests, all passing\n\n**Outstanding implementation** that provides a solid foundation for per-project rate limit budgeting while maintaining perfect backward compatibility.\n\n**Ready for QA validation** ✅\n\nApproved for stage:qa","status":"closed","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:43:54.570177136+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T03:12:13.820552453+10:00","closed_at":"2026-02-18T03:12:10.747249212+10:00","close_reason":"Closed","labels":["stage:qa","stage:review"]}
{"id":"cortex-otx","title":"Auto: repeated '-m/--message' runtime failures","description":"Detected 3 failures in the last 15 minutes with: required option '-m, --message \u003ctext\u003e' not specified.\\n\\nNightwatch restarted Cortex automatically. Inspect recent dispatch output tails and CLI routing config.","status":"open","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:34:59.510953201+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T05:19:58.414094257+10:00","labels":["stage:review"]}
{"id":"cortex-pg5","title":"Multi-workflow support: stage-based pipelines for dev, content, trading","description":"Replace single-shot dispatch with multi-stage workflow pipelines. Each workflow defines ordered stages with stage-specific roles, prompt templates, transition rules, and validation gates. A bead progresses through stages (each stage = a separate dispatch) rather than being handled in one shot.\n\nTarget workflows:\n- **Dev**: implement → test → review → merge/deploy\n- **Content**: research → draft → edit/review → publish\n- **Trading**: signal analysis → risk validation → execution → confirmation/audit\n\nKey capabilities:\n- Workflow definitions in cortex.toml config\n- Workflow engine tracking stage progression per bead\n- Stage-aware prompt building with per-stage templates\n- New roles beyond coder/reviewer/ops (writer, editor, analyst, executor, etc.)\n- DB schema extension for stage tracking (current stage, stage history, stage outputs)\n- Automatic workflow assignment based on bead labels/type\n- Gates between stages (e.g., tests must pass before review stage)\n- Manual override to skip/repeat stages\n\nThis is the largest architectural change since initial orchestrator implementation.","status":"closed","priority":1,"issue_type":"epic","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:05:13.440994334+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:34:12.587532744+10:00","closed_at":"2026-02-18T04:34:12.587532744+10:00","close_reason":"Epic completed - broken down into 10 executable tasks"}
{"id":"cortex-pg5.1","title":"Define workflow data model and config schema","description":"Design and implement the core data structures for workflows.\n\nA Workflow definition needs:\n- Name (string identifier, e.g. 'dev', 'content', 'trading')\n- Stages: ordered list of Stage definitions\n- Default: bool (is this the fallback workflow?)\n- Match rules: labels/types that auto-assign this workflow\n\nA Stage definition needs:\n- Name (e.g. 'implement', 'test', 'review')\n- Role (agent role for this stage, e.g. 'coder', 'reviewer', 'writer')\n- Tier override (optional, force a specific complexity tier)\n- Prompt template key (which prompt template to use)\n- Gate (optional validation command that must succeed before advancing)\n- Auto-advance (bool: advance automatically on completion, or wait?)\n\nConfig schema in cortex.toml:\n```toml\n[workflows.dev]\ndefault = true\nmatch_labels = [\"dev\", \"code\", \"feature\", \"bug\"]\nmatch_types = [\"task\", \"bug\", \"feature\"]\n\n[[workflows.dev.stages]]\nname = \"implement\"\nrole = \"coder\"\nprompt_template = \"implement\"\n\n[[workflows.dev.stages]]\nname = \"test\"\nrole = \"reviewer\"\nprompt_template = \"test\"\ngate = \"go test ./...\"\n\n[[workflows.dev.stages]]\nname = \"review\"\nrole = \"reviewer\"\nprompt_template = \"review\"\ntier = \"premium\"\n```\n\nCreate Go types in internal/workflow/types.go\n\nAcceptance: Types compile, config can be parsed from TOML, unit test for parsing","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:06:34.87931377+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T20:13:32.561412478+10:00","closed_at":"2026-02-17T20:13:32.561412478+10:00","close_reason":"Workflow data model implemented: Workflow, Stage, Registry types with match rules, stage navigation, and comprehensive tests","dependencies":[{"issue_id":"cortex-pg5.1","depends_on_id":"cortex-pg5","type":"parent-child","created_at":"2026-02-17T17:06:34.929296003+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-pg5.10","title":"Add comprehensive tests for workflow system","description":"Write tests for the entire workflow system.\n\nTest files:\n- internal/workflow/types_test.go - config parsing, validation\n- internal/workflow/engine_test.go - stage progression, gate handling, completion\n- internal/workflow/prompts_test.go - template rendering per stage\n- internal/workflow/builtin_test.go - built-in workflow correctness\n- internal/store/store_test.go - new stage tracking methods\n- internal/scheduler/scheduler_test.go - workflow-integrated tick\n\nKey test scenarios:\n- Bead progresses through all stages of dev workflow\n- Gate failure prevents stage advancement\n- Bead with no matching workflow uses single-shot mode\n- Config override replaces built-in workflow\n- Stage tier override is respected\n- Concurrent beads at different stages\n- Backward compat: no workflows config = old behavior\n\nAcceptance: All tests pass, \u003e80% coverage on workflow package","notes":"**Review Result: Changes Needed**\n\nIssue: Cannot review tests for non-existent code. The workflow system has not been implemented yet.\n\nMissing Dependencies: All blocking issues are still OPEN:\n- cortex-pg5.1: Define workflow data model and config schema  \n- cortex-pg5.2: Extend config parser for workflow definitions\n- cortex-pg5.3: Extend DB schema for workflow stage tracking\n- cortex-pg5.4: Implement workflow engine for stage progression\n- cortex-pg5.5: Add stage-aware prompt templates\n- cortex-pg5.6: Extend role system for workflow-specific roles  \n- cortex-pg5.7: Update scheduler to drive workflow stages\n- cortex-pg5.8: Add built-in workflow templates\n\nMissing Files: None of the expected test files exist:\n- internal/workflow/ directory doesn't exist\n- No workflow types, engine, prompts, or builtin modules to test\n\nAction Required: Complete all dependency issues first. The workflow system must be implemented before comprehensive tests can be written.\n\nNext Steps: \n1. Implement the core workflow system (cortex-pg5.1 through cortex-pg5.8)\n2. Return this issue to review queue once all dependencies are closed\n3. Tests should achieve \u003e80% coverage on the workflow package\n\nTransitioned back to stage:coding for dependency resolution.","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:07:33.605339669+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T18:01:01.47428132+10:00","labels":["stage:coding","test"],"dependencies":[{"issue_id":"cortex-pg5.10","depends_on_id":"cortex-pg5","type":"parent-child","created_at":"2026-02-17T17:07:33.762863647+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-pg5.10","depends_on_id":"cortex-pg5.1","type":"blocks","created_at":"2026-02-17T17:12:49.005518011+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-pg5.10","depends_on_id":"cortex-pg5.2","type":"blocks","created_at":"2026-02-17T17:12:49.184559794+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-pg5.10","depends_on_id":"cortex-pg5.3","type":"blocks","created_at":"2026-02-17T17:12:49.3910256+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-pg5.10","depends_on_id":"cortex-pg5.4","type":"blocks","created_at":"2026-02-17T17:12:49.549064945+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-pg5.10","depends_on_id":"cortex-pg5.5","type":"blocks","created_at":"2026-02-17T17:12:49.695756234+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-pg5.10","depends_on_id":"cortex-pg5.6","type":"blocks","created_at":"2026-02-17T17:12:49.857952152+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-pg5.10","depends_on_id":"cortex-pg5.7","type":"blocks","created_at":"2026-02-17T17:12:50.019518985+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-pg5.10","depends_on_id":"cortex-pg5.8","type":"blocks","created_at":"2026-02-17T17:12:50.220371225+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-pg5.10","depends_on_id":"cortex-pg5.9","type":"blocks","created_at":"2026-02-17T17:12:50.366381872+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-pg5.2","title":"Extend config parser for workflow definitions","description":"Update internal/config/config.go to parse [workflows.*] sections from cortex.toml.\n\n- Add WorkflowConfig and StageConfig structs to Config\n- Parse match_labels, match_types, stages array\n- Validate: at least one workflow if workflows section exists\n- Validate: each stage has name and role\n- Validate: no duplicate stage names within a workflow\n- Validate: referenced roles are known\n- Backward compatible: if no [workflows] section, system works as before (single-shot)\n\nAcceptance: Config parsing works with and without workflows section, validation catches malformed configs","status":"in_progress","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:06:39.043856508+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T21:48:32.569235349+10:00","labels":["stage:review"],"dependencies":[{"issue_id":"cortex-pg5.2","depends_on_id":"cortex-pg5","type":"parent-child","created_at":"2026-02-17T17:06:39.060093324+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-pg5.2","depends_on_id":"cortex-pg5.1","type":"blocks","created_at":"2026-02-17T17:12:23.303038929+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-pg5.3","title":"Extend DB schema for workflow stage tracking","description":"Add workflow stage tracking to the SQLite store (internal/store/store.go).\n\nNew table: bead_stages\n- id (auto PK)\n- bead_id (string)\n- project (string)\n- workflow (string, workflow name)\n- current_stage (string, stage name)\n- stage_index (int, 0-based position in workflow)\n- total_stages (int)\n- stage_history (JSON array of {stage, status, started_at, completed_at, dispatch_id})\n- created_at, updated_at\n\nNew methods:\n- InitBeadWorkflow(beadID, project, workflow, stages) - create tracking record\n- GetBeadStage(beadID) - current stage info\n- AdvanceStage(beadID) - move to next stage\n- RecordStageCompletion(beadID, stage, dispatchID) - log stage done\n- GetBeadsAtStage(project, stage) - query by stage\n- IsWorkflowComplete(beadID) - all stages done?\n\nUpdate dispatches table: add 'workflow' and 'stage' columns (nullable for backward compat).\n\nAcceptance: Schema migrates cleanly, methods work, existing data unaffected","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:06:44.122181075+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T17:06:44.122181075+10:00","dependencies":[{"issue_id":"cortex-pg5.3","depends_on_id":"cortex-pg5","type":"parent-child","created_at":"2026-02-17T17:06:44.157824257+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-pg5.4","title":"Implement workflow engine for stage progression","description":"Create internal/workflow/engine.go - the core workflow engine that drives beads through stages.\n\nEngine responsibilities:\n- AssignWorkflow(bead) → workflow name: match bead labels/type against workflow match rules, fall back to default workflow, return 'single-shot' if no workflows configured\n- GetCurrentStage(bead) → stage definition: look up where bead is in its workflow\n- ShouldDispatch(bead, stage) → bool: check if stage needs a new dispatch (not already running)\n- RunGate(bead, stage) → (passed bool, output string): execute gate command if defined\n- Advance(bead) → (nextStage, done): move to next stage or mark workflow complete\n- HandleStageCompletion(bead, dispatch) → action: when a dispatch completes, decide next action (run gate → advance or fail)\n\nThe engine sits between the scheduler and dispatcher. The scheduler calls the engine to determine what to dispatch next for each bead.\n\nKey design: the engine is stateless - all state lives in the DB (bead_stages table). Engine reads state, computes action, writes state.\n\nAcceptance: Engine correctly progresses beads through multi-stage workflows, handles gate failures, integrates with store","status":"open","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:06:49.78662763+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T17:06:49.78662763+10:00","dependencies":[{"issue_id":"cortex-pg5.4","depends_on_id":"cortex-pg5","type":"parent-child","created_at":"2026-02-17T17:06:49.807644349+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-pg5.4","depends_on_id":"cortex-pg5.1","type":"blocks","created_at":"2026-02-17T17:12:23.527139002+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-pg5.4","depends_on_id":"cortex-pg5.2","type":"blocks","created_at":"2026-02-17T17:12:39.725638067+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-pg5.4","depends_on_id":"cortex-pg5.3","type":"blocks","created_at":"2026-02-17T17:12:39.924255356+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-pg5.5","title":"Add stage-aware prompt templates","description":"Extend internal/scheduler/prompt.go to support per-stage prompt templates.\n\nCurrent BuildPrompt() creates a single generic prompt. Need multiple templates:\n\nTemplates (internal/workflow/prompts.go):\n- 'implement': Current default prompt (implement the task)\n- 'test': Focus on writing/running tests for already-implemented code\n- 'review': Review code changes, check for bugs/style/security, suggest fixes\n- 'draft': Write content based on brief/outline (for content workflow)\n- 'edit': Edit/improve existing content for clarity and quality\n- 'publish': Format and prepare content for publication\n- 'analyze': Analyze data/signals and produce structured findings\n- 'validate': Check analysis against risk rules, flag concerns\n- 'execute': Execute a validated action with audit trail\n\nEach template receives the same context (bead info, workspace, acceptance criteria) but frames the task differently.\n\nBuildPrompt signature changes: BuildPrompt(bead, workspace, stage) where stage determines template selection.\n\nAlso include stage context in prompt: 'You are at stage 2/4 (test) of the dev workflow. Previous stage (implement) was completed by agent X.'\n\nAcceptance: Prompts render correctly per stage, backward compatible when no workflow","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:06:54.983770899+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T17:06:54.983770899+10:00","dependencies":[{"issue_id":"cortex-pg5.5","depends_on_id":"cortex-pg5","type":"parent-child","created_at":"2026-02-17T17:06:55.015798901+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-pg5.5","depends_on_id":"cortex-pg5.1","type":"blocks","created_at":"2026-02-17T17:12:23.758666929+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-pg5.6","title":"Extend role system for workflow-specific roles","description":"Extend internal/scheduler/role.go to support workflow-defined roles.\n\nCurrent roles: coder, reviewer, ops (inferred from labels).\n\nNew roles needed:\n- writer (content drafting)\n- editor (content editing/review)\n- publisher (content publishing)\n- analyst (data/signal analysis)\n- risk (risk validation)\n- executor (action execution)\n- auditor (confirmation/audit)\n\nChanges:\n- When a workflow stage specifies a role, use that role directly (no inference needed)\n- Keep InferRole() as fallback for single-shot mode (no workflow)\n- Agent naming: {project}-{role} remains the pattern\n- Add ValidateRole() to check role is known\n\nAcceptance: Workflow-specified roles override inferred roles, agent names resolve correctly","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:06:59.541458505+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T17:06:59.541458505+10:00","dependencies":[{"issue_id":"cortex-pg5.6","depends_on_id":"cortex-pg5","type":"parent-child","created_at":"2026-02-17T17:06:59.570084549+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-pg5.6","depends_on_id":"cortex-pg5.1","type":"blocks","created_at":"2026-02-17T17:12:23.9932262+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-pg5.7","title":"Update scheduler to drive workflow stages","description":"Modify internal/scheduler/scheduler.go RunTick to integrate the workflow engine.\n\nCurrent flow: discover beads → infer role/complexity → pick provider → dispatch\nNew flow: discover beads → assign workflow → get current stage → check gates → infer complexity (or use stage override) → pick provider → dispatch stage\n\nKey changes to RunTick:\n1. After filtering unblocked beads, call engine.AssignWorkflow() for each\n2. For workflow beads: call engine.GetCurrentStage() instead of InferRole()\n3. Use stage.Role for agent resolution (not label-inferred role)\n4. Use stage.Tier override if set, else DetectComplexity() as before\n5. Pass stage to BuildPrompt()\n6. On dispatch completion detection: call engine.HandleStageCompletion()\n   - If gate passes → engine.Advance() → next tick dispatches next stage\n   - If gate fails → mark stage failed, retry or escalate\n7. A bead is only closed (bd close) when IsWorkflowComplete() returns true\n8. Single-shot beads (no workflow match) continue working exactly as before\n\nAcceptance: Multi-stage beads progress through workflow, single-shot beads unaffected, gates enforced","status":"open","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:07:06.913146127+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T17:07:06.913146127+10:00","dependencies":[{"issue_id":"cortex-pg5.7","depends_on_id":"cortex-pg5","type":"parent-child","created_at":"2026-02-17T17:07:07.012047961+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-pg5.7","depends_on_id":"cortex-pg5.4","type":"blocks","created_at":"2026-02-17T17:12:40.096220052+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-pg5.7","depends_on_id":"cortex-pg5.5","type":"blocks","created_at":"2026-02-17T17:12:40.313278826+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-pg5.7","depends_on_id":"cortex-pg5.6","type":"blocks","created_at":"2026-02-17T17:12:40.616978352+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-pg5.7","depends_on_id":"cortex-pg5.8","type":"blocks","created_at":"2026-02-17T17:12:40.828620379+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-pg5.8","title":"Add built-in workflow templates: dev, content, trading","description":"Create three built-in workflow definitions that ship with Cortex.\n\nFile: internal/workflow/builtin.go\n\n**Dev Workflow** (default=true):\n- match_labels: dev, code, feature, bug, refactor\n- match_types: task, bug, feature\n- Stages:\n  1. implement (coder) - write the code\n  2. test (reviewer, gate: 'go test ./...') - verify with tests\n  3. review (reviewer, tier: premium) - code review\n\n**Content Workflow**:\n- match_labels: content, blog, docs, copy, writing\n- match_types: docs\n- Stages:\n  1. research (analyst) - gather context and outline\n  2. draft (writer) - write first draft\n  3. edit (editor) - review and polish\n  4. publish (publisher) - format and ship\n\n**Trading Workflow**:\n- match_labels: trade, signal, execution, position\n- Stages:\n  1. analyze (analyst, tier: premium) - analyze signal/opportunity\n  2. validate (risk) - risk check and sizing\n  3. execute (executor) - place the trade\n  4. confirm (auditor) - verify execution and log\n\nBuilt-ins are used when no [workflows] config exists. If config defines workflows, they override built-ins. Provide a MergeWithBuiltins() function that lets config extend rather than replace.\n\nAcceptance: Built-in workflows available out of box, overridable via config","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:07:17.704634701+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T17:07:17.704634701+10:00","dependencies":[{"issue_id":"cortex-pg5.8","depends_on_id":"cortex-pg5","type":"parent-child","created_at":"2026-02-17T17:07:17.751369399+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-pg5.8","depends_on_id":"cortex-pg5.1","type":"blocks","created_at":"2026-02-17T17:12:24.197539381+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-pg5.9","title":"Add workflow status API endpoints","description":"Extend internal/api/api.go with workflow-related endpoints.\n\nNew endpoints:\n- GET /workflows - list all defined workflows with their stages\n- GET /workflows/{name} - detail view of a workflow definition\n- GET /beads/{id}/workflow - current workflow state for a bead (stage, history, progress)\n- GET /projects/{id}/pipeline - all beads grouped by their current workflow stage\n\nUpdate existing endpoints:\n- GET /status - add workflow_beads_in_progress count, beads_by_stage breakdown\n- GET /metrics - add cortex_workflow_stage_duration_seconds histogram, cortex_workflow_completions_total counter\n\nAcceptance: Endpoints return correct data, backward compatible (empty/null when no workflows)","status":"open","priority":3,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:07:25.439383905+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T17:07:25.439383905+10:00","dependencies":[{"issue_id":"cortex-pg5.9","depends_on_id":"cortex-pg5","type":"parent-child","created_at":"2026-02-17T17:07:25.480979113+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-pg5.9","depends_on_id":"cortex-pg5.7","type":"blocks","created_at":"2026-02-17T17:12:40.990799346+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-q3c","title":"Define Backend dispatcher interface","description":"Create internal/dispatch/backend.go with the pluggable Backend interface:\n\ntype Backend interface {\n    Dispatch(ctx context.Context, opts DispatchOpts) (Handle, error)\n    Status(handle Handle) (DispatchStatus, error)\n    CaptureOutput(handle Handle) (string, error)\n    Kill(handle Handle) error\n    Cleanup(handle Handle) error\n}\n\nPlus DispatchOpts, Handle, and DispatchStatus structs as specified in cortex-ceg design.\n\nAcceptance: interface compiles, types documented, no implementations yet.","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:59:56.012925745+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T20:18:55.288080014+10:00","closed_at":"2026-02-17T20:18:55.288080014+10:00","close_reason":"Closed","dependencies":[{"issue_id":"cortex-q3c","depends_on_id":"cortex-hr2","type":"blocks","created_at":"2026-02-17T18:01:11.568020684+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-r3x","title":"Add structured error events for dispatch failures","description":"Emit structured diagnostic events when dispatch operations fail to improve observability and debugging.\n\n## Goal\nProvide detailed, structured information about dispatch failures for monitoring and debugging rather than relying on log parsing.\n\n## Scope  \n- Add error event emission for dispatch config failures\n- Add error event emission for backend unavailability  \n- Add error event emission for command construction failures\n- Integrate with existing health event system in store\n- Include structured metadata: bead, provider, backend, reason\n\n## Events to Add\n1. **dispatch_config_invalid** - Provider/CLI config validation failures\n2. **dispatch_backend_unavailable** - Configured backend not available  \n3. **dispatch_command_build_failed** - Command construction/shell issues\n4. **dispatch_provider_unavailable** - Provider CLI missing or broken\n\n## Event Structure\n```go\ntype DispatchErrorEvent struct {\n    EventType string\n    BeadID    string\n    Provider  string  \n    Backend   string\n    Reason    string\n    Details   string\n}\n```\n\n## Acceptance Criteria\n1) Config validation failures emit dispatch_config_invalid events\n2) Backend unavailability emits dispatch_backend_unavailable events  \n3) Command construction failures emit dispatch_command_build_failed events\n4) All events include structured metadata (bead, provider, backend, reason)\n5) Events integrate with existing health monitoring and can be queried\n\n## Integration\n- Use existing store.RecordHealthEventWithDispatch() \n- Events appear in /health API endpoint\n- Compatible with monitoring/alerting systems","status":"open","priority":3,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:31:16.890465056+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:31:16.890465056+10:00","labels":["events","monitoring","observability"]}
{"id":"cortex-rlj","title":"Add per-project rate limit tracking","description":"Extend rate limiter to track usage per project instead of only globally.\n\n## Goal\nTrack rate limit usage separately by project to enable budget enforcement.\n\n## Scope\nExtend internal/dispatch/ratelimit.go to track per-project usage:\n\n## Implementation\n- Add project parameter to RecordAuthedDispatch method\n- Add CountAuthedUsageByProject method (similar to existing count methods)\n- Store queries group dispatches by project when counting\n- Maintain backward compatibility with existing rate limit logic\n\n## New Methods\n- RecordAuthedDispatch(model, agent, beadID, project) - add project param\n- CountAuthedUsageByProject(project, window) - project-specific counts\n- GetProjectUsageSummary() - usage across all projects\n\n## Database Integration\n- Modify existing store queries to support project grouping\n- Use existing dispatches table project field\n- Efficient queries with proper indexes\n\n## Acceptance Criteria\n1) RecordAuthedDispatch accepts project parameter  \n2) CountAuthedUsageByProject returns accurate per-project counts\n3) Maintains backward compatibility with existing rate limit checks\n4) Database queries are efficient and properly indexed\n5) Unit tests cover per-project tracking functionality\n\n## Dependencies\n- Requires cortex-ood (budget configuration parsing)\n\n## Files to Modify  \n- internal/dispatch/ratelimit.go (add per-project methods)\n- internal/dispatch/ratelimit_test.go (test per-project tracking)","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:44:26.332846459+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:44:26.332846459+10:00","labels":["per-project","rate-limits","tracking"],"dependencies":[{"issue_id":"cortex-rlj","depends_on_id":"cortex-ood","type":"blocks","created_at":"2026-02-18T02:44:44.070968921+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-san","title":"Auto: break down epic cortex-c4j into executable bug/task beads","description":"Epic `cortex-c4j` is still open in project `cortex`.\n\nPolicy: epics should not be assigned directly to coders. Break this epic into concrete `bug`/`task` beads with acceptance criteria so overnight automation can execute them.\n\nEpic title: Launch readiness go/no-go execution plan","status":"closed","priority":1,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T03:20:15.909548722+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:23:45.768536093+10:00","closed_at":"2026-02-18T04:23:45.768536093+10:00","close_reason":"Duplicate breakdown tasks - epic was already decomposed and completed by cortex-bjc","dependencies":[{"issue_id":"cortex-san","depends_on_id":"cortex-c4j","type":"discovered-from","created_at":"2026-02-18T03:20:15.918067655+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-sfb","title":"Stage-based pipeline + auto-spawn teams","description":"Implement stage-based role inference, stage-aware prompts, agent-busy guard, stage dispatch, auto-spawn teams, and /teams API endpoint","status":"closed","priority":1,"issue_type":"feature","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:10:58.547732864+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T17:14:48.403083372+10:00","closed_at":"2026-02-17T17:14:48.403083372+10:00","close_reason":"Implemented stage-based pipeline with auto-spawn teams"}
{"id":"cortex-sgw","title":"Validate CLI bindings at startup","description":"Add startup validation to ensure provider-\u003eCLI mappings exist and required CLI tools are available. Current system allows runtime failures when CLI tools are missing or misconfigured.\n\n## Goal\nFast-fail startup when dispatch configuration is invalid rather than encountering runtime errors during dispatch.\n\n## Scope\n- Add validation in config.Load() to check provider-\u003eCLI mappings\n- Verify CLI tools exist and are executable  \n- Check for required flags (model_flag, args) in CLI configs\n- Provide clear error messages for misconfigurations\n\n## Acceptance Criteria\n1) Startup fails with clear message when provider references missing CLI config\n2) Startup fails when CLI executable is not found or not executable  \n3) Startup validates required CLI config fields (cmd, model_flag)\n4) Validation covers all configured providers in tiers (fast/balanced/premium)\n5) Error messages guide user to fix specific configuration issues\n\n## Test Coverage\n- Missing CLI config for provider\n- CLI executable not found\n- Invalid CLI configuration (missing required fields)  \n- Valid configuration passes validation","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:30:44.519450141+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:30:44.519450141+10:00","labels":["config","startup","validation"]}
{"id":"cortex-spo","title":"Auto: break down epic cortex-2px into executable bug/task beads","description":"Epic `cortex-2px` is still open in project `cortex`.\n\nPolicy: epics should not be assigned directly to coders. Break this epic into concrete `bug`/`task` beads with acceptance criteria so overnight automation can execute them.\n\nEpic title: Git workflow: branches, PRs, and review","status":"closed","priority":1,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T04:24:24.022255189+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:26:39.404141849+10:00","closed_at":"2026-02-18T04:26:39.404141849+10:00","close_reason":"Epic breakdown completed successfully - cortex-2px epic fully broken down into executable tasks","dependencies":[{"issue_id":"cortex-spo","depends_on_id":"cortex-2px","type":"discovered-from","created_at":"2026-02-18T04:24:24.024659595+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-trl","title":"Runbook: rollback to prior known-good release","description":"Create a rollback runbook for restoring Cortex to last known-good config/binary.\n\nAcceptance criteria:\n1) Document rollback trigger criteria and exact rollback commands.\n2) Include verification checklist to confirm stable post-rollback state.\n3) Record one tabletop drill outcome under artifacts/launch/runbooks/.","status":"closed","priority":1,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:42:08.026505926+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:59:23.826861567+10:00","closed_at":"2026-02-18T04:59:23.826861567+10:00","close_reason":"Closed","labels":["stage:qa","stage:review"],"dependencies":[{"issue_id":"cortex-trl","depends_on_id":"cortex-c4j.3","type":"discovered-from","created_at":"2026-02-18T02:42:08.031536668+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-tsv","title":"Add bead redispatch cooldown to stop per-tick repeat executions","description":"## Summary\nCompleted/failed dispatches become immediately eligible for redispatch every tick if bead remains open, causing repeated executions and credit burn.\n\n## Scope\n- Add dispatch dedup guard using recent attempt window at bead level.\n- Apply guard to normal dispatch and retry selection paths where appropriate.\n- Expose reason in logs when dispatch skipped due to cooldown.\n\n## Hardening\n- Prevent starvation by allowing dispatch after cooldown expiry.\n- Make cooldown configurable (default conservative value).\n\n## Tests\n- Add scheduler tests that reproduce rapid redispatch and verify cooldown blocks duplicate dispatch within window.\n- Add test that dispatch resumes after window expiry.\n\n## Acceptance Criteria\n- Same bead is not redispatched every tick immediately after completion/failure.\n- Cooldown behavior is deterministic and test-covered.\n- Existing retry semantics remain functional.\n","status":"closed","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T21:25:59.109582428+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T21:57:31.120980615+10:00","closed_at":"2026-02-17T21:57:31.120980615+10:00","close_reason":"Implemented with hardening changes and automated tests","labels":["code","hardening","scheduler","test"]}
{"id":"cortex-tyl","title":"Phase 2: Health \u0026 Self-Healing","description":"Gateway monitoring, stuck task detection with tier escalation, zombie process cleanup, flock mutex for single-instance enforcement. Runs as separate goroutine on 2min interval.","status":"closed","priority":2,"issue_type":"epic","owner":"simon.heikkila@gmail.com","estimated_minutes":240,"created_at":"2026-02-17T13:37:53.458300888+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:55:46.340134573+10:00","closed_at":"2026-02-17T14:55:46.340134573+10:00","close_reason":"Phase 2 complete","labels":["health","phase-2"]}
{"id":"cortex-tyl.1","title":"Gateway health monitor","description":"Implement internal/health/health.go — monitors the OpenClaw gateway service.\n\nFunction:\n- CheckGateway(unitName string) -\u003e HealthStatus\n  1. Run: systemctl --user is-active {unitName}\n  2. If inactive -\u003e attempt restart: systemctl --user restart {unitName}\n  3. If restart fails -\u003e check for stale locks/PIDs in /tmp/openclaw-gateway*, clear them, retry\n  4. Record health event to store (gateway_restart type)\n  5. Track restart count in rolling 1h window\n  6. If 3+ restarts in 1h -\u003e return critical status (triggers Matrix alert upstream)\n\nRuns as separate goroutine on config.Health.CheckInterval (default 2min).\n\nAcceptance criteria:\n- Detects inactive gateway and restarts it\n- Clears stale lock files on restart failure\n- Records all health events to SQLite\n- Escalates to alert after 3 restarts in 1h\n- Unit tests mock systemctl commands","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":60,"created_at":"2026-02-17T14:13:05.776280397+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:55:46.02130734+10:00","closed_at":"2026-02-17T14:55:46.02130734+10:00","close_reason":"Phase 2 health modules implemented with tests","labels":["health","phase-2"],"dependencies":[{"issue_id":"cortex-tyl.1","depends_on_id":"cortex-tyl","type":"parent-child","created_at":"2026-02-17T14:13:05.780322968+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-tyl.1","depends_on_id":"cortex-08z.3","type":"blocks","created_at":"2026-02-17T14:13:05.786912944+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-tyl.2","title":"Stuck task detection + tier escalation","description":"Implement internal/health/stuck.go — detects dispatched tasks that have been running too long and handles retries with tier escalation.\n\nFunction:\n- CheckStuckDispatches(timeout duration, maxRetries int) -\u003e []StuckAction\n  1. Query store.GetStuckDispatches(timeout) — dispatches WHERE status=running AND dispatched_at \u003c now()-timeout\n  2. For each stuck dispatch:\n     a. Check if PID is still alive (kill -0 pid)\n     b. If PID dead -\u003e mark status=failed in store\n     c. If PID alive but past timeout -\u003e kill it (SIGTERM, wait 5s, SIGKILL)\n     d. If retries \u003c maxRetries: re-dispatch with escalated tier (fast-\u003ebalanced-\u003epremium)\n        Set escalated_from_tier on new dispatch record\n     e. If retries \u003e= maxRetries -\u003e mark status=failed, log, return alert action\n  3. Record health events for each action taken\n\nAcceptance criteria:\n- Correctly identifies stuck dispatches past timeout\n- Dead PIDs detected and cleaned up\n- Alive-but-stuck PIDs killed gracefully\n- Tier escalation works: fast-\u003ebalanced-\u003epremium\n- Stops retrying after maxRetries, flags for alert\n- Unit tests with mock PID checks and store data","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":60,"created_at":"2026-02-17T14:19:24.632167247+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:55:46.044554518+10:00","closed_at":"2026-02-17T14:55:46.044554518+10:00","close_reason":"Phase 2 health modules implemented with tests","labels":["health","phase-2"],"dependencies":[{"issue_id":"cortex-tyl.2","depends_on_id":"cortex-tyl","type":"parent-child","created_at":"2026-02-17T14:19:24.646193963+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-tyl.2","depends_on_id":"cortex-08z.3","type":"blocks","created_at":"2026-02-17T14:19:24.70179185+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-tyl.2","depends_on_id":"cortex-08z.8","type":"blocks","created_at":"2026-02-17T14:19:24.724537621+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-tyl.3","title":"Zombie process cleanup","description":"Implement internal/health/zombie.go — finds orphaned openclaw agent processes that have no matching dispatch record.\n\nFunction:\n- CleanZombies() -\u003e int (count killed)\n  1. Run: pgrep -f 'openclaw agent' to get all PIDs running openclaw agents\n  2. Query store.GetRunningDispatches() to get all tracked PIDs\n  3. Any PID from pgrep NOT in the dispatches table is an orphan\n  4. Kill orphans: SIGTERM, wait 5s, SIGKILL if still alive\n  5. Record health event for each zombie killed (zombie_killed type)\n  6. Return count of killed processes\n\nCalled from the health check goroutine on each interval.\n\nAcceptance criteria:\n- Correctly identifies orphan processes (PID exists but no dispatch record)\n- Does NOT kill processes that are tracked in dispatches\n- Graceful kill with SIGTERM fallback to SIGKILL\n- Records health events for audit trail\n- Unit tests with mock pgrep output and store data","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":30,"created_at":"2026-02-17T14:20:27.342833336+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:55:46.083012475+10:00","closed_at":"2026-02-17T14:55:46.083012475+10:00","close_reason":"Phase 2 health modules implemented with tests","labels":["health","phase-2"],"dependencies":[{"issue_id":"cortex-tyl.3","depends_on_id":"cortex-tyl","type":"parent-child","created_at":"2026-02-17T14:20:27.385269769+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-tyl.3","depends_on_id":"cortex-08z.3","type":"blocks","created_at":"2026-02-17T14:20:27.430397688+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-tyl.3","depends_on_id":"cortex-08z.8","type":"blocks","created_at":"2026-02-17T14:20:27.496748999+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-tyl.4","title":"Single-instance flock mutex","description":"Add flock-based mutex to cmd/cortex/main.go so only one Cortex instance can run at a time.\n\nOn startup:\n1. Open lock file at /tmp/cortex.lock (or config-specified path)\n2. Attempt flock(LOCK_EX | LOCK_NB)\n3. If lock fails -\u003e log 'Another Cortex instance is running', exit 1\n4. Hold lock for lifetime of process (released on exit)\n\nUse syscall.Flock in Go.\n\nAcceptance criteria:\n- Second instance exits immediately with clear error message\n- Lock released cleanly on normal exit and SIGTERM\n- Unit test: start two instances, verify second fails","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","estimated_minutes":15,"created_at":"2026-02-17T14:20:43.885573502+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T14:55:46.101392206+10:00","closed_at":"2026-02-17T14:55:46.101392206+10:00","close_reason":"Phase 2 health modules implemented with tests","labels":["health","phase-2"],"dependencies":[{"issue_id":"cortex-tyl.4","depends_on_id":"cortex-tyl","type":"parent-child","created_at":"2026-02-17T14:20:43.902052012+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-tyl.4","depends_on_id":"cortex-08z.10","type":"blocks","created_at":"2026-02-17T14:20:43.922396179+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-u37","title":"Auto: churn guard blocked bead cortex-46d.2 (7 dispatches/1h0m0s)","description":"Bead `cortex-46d.2` in project `cortex` exceeded churn threshold (7 dispatches in 1h0m0s) and was blocked from further overnight dispatch.\n\nPlease investigate root cause, split work into smaller tasks if needed, and add hardening/tests before re-enabling.\n\nBead title: Correct PID dispatcher completion semantics\nBead type: bug","status":"closed","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:21:07.929015335+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:28:56.271075858+10:00","closed_at":"2026-02-18T02:28:56.271075858+10:00","close_reason":"Root cause verified in dispatch history for cortex-46d.2: OpenClaw emitted 'LLM request rejected ... exceed context limit' but tmux pane exited status 0, so scheduler misclassified runs as completed and redispatched until churn guard. Hardened scheduler completion semantics to reclassify zero-exit runs as failed when captured output contains terminal request rejection markers (tmux + PID paths), storing failure diagnosis category context_limit_rejected/llm_request_rejected. Added tests: internal/scheduler/completion_semantics_test.go (context-limit rejection =\u003e failed, normal zero-exit =\u003e completed) and internal/learner/diagnostics_test.go coverage for context_limit_rejected. Validation: go test ./internal/scheduler ./internal/learner and go test ./... both pass.","dependencies":[{"issue_id":"cortex-u37","depends_on_id":"cortex-46d.2","type":"discovered-from","created_at":"2026-02-18T02:21:07.979780779+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-uec","title":"Auto: break down epic cortex-c4j into executable bug/task beads","description":"Epic `cortex-c4j` is still open in project `cortex`.\n\nPolicy: epics should not be assigned directly to coders. Break this epic into concrete `bug`/`task` beads with acceptance criteria so overnight automation can execute them.\n\nEpic title: Launch readiness go/no-go execution plan","status":"closed","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:35:03.018913522+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:23:45.792052327+10:00","closed_at":"2026-02-18T04:23:45.792052327+10:00","close_reason":"Duplicate breakdown tasks - epic was already decomposed and completed by cortex-bjc","dependencies":[{"issue_id":"cortex-uec","depends_on_id":"cortex-c4j","type":"discovered-from","created_at":"2026-02-18T02:35:03.022705527+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-ul3","title":"Pass selected provider/model through dispatch command paths","description":"## Summary\nScheduler selects provider/model, but dispatcher command invocation does not pass model/provider through. This breaks routing intent, cost attribution fidelity, and reliability tuning per tier.\n\n## Scope\n- Thread selected provider/model into `openclaw agent` invocation paths for both PID and tmux dispatchers.\n- Ensure parity across all dispatch backends currently used in runtime.\n- Preserve existing thinking-level behavior.\n\n## Hardening\n- Avoid shell-escaping regressions when adding model flag arguments.\n- Keep behavior backward compatible when provider string is empty.\n\n## Tests\n- Add/extend dispatcher tests to validate model/provider arg propagation for both dispatcher implementations.\n- Add regression assertions for command construction.\n\n## Acceptance Criteria\n- Runtime dispatch command includes selected model/provider.\n- PID and tmux dispatchers behave consistently.\n- Tests fail on regression where model argument is dropped.\n","status":"closed","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T21:25:59.065367895+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T21:57:31.096515201+10:00","closed_at":"2026-02-17T21:57:31.096515201+10:00","close_reason":"Implemented with hardening changes and automated tests","labels":["code","dispatch","hardening","test"]}
{"id":"cortex-umg","title":"Auto: multiple dead-running dispatches reconciled (2)","description":"Nightwatch found and cancelled 2 dead-running dispatches in one cycle at 2026-02-18T01:34:13+10:00.\\n\\n- dispatch 1002 bead cortex-46d.9 pane=1 session=ctx-cortex-cortex-ops-1771342410496069544-3974660-8ee0e96e\n- dispatch 1003 bead cortex-evu.2 pane=1 session=ctx-cortex-cortex-coder-1771342410694056747-3974660-fe4947c7\n","status":"closed","priority":1,"issue_type":"bug","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T01:34:13.490059632+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T01:43:58.594070583+10:00","closed_at":"2026-02-18T01:43:58.594070583+10:00","close_reason":"auto-verified by codex-worker: no dead-running dispatches remain"}
{"id":"cortex-v2h","title":"Implement HeadlessCLI backend","description":"Create internal/dispatch/headless.go implementing Backend interface.\n\n- Builds command from CLI config: cmd + args with {prompt} substitution + model_flag + model + approval_flags\n- Handles prompt_mode: argument (substitute in args), stdin (pipe), tempfile (write and pass path)\n- Redirects stdout/stderr to per-dispatch log file in log_dir\n- Returns Handle with PID and log path\n- Status: check PID alive via syscall.Kill(pid, 0)\n- CaptureOutput: read log file\n- Kill: SIGTERM, wait 5s, SIGKILL (existing pattern)\n- Cleanup: remove log file if past retention\n\nShell escaping must be safe for all prompt_modes.\n\nAcceptance: can dispatch claude -p, codex -q, kilo run --auto, aider --message headlessly. Output captured to file. Exit codes returned.","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:00:05.569056002+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T18:00:05.569056002+10:00","dependencies":[{"issue_id":"cortex-v2h","depends_on_id":"cortex-hr2","type":"blocks","created_at":"2026-02-17T18:01:19.241567289+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-v2h","depends_on_id":"cortex-q3c","type":"blocks","created_at":"2026-02-17T18:01:19.650720412+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-wp6","title":"Runbook: stuck dispatch triage and recovery","description":"Create a runbook for diagnosing and recovering stuck/looping dispatches.\n\nAcceptance criteria:\n1) Include concrete commands for inspection, cancel/retry, and escalation paths.\n2) Define decision points for retry vs quarantine vs manual intervention.\n3) Record one tabletop drill outcome under artifacts/launch/runbooks/.","status":"closed","priority":1,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:42:07.568682808+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T05:14:23.062681943+10:00","closed_at":"2026-02-18T05:14:23.062681943+10:00","close_reason":"Closed","labels":["stage:qa","stage:review"],"dependencies":[{"issue_id":"cortex-wp6","depends_on_id":"cortex-c4j.3","type":"discovered-from","created_at":"2026-02-18T02:42:07.572519932+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-x83","title":"Wrap existing OpenClaw dispatcher as Backend interface","description":"Create internal/dispatch/openclaw.go that wraps the existing Dispatcher to implement the Backend interface.\n\n- Dispatch: delegates to existing Dispatcher.Dispatch() \n- Status: uses existing IsProcessAlive()\n- CaptureOutput: returns empty string (openclaw manages its own output via gateway)\n- Kill: uses existing KillProcess()\n- Cleanup: no-op\n\nThis preserves the existing comms/reporting path unchanged.\n\nAcceptance: existing openclaw dispatch works through new interface. Reporter still functions. No behavior change.","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T18:00:15.217111223+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T18:00:15.217111223+10:00","dependencies":[{"issue_id":"cortex-x83","depends_on_id":"cortex-q3c","type":"blocks","created_at":"2026-02-17T18:01:26.741085505+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-xcp","title":"Auto: churn guard blocked bead cortex-c4j.2 (6 dispatches/1h0m0s)","description":"Bead `cortex-c4j.2` in project `cortex` exceeded churn threshold (6 dispatches in 1h0m0s) and was blocked from further overnight dispatch.\n\nPlease investigate root cause, split work into smaller tasks if needed, and add hardening/tests before re-enabling.\n\nBead title: Automate 7-day burn-in evidence capture and SLO scoring\nBead type: task","status":"in_progress","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:30:10.375054791+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:35:06.470435374+10:00","labels":["stage:review"],"dependencies":[{"issue_id":"cortex-xcp","depends_on_id":"cortex-c4j.2","type":"discovered-from","created_at":"2026-02-18T02:30:10.416741388+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-xhk","title":"LeSS coordination layer: cross-team orchestration","description":"Implement the Large-Scale Scrum (LeSS) coordination layer for multi-project orchestration.\n\nCurrently each project is a silo — its own beads, its own agents, its own scrum master, no awareness of other projects. This epic adds the cross-team coordination that LeSS requires: a Chief Scrum Master, cross-project dependencies, aligned cadence, shared learnings, unified ceremonies, and capacity budgeting.\n\n**Design principle:** build deterministic logic into Go code wherever possible. Only use LLM dispatch for work that requires reasoning (narrative synthesis, priority trade-offs, pattern analysis). Status aggregation, dependency graphs, scheduling, rate limit math — all code.\n\n**Key components:**\n- Cross-project dependency tracking (code)\n- Aligned sprint cadence (code)\n- Chief Scrum Master agent (LLM — the coordination brain)\n- Rate limit capacity budgeting per project (code)\n- Cross-project provider performance profiling (code + LLM)\n- Multi-team sprint planning ceremony (LLM via chief SM)\n- Overall retrospective ceremony (LLM via chief SM)\n- Unified sprint review (LLM via chief SM)\n- Definition of Done enforcement (code)\n- Predictive capacity planning (code)\n- Unified backlog API (code)","notes":"EPIC DECOMPOSED: Epic closed to unblock child task execution by overnight automation.\n\n## Analysis of Original Child Tasks:\n- cortex-xhk.1: Cross-project dependency tracking ✅ COMPLETED\n- cortex-xhk.3: Implement Chief Scrum Master agent ❌ TOO COMPLEX (entire agent system)\n- cortex-xhk.4: Rate limit capacity budgeting ❌ TOO COMPLEX (multi-system integration)  \n- cortex-xhk.6: Multi-team sprint planning ceremony ❌ TOO COMPLEX (entire ceremony system)\n- cortex-xhk.2, xhk.5, xhk.7, xhk.8, xhk.9, xhk.10, xhk.11: ❌ TOO COMPLEX\n\n## New Focused Replacement Tasks Created:\n- cortex-1ik: Add chief scrum master configuration schema (foundation)\n- cortex-ood: Add rate limit budget configuration parsing (foundation)\n- cortex-1ix: Add basic cross-project statistics queries (foundation)\n- cortex-e3f: Create chief scrum master agent role definition (simplified xhk.3)\n- cortex-rlj: Add per-project rate limit tracking (simplified xhk.4 part 1)\n- cortex-nk8: Implement per-project budget enforcement (simplified xhk.4 part 2)\n\n## Benefits of Decomposition:\n- 11 complex, blocked tasks → 6 focused, executable foundation tasks\n- Each task completable in \u003c2 hours focused work\n- Clear dependency chain: Config → Role Creation → Budget Tracking → Enforcement\n- Testable components with single responsibilities\n- Ready for overnight automation execution\n\n## Still Needs Breakdown:\nMost remaining complex tasks (ceremonies, advanced features) still need decomposition into focused work items.","status":"closed","priority":1,"issue_type":"epic","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:36:52.803737261+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:45:05.275864166+10:00","closed_at":"2026-02-18T02:45:05.275872602+10:00"}
{"id":"cortex-xhk.1","title":"Cross-project dependency tracking","description":"Enable beads to depend on beads in other projects. Pure Go code — no LLM needed.\n\n**Current limitation:**\nbd dep add only works within a single project's .beads/ directory. Dependencies are project-scoped. Project B's API integration task can't formally block on Project A's endpoint bead.\n\n**Implementation (all deterministic Go code):**\n\nExtend internal/beads/beads.go:\n- Cross-project bead ID format: {project}:{bead_id} (e.g. 'hg-website:cortex-abc')\n- When DependsOn contains a colon, it's a cross-project dep\n- ListBeads already returns bead IDs — extend to optionally include project prefix\n\nCreate internal/beads/crossdeps.go:\n```go\ntype CrossProjectGraph struct {\n    // project -\u003e bead_id -\u003e []dependency{project, bead_id}\n    Edges map[string]map[string][]CrossDep\n}\n\ntype CrossDep struct {\n    Project string\n    BeadID  string\n}\n\n// BuildCrossProjectGraph scans all enabled projects and builds unified dep graph\nfunc BuildCrossProjectGraph(projects map[string]config.Project) (*CrossProjectGraph, error)\n\n// FilterUnblockedCrossProject returns beads that are unblocked considering cross-project deps\nfunc (g *CrossProjectGraph) FilterUnblocked(project string, beadList []Bead) []Bead\n\n// GetCrossProjectBlockers returns what cross-project deps are blocking a bead\nfunc (g *CrossProjectGraph) GetBlockers(project, beadID string) []CrossDep\n```\n\nUpdate scheduler RunTick:\n- Build CrossProjectGraph once per tick (scans all projects)\n- Use FilterUnblocked instead of FilterUnblockedOpen when cross-deps exist\n- Log cross-project blockers\n\nUpdate internal/api/api.go:\n- GET /dependencies — show cross-project dependency graph\n- Include in project detail endpoint\n\n**No config changes needed** — cross-deps are expressed in bead DependsOn field using the project:bead_id format.\n\nAcceptance: Cross-project deps detected, enforced in scheduler, visible in API","status":"closed","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:39:19.26966189+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T20:10:32.75402631+10:00","closed_at":"2026-02-17T20:10:32.75402631+10:00","close_reason":"Cross-project dependency tracking implemented: ParseCrossDep, CrossProjectGraph, FilterUnblockedCrossProject with comprehensive tests","labels":["code"],"dependencies":[{"issue_id":"cortex-xhk.1","depends_on_id":"cortex-xhk","type":"parent-child","created_at":"2026-02-17T17:39:19.2745517+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-xhk.10","title":"Predictive capacity planning","description":"Predict how long backlogs will take to clear based on velocity. Pure arithmetic — no LLM.\n\n**Implementation:**\n\nCreate internal/learner/forecast.go:\n```go\ntype Forecast struct {\n    Project        string\n    BacklogSize    int       // open beads\n    Velocity       float64   // beads/day (rolling 7d)\n    EstimatedDays  float64   // backlog / velocity\n    EstimatedSprints int     // estimated_days / sprint_length\n    SprintsOfRunway  int     // rate_limit_remaining / avg_dispatches_per_sprint\n    CapacityWarning  string  // 'rate limit will be exhausted in N days'\n}\n\n// ForecastProject predicts backlog completion for a project\nfunc ForecastProject(store *store.Store, project string, cadence *SprintCadence, budget ProjectBudget) (*Forecast, error)\n\n// ForecastPortfolio runs forecast for all projects\nfunc ForecastPortfolio(store *store.Store, projects map[string]config.Project, cadence *SprintCadence) ([]Forecast, error)\n```\n\nIncluded in:\n- Chief SM's PortfolioContext (for planning/retro prompts)\n- API: GET /forecast and GET /forecast/{project}\n- Daily standup (per-project scrum master mentions 'at current velocity, backlog clears in N days')\n\nAcceptance: Forecasts calculate from velocity+backlog, rate limit runway computed, available in API and prompts","status":"open","priority":3,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:41:30.290196833+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T17:41:30.290196833+10:00","labels":["code"],"dependencies":[{"issue_id":"cortex-xhk.10","depends_on_id":"cortex-xhk","type":"parent-child","created_at":"2026-02-17T17:41:30.294575172+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-xhk.10","depends_on_id":"cortex-xhk.2","type":"blocks","created_at":"2026-02-17T17:41:49.267352889+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-xhk.10","depends_on_id":"cortex-xhk.4","type":"blocks","created_at":"2026-02-17T17:41:49.424603376+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-xhk.11","title":"Unified backlog API endpoint","description":"API endpoint showing beads across all projects in one view. Pure Go code — query aggregation.\n\n**Implementation:**\n\nAdd to internal/api/api.go:\n\nGET /backlog — unified backlog across all projects\n- Query params: ?status=open\u0026project=X\u0026sort=priority\n- Returns beads from all enabled projects with project field added\n- Includes cross-project dependency info\n- Sorted by priority (respecting project priority weight)\n\nGET /backlog/stats — aggregate stats\n- Total open, in_progress, blocked across all projects\n- Per-project breakdown\n- Cross-project blockers count\n\nGET /portfolio — high-level portfolio view\n- Per-project: open/progress/blocked/velocity\n- Overall capacity: rate limit used/remaining\n- Current sprint number and day\n- Next ceremony time\n\nNo LLM needed — this is query aggregation and JSON serialization.\n\nAcceptance: Endpoints return correct cross-project data, filtering works, sorted by priority","status":"open","priority":3,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:41:39.388353475+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T17:41:39.388353475+10:00","labels":["code"],"dependencies":[{"issue_id":"cortex-xhk.11","depends_on_id":"cortex-xhk","type":"parent-child","created_at":"2026-02-17T17:41:39.390504032+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-xhk.11","depends_on_id":"cortex-xhk.1","type":"blocks","created_at":"2026-02-17T17:41:49.577448584+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-xhk.2","title":"Aligned sprint cadence across projects","description":"Align all projects to a shared sprint cadence. Pure Go code — scheduling logic.\n\n**Current state:**\nEach project ticks independently. Sprint planning day/time is per-project. No concept of a shared sprint.\n\n**Implementation:**\n\nAdd to config:\n```toml\n[cadence]\nsprint_length = \"1w\"           # 1w, 2w\nsprint_start_day = \"Monday\"\nsprint_start_time = \"09:00\"\ntimezone = \"UTC\"\n```\n\nCreate internal/scheduler/cadence.go:\n```go\ntype SprintCadence struct {\n    Length    time.Duration\n    StartDay time.Weekday\n    StartTime string  // HH:MM\n    Timezone *time.Location\n}\n\n// CurrentSprint returns the current sprint number and boundaries\nfunc (c *SprintCadence) CurrentSprint() (number int, start, end time.Time)\n\n// IsSprintBoundary returns true if we're within N minutes of sprint start/end\nfunc (c *SprintCadence) IsSprintBoundary(t time.Time, windowMinutes int) (isStart, isEnd bool)\n\n// SprintDay returns which day of the sprint we're on (1-indexed)\nfunc (c *SprintCadence) SprintDay(t time.Time) int\n\n// NextCeremony returns the next scheduled ceremony time\nfunc (c *SprintCadence) NextCeremony() (name string, at time.Time)\n```\n\nCeremony schedule (derived from cadence, no per-project config needed):\n- Sprint planning: sprint start day, start time\n- Daily standup: every day at start time\n- Sprint review: last day of sprint, start time\n- Sprint retro: last day of sprint, start time + 1h\n\nPer-project sprint_planning_day/time in a4s.9 becomes optional override, defaults to cadence.\n\nStore additions:\n- RecordSprintBoundary(sprintNumber, start, end)\n- GetCurrentSprintNumber() int\n\nAcceptance: Unified cadence, ceremonies derive from it, per-project override still works, sprint numbers tracked","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:39:32.081453679+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T17:39:32.081453679+10:00","labels":["code"],"dependencies":[{"issue_id":"cortex-xhk.2","depends_on_id":"cortex-xhk","type":"parent-child","created_at":"2026-02-17T17:39:32.087561951+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-xhk.3","title":"Implement Chief Scrum Master agent","description":"Create the Chief Scrum Master (Chief SM) — a coordination agent that sits above per-project scrum masters.\n\n**What requires LLM:** Reasoning about cross-project trade-offs, synthesizing patterns across teams, producing actionable coordination decisions. The Chief SM is the only agent that sees ALL projects simultaneously.\n\n**What is code (not LLM):** Agent creation, data gathering, prompt assembly, ceremony scheduling.\n\n**Implementation:**\n\nAdd Chief SM to internal/team/team.go:\n```go\n// New role (not per-project — global)\n\"chief-scrum\": `# Chief Scrum Master Agent\n\nYou are the Chief Scrum Master coordinating across all projects.\n\n## Responsibilities\n- Run multi-team sprint planning: allocate work across projects\n- Run overall retrospective: spot systemic patterns across teams\n- Mediate resource contention: when projects compete for capacity\n- Escalate impediments that individual scrum masters can't resolve\n- Ensure cross-project dependencies are tracked and unblocked\n\n## You communicate via Matrix in the coordination room\n- Summarize cross-team status\n- Flag systemic risks\n- Propose capacity allocation changes\n\n## You do NOT\n- Refine individual beads (that's the project scrum master)\n- Make product decisions (that's the human PO)\n`\n```\n\nAgent naming: 'cortex-chief-scrum' (not project-prefixed — it's global)\n\nCreate internal/scheduler/chief.go:\n```go\ntype ChiefSM struct {\n    store      *store.Store\n    dispatcher *dispatch.Dispatcher\n    cfg        *config.Config\n    logger     *slog.Logger\n}\n\n// GatherPortfolioContext builds context across ALL projects (code, not LLM)\nfunc (c *ChiefSM) GatherPortfolioContext() *PortfolioContext\n\ntype PortfolioContext struct {\n    Projects       []ProjectSummary  // per-project stats\n    CrossDeps      []CrossDepStatus  // unresolved cross-deps\n    RateLimitUsage RateLimitSummary  // global capacity state\n    ProviderHealth map[string]ProviderHealthSummary\n    SprintNumber   int\n    SprintDay      int\n}\n\ntype ProjectSummary struct {\n    Name           string\n    OpenBeads      int\n    InProgress     int\n    Blocked        int\n    CompletedThisSprint int\n    FailedThisSprint    int\n    Velocity       float64\n    ScrumMasterAgent string\n}\n```\n\nConfig:\n```toml\n[chief]\nenabled = true\nmatrix_room = \"!coordination:matrix.org\"   # separate room for cross-team coordination\nmodel = \"claude-opus-4-6\"                  # always Opus\n```\n\nThe Chief SM dispatches are always premium tier. It only runs for ceremonies (not per-tick), so rate limit impact is minimal.\n\nAcceptance: Chief SM agent exists, GatherPortfolioContext works, config parsed, agent created on startup","notes":"REPLACED: This task was too complex (entire Chief Scrum Master agent system). \n\nReplaced with focused tasks:\n- cortex-1ik: Add chief scrum master configuration schema\n- cortex-e3f: Create chief scrum master agent role definition\n\nThese focused tasks can be completed by overnight automation, building the foundation incrementally.","status":"closed","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:39:54.054416696+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:45:31.349987744+10:00","closed_at":"2026-02-18T02:45:11.027306935+10:00","dependencies":[{"issue_id":"cortex-xhk.3","depends_on_id":"cortex-xhk","type":"parent-child","created_at":"2026-02-17T17:39:54.058618895+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-xhk.3","depends_on_id":"cortex-xhk.1","type":"blocks","created_at":"2026-02-17T17:41:47.700075134+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-xhk.3","depends_on_id":"cortex-xhk.2","type":"blocks","created_at":"2026-02-17T17:41:47.839437407+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-xhk.4","title":"Rate limit capacity budgeting per project","description":"Allocate rate limit budget across projects instead of first-come-first-served. Pure Go code — arithmetic and enforcement.\n\n**Current problem:**\nRate limits are global. If project A is high priority and project B is low priority, B can still exhaust the weekly cap before A gets its work done. The rate limiter doesn't know about project priority.\n\n**Implementation (all deterministic code):**\n\nConfig:\n```toml\n[rate_limits]\nwindow_5h_cap = 20\nweekly_cap = 200\n\n# Budget allocation (must sum to 100)\n[rate_limits.budget]\nhg-website = 60      # 60% of weekly cap = 120 dispatches\nother-project = 40   # 40% = 80 dispatches\n```\n\nIf no budget section exists, fall back to current behavior (shared pool).\n\nExtend internal/dispatch/ratelimit.go:\n```go\n// BudgetedCanDispatch checks project-specific budget before dispatching\nfunc (rl *RateLimiter) BudgetedCanDispatch(project string) (bool, string)\n\n// ProjectBudget returns remaining capacity for a project\nfunc (rl *RateLimiter) ProjectBudget(project string) (used, cap int)\n\n// RebalanceBudget allows Chief SM to temporarily shift allocation (e.g. 'all hands on A')\nfunc (rl *RateLimiter) RebalanceBudget(allocations map[string]int) error\n```\n\nStore query:\n- CountAuthedUsageByProject(project, window) — already have provider-level, add project grouping\n\nScheduler integration:\n- RunTick checks BudgetedCanDispatch(project) before picking provider\n- If project budget exhausted but global cap has room, log it but don't dispatch\n\nAPI addition:\n- GET /status includes per-project budget: used/cap/remaining\n\nAcceptance: Budget enforced per project, fallback to shared pool if unconfigured, rebalance API works","notes":"REPLACED: This task was too complex (multi-system rate limit integration).\n\nReplaced with focused tasks:\n- cortex-ood: Add rate limit budget configuration parsing  \n- cortex-rlj: Add per-project rate limit tracking\n- cortex-nk8: Implement per-project budget enforcement\n\nThese focused tasks can be completed by overnight automation, building the capability incrementally.","status":"closed","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:40:10.215643736+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:45:15.048405339+10:00","closed_at":"2026-02-18T02:45:15.048415318+10:00","labels":["code"],"dependencies":[{"issue_id":"cortex-xhk.4","depends_on_id":"cortex-xhk","type":"parent-child","created_at":"2026-02-17T17:40:10.450122079+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-xhk.5","title":"Cross-project provider performance profiling","description":"Aggregate provider performance stats across all projects and detect patterns. Mostly Go code for stats, with optional LLM analysis in retro.\n\n**What is code:** Aggregating success/fail rates by provider × label/type across projects. Detecting statistical patterns (e.g. 'provider X fails \u003e50% on label:go'). Building skill profiles.\n\n**What is LLM (handled in overall retro, not here):** Interpreting why a provider fails and recommending what to do about it.\n\n**Implementation:**\n\nCreate internal/learner/profiles.go:\n```go\ntype ProviderProfile struct {\n    Provider     string\n    TotalDispatches int\n    SuccessRate  float64\n    AvgDuration  float64\n    // Performance by label\n    LabelStats   map[string]LabelPerformance\n    // Performance by bead type\n    TypeStats    map[string]LabelPerformance\n}\n\ntype LabelPerformance struct {\n    Label       string\n    Total       int\n    SuccessRate float64\n    AvgDuration float64\n    Trend       string // improving, stable, degrading\n}\n\n// BuildProviderProfiles aggregates stats across all projects\nfunc BuildProviderProfiles(store *store.Store, window time.Duration) (map[string]ProviderProfile, error)\n\n// DetectWeaknesses returns provider+label combos with \u003e40% failure rate and \u003e=3 samples\nfunc DetectWeaknesses(profiles map[string]ProviderProfile) []Weakness\n\ntype Weakness struct {\n    Provider    string\n    Label       string\n    FailureRate float64\n    SampleSize  int\n    Suggestion  string  // deterministic: 'deprioritize for label:go'\n}\n\n// ApplyProfileToTierSelection adjusts tier/provider selection based on profiles\n// e.g. if provider X is weak on label:go, skip it for Go beads even if it's in the right tier\nfunc ApplyProfileToTierSelection(profiles map[string]ProviderProfile, bead beads.Bead, candidates []string) []string\n```\n\nStore additions:\n- Dispatches already store provider and tier. Need to also store bead labels (add labels column to dispatches table) so we can query performance by label.\n- Query: GetProviderLabelStats(window) — group by provider, label, count success/fail\n\nIntegration:\n- Scheduler calls ApplyProfileToTierSelection when picking provider — filters out providers known to be weak for this bead's labels\n- Profiles rebuilt periodically (every N ticks or daily), cached in memory\n- Weaknesses included in portfolio context for Chief SM retro\n\nAcceptance: Profiles built from dispatch history, weaknesses detected, weak providers filtered from selection, data available for retro","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:40:28.427985135+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T17:40:28.427985135+10:00","labels":["code"],"dependencies":[{"issue_id":"cortex-xhk.5","depends_on_id":"cortex-xhk","type":"parent-child","created_at":"2026-02-17T17:40:28.431917212+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-xhk.6","title":"Multi-team sprint planning ceremony","description":"Chief SM runs a unified sprint planning across all projects. LLM for reasoning about allocation trade-offs.\n\n**What is code:** Gathering backlogs, calculating capacity, enforcing budget constraints, recording sprint plan.\n**What is LLM (Chief SM dispatch):** Reasoning about priority trade-offs, resolving cross-project conflicts, producing allocation rationale.\n\n**Implementation:**\n\nExtend internal/scheduler/chief.go:\n\nfunc (c *ChiefSM) RunMultiTeamPlanning(ctx):\n\nCode (before dispatch):\n1. Gather all project backlogs (unrefined + refined beads across all projects)\n2. Build cross-project dependency graph\n3. Calculate per-project capacity budget (from rate_limits.budget)\n4. Get provider profiles (what's working, what's weak)\n5. Get each project's sprint planning results if already run (from a4s.9)\n6. Package into PortfolioContext\n\nLLM (Chief SM dispatch at premium/Opus tier):\n7. Chief SM receives PortfolioContext + all backlogs\n8. Reviews cross-project dependencies: 'Project B needs endpoint from Project A — prioritize A's endpoint bead'\n9. Allocates capacity: 'Project A gets 60% this sprint (critical deadline), B gets 40%'\n10. Identifies conflicts: 'Both projects want premium tier for similar work — stagger them'\n11. Produces unified sprint plan sent to coordination Matrix room\n\nAfter dispatch (code):\n12. Record allocations in store\n13. Update rate limit budgets if Chief SM recommended rebalancing\n\nScheduling: runs at sprint start (from cadence config), BEFORE individual project sprint planning.\nOrder: Chief SM multi-team planning → per-project scrum master sprint planning (a4s.9)\n\nPrompt template: 'sprint_planning_multi' — includes all project backlogs, cross-deps, capacity, profiles.\n\nAcceptance: Chief SM sees all projects, reasons about allocation, produces unified plan, runs before per-project planning","notes":"⚠️ NEEDS BREAKDOWN: This task is still too complex for overnight automation. It attempts to build entire multi-team sprint planning ceremony with:\n\n- Portfolio context gathering across all projects\n- Cross-project dependency analysis  \n- Capacity budget calculations\n- Provider performance integration\n- LLM dispatch coordination with complex prompts\n- Matrix room integration and reporting\n- Store recording of allocations and decisions\n\nRecommend breaking into 4-5 focused tasks:\n1. Add portfolio backlog gathering queries\n2. Create multi-team planning prompt template  \n3. Add ceremony scheduling infrastructure\n4. Implement allocation recording and reporting\n5. Integrate ceremony with scheduler triggers\n\nEach task should be completable in a single focused session.","status":"open","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:40:43.697836427+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:45:22.919375845+10:00","dependencies":[{"issue_id":"cortex-xhk.6","depends_on_id":"cortex-xhk","type":"parent-child","created_at":"2026-02-17T17:40:43.727751168+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-xhk.6","depends_on_id":"cortex-xhk.3","type":"blocks","created_at":"2026-02-17T17:41:47.987719672+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-xhk.6","depends_on_id":"cortex-xhk.4","type":"blocks","created_at":"2026-02-17T17:41:48.123624311+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-xhk.6","depends_on_id":"cortex-xhk.5","type":"blocks","created_at":"2026-02-17T17:41:48.26979425+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-xhk.7","title":"Overall retrospective ceremony","description":"Chief SM runs a meta-retrospective across all projects. LLM for pattern analysis.\n\n**What is code:** Aggregating per-project retro data, cross-project stats, systemic metrics.\n**What is LLM (Chief SM dispatch):** Spotting systemic patterns, producing cross-cutting recommendations.\n\n**Implementation:**\n\nExtend internal/scheduler/chief.go:\n\nfunc (c *ChiefSM) RunOverallRetro(ctx):\n\nCode (data gathering):\n1. Collect per-project RetroReports (from retro.go)\n2. Aggregate: total dispatches, failures, velocity across all projects\n3. Build cross-project provider profiles (from profiles.go)\n4. Get cross-project dependency resolution stats: how many cross-deps resolved this sprint, how many are still blocking\n5. Rate limit usage: per-project budget utilization, any project starved?\n6. Compare sprint plan vs actual across all projects\n\nLLM (Chief SM dispatch at premium/Opus tier):\n7. Chief SM receives all aggregated data\n8. Identifies systemic patterns:\n   - 'Provider X is underperforming across ALL projects, not just one'\n   - 'Cross-project deps are the #1 blocker — 3 beads blocked for \u003e3 days'\n   - 'Tier misclassification is 30% globally — complexity detection needs tuning'\n   - 'Project A is starving Project B of capacity — rebalance budget'\n9. Produces action items:\n   - Code-level: 'adjust complexity thresholds' (can create beads)\n   - Config-level: 'deprioritize provider X' (can suggest config changes)\n   - Process-level: 'require estimates on all beads before sprint planning'\n10. Sends to coordination Matrix room\n\nScheduling: runs at sprint end (from cadence), AFTER per-project retros.\nOrder: per-project retros (a4s.11) → Chief SM overall retro\n\nAcceptance: Chief SM analyzes cross-project patterns, produces systemic recommendations, creates follow-up beads if needed","notes":"⚠️ NEEDS BREAKDOWN: This task is still too complex for overnight automation. Overall retrospective ceremony involves:\n\n- Cross-project data aggregation and analysis\n- Pattern recognition across multiple teams  \n- Systemic issue identification and reporting\n- Complex LLM prompts for cross-team insights\n- Matrix integration for coordination communication\n\nRecommend breaking into 3-4 focused tasks:\n1. Add cross-project retrospective data gathering\n2. Create retrospective analysis prompt templates\n3. Add retrospective scheduling and triggers  \n4. Implement retrospective reporting and communication\n\nEach task should be completable in a single focused session.","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:40:57.016207201+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:45:28.143018388+10:00","dependencies":[{"issue_id":"cortex-xhk.7","depends_on_id":"cortex-xhk","type":"parent-child","created_at":"2026-02-17T17:40:57.018624225+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-xhk.7","depends_on_id":"cortex-xhk.3","type":"blocks","created_at":"2026-02-17T17:41:48.515419988+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-xhk.7","depends_on_id":"cortex-xhk.5","type":"blocks","created_at":"2026-02-17T17:41:48.71094653+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-xhk.8","title":"Unified sprint review","description":"Chief SM produces a single sprint review summarizing what shipped across all projects. LLM for narrative synthesis.\n\n**What is code:** Gathering completed beads, velocity, stats per project.\n**What is LLM (Chief SM dispatch):** Synthesizing a coherent narrative of what shipped, for the human PO.\n\n**Implementation:**\n\nExtend internal/scheduler/chief.go:\n\nfunc (c *ChiefSM) RunUnifiedReview(ctx):\n\nCode:\n1. For each project: list beads closed during this sprint\n2. Calculate: planned (from sprint plan) vs delivered\n3. Get velocity per project and overall\n4. Identify scope changes mid-sprint\n\nLLM (Chief SM at premium tier):\n5. Produce portfolio-level narrative:\n   - What shipped across all projects (grouped by project)\n   - Overall completion rate: N/M planned beads across all projects\n   - Cross-project milestones: 'Project A's API is done, unblocking Project B'\n   - Risks carrying into next sprint\n6. Send to coordination Matrix room (and optionally to per-project rooms)\n\nScheduling: sprint end, before retro.\nOrder: unified review → per-project retros → overall retro\n\nAcceptance: Narrative covers all projects, planned vs delivered, sent to Matrix","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:41:06.716314596+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T17:41:06.716314596+10:00","dependencies":[{"issue_id":"cortex-xhk.8","depends_on_id":"cortex-xhk","type":"parent-child","created_at":"2026-02-17T17:41:06.721542958+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-xhk.8","depends_on_id":"cortex-xhk.3","type":"blocks","created_at":"2026-02-17T17:41:48.847793786+10:00","created_by":"Simon Heikkila"},{"issue_id":"cortex-xhk.8","depends_on_id":"cortex-xhk.2","type":"blocks","created_at":"2026-02-17T17:41:49.122137158+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-xhk.9","title":"Definition of Done enforcement","description":"Configurable per-project DoD that the ops/qa agent checks. Pure Go code — run commands, check results.\n\n**Implementation:**\n\nConfig:\n```toml\n[projects.hg-website.dod]\nchecks = [\n    \"go test ./...\",\n    \"go vet ./...\",\n    \"golangci-lint run\",\n]\ncoverage_min = 70          # optional: fail if coverage \u003c N%\nrequire_estimate = true    # bead must have estimate before closing\nrequire_acceptance = true  # bead must have acceptance criteria\n```\n\nCreate internal/scheduler/dod.go:\n```go\ntype DoDChecker struct {\n    checks          []string\n    coverageMin     int\n    requireEstimate bool\n    requireAcceptance bool\n}\n\n// CheckDoD runs all DoD checks in the project workspace. Returns pass/fail with details.\n// This is called by the scheduler when a dispatch completes (before marking bead as done).\nfunc (d *DoDChecker) Check(ctx context.Context, workspace string, bead beads.Bead) (*DoDResult, error)\n\ntype DoDResult struct {\n    Passed  bool\n    Checks  []CheckResult  // per-command results\n    Failures []string       // human-readable failure reasons\n}\n\ntype CheckResult struct {\n    Command  string\n    ExitCode int\n    Output   string  // truncated\n    Passed   bool\n}\n```\n\nIntegration:\n- After ops/qa agent completes and before bd close, scheduler runs DoDChecker\n- If DoD fails, bead transitions back to stage:coding with failure notes\n- DoD results recorded in store for retro analysis\n- No LLM needed — this is running commands and checking exit codes\n\nAcceptance: DoD checks run on completion, failures block closing, results recorded, configurable per project","status":"open","priority":2,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T17:41:18.931164144+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T17:41:18.931164144+10:00","labels":["code"],"dependencies":[{"issue_id":"cortex-xhk.9","depends_on_id":"cortex-xhk","type":"parent-child","created_at":"2026-02-17T17:41:18.953268002+10:00","created_by":"Simon Heikkila"}]}
{"id":"cortex-y6s","title":"Auto: break down epic cortex-46d into executable bug/task beads","description":"Epic `cortex-46d` is still open in project `cortex`.\n\nPolicy: epics should not be assigned directly to coders. Break this epic into concrete `bug`/`task` beads with acceptance criteria so overnight automation can execute them.\n\nEpic title: Self-healing control-loop hardening","status":"closed","priority":1,"issue_type":"task","assignee":"Simon Heikkila","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T03:20:16.086055589+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T04:21:28.096302161+10:00","closed_at":"2026-02-18T04:21:28.096302161+10:00","close_reason":"Epic breakdown completed successfully - 13 tasks created and approved","labels":["stage:qa"],"dependencies":[{"issue_id":"cortex-y6s","depends_on_id":"cortex-46d","type":"discovered-from","created_at":"2026-02-18T03:20:16.10937239+10:00","created_by":"Simon Heikkila"}],"comments":[{"id":1,"issue_id":"cortex-y6s","author":"Simon Heikkila","text":"**REVIEWER ASSESSMENT: APPROVED ✅**\n\nEpic cortex-46d breakdown completed to exceptional standards:\n- 13 properly specified bug/task beads with executable acceptance criteria  \n- Outstanding technical architecture with safety boundaries\n- Comprehensive test coverage and observability strategies\n- All tasks ready for overnight automation execution\n\nTransitioned to stage:qa for validation.","created_at":"2026-02-17T18:13:09Z"}]}
{"id":"cortex-yh4","title":"Treat tmux session status 'gone' as failed / needs-check in scheduler","description":"In scheduler.checkRunningDispatches, tmux sessions returning status 'gone' are currently classified as completed with exit_code=0. Update classification to mark dispatch as failed and/or NeedsCheck so it can be manually diagnosed and retried according to policy.","notes":"**Review Result: APPROVED**\n\n**Excellent Implementation - Complete Solution**:\n\n## Core Functionality - CORRECTLY IMPLEMENTED\n\n**Before (Bug):**\n- Tmux sessions with status gone were marked as completed with exit_code=0\n- No diagnostic information was captured\n- Sessions that disappeared were treated as successful\n\n**After (Fixed):**\n- Status gone → dispatch marked as failed with exit_code=-1\n- finalStage set to gone for clear identification  \n- Comprehensive logging and health event recording\n- Failure diagnosis with specific category and summary\n\n## Implementation Quality\n\n**1. Proper Status Handling:**\n- gone case now sets status=failed, exitCode=-1, finalStage=gone\n\n**2. Comprehensive Logging:**\n- Error-level logging with detailed context (bead, session, agent, provider, duration)\n- Health event recording for tracking patterns\n- Structured logging for observability\n\n**3. Failure Diagnosis Integration:**\n- Category: session_disappeared\n- Summary: Clear explanation of potential causes and need for manual investigation\n- Stored in database for analysis and retry decisions\n\n**4. Database Schema Support:**\n- failure_category and failure_summary columns exist\n- UpdateFailureDiagnosis method implemented and tested\n- Proper schema migration logic in place\n\n## Testing Status\n\n**Core Components Tested:**\n- SessionStatus gone returns correct values (tmux_test.go)\n- UpdateFailureDiagnosis database operations (store_test.go)\n- All scheduler tests pass\n- All store tests pass\n\n## Acceptance Criteria Assessment\n\n- Mark dispatch as failed: IMPLEMENTED\n- NeedsCheck capability: IMPLEMENTED - failure diagnosis with manual investigation note\n- Manual diagnosis: IMPLEMENTED - detailed health events and failure summaries  \n- Retry policy compatibility: IMPLEMENTED - failed dispatches can be retried per existing policy\n\n**Overall Assessment:** \nThis is a thorough, well-architected fix that properly addresses the core issue while providing excellent observability and diagnostic capabilities.\n\nApproved for stage:qa","status":"closed","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-17T20:48:15.22403479+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-17T21:08:05.65529401+10:00","closed_at":"2026-02-17T21:08:05.65529401+10:00","close_reason":"Closed","labels":["stage:qa"]}
{"id":"cortex-zly","title":"Define burn-in SLO metrics and thresholds","description":"Establish clear definitions and thresholds for 7-day burn-in SLO metrics required for launch readiness evaluation.\n\n## Goal\nDefine precise calculations and acceptable thresholds for each burn-in metric to enable consistent scoring.\n\n## Metrics to Define\n\n### 1. Unknown/Disappeared Failure Rate\n- **Calculation**: (dispatches with failure_category='session_disappeared' OR failure_category='unknown_exit_state') / total_dispatches * 100\n- **7-day threshold**: \u003c 2%\n- **Daily threshold**: \u003c 5%\n\n### 2. Intervention Rate  \n- **Calculation**: (manual cancellations + manual retries) / total_dispatches * 100\n- **7-day threshold**: \u003c 10% \n- **Daily threshold**: \u003c 15%\n\n### 3. Critical Health Events\n- **Events**: gateway_critical, dispatch_session_gone, bead_churn_blocked\n- **7-day threshold**: \u003c 5 events\n- **Daily threshold**: \u003c 2 events\n\n### 4. System Stability\n- **Calculation**: uptime_percentage over 7 days\n- **Threshold**: \u003e 99%\n\n## Deliverables\n1. **burn-in-metrics.md** - Formal metric definitions\n2. **slo-thresholds.json** - Machine-readable thresholds  \n3. **Data source mapping** - Which tables/columns provide each metric\n\n## Acceptance Criteria  \n1) All metric calculations are precisely defined with SQL queries\n2) Thresholds are set for both daily and 7-day evaluations\n3) Data sources are identified and verified to exist\n4) Definitions are reviewable by ops team for correctness\n5) Machine-readable format enables automated scoring","status":"open","priority":1,"issue_type":"task","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:33:21.450591703+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:33:21.450591703+10:00","labels":["definition","launch","metrics","slo"]}
{"id":"cortex-ztu","title":"Auto: churn guard blocked bead cortex-c4j.3 (6 dispatches/1h0m0s)","description":"Bead `cortex-c4j.3` in project `cortex` exceeded churn threshold (6 dispatches in 1h0m0s) and was blocked from further overnight dispatch.\n\nPlease investigate root cause, split work into smaller tasks if needed, and add hardening/tests before re-enabling.\n\nBead title: Publish operational runbook set for launch operations\nBead type: task","status":"closed","priority":1,"issue_type":"bug","owner":"simon.heikkila@gmail.com","created_at":"2026-02-18T02:35:14.303927803+10:00","created_by":"Simon Heikkila","updated_at":"2026-02-18T02:43:26.011072479+10:00","closed_at":"2026-02-18T02:43:26.011072479+10:00","close_reason":"Root cause confirmed from dispatch output: dispatches 1039,1050,1059,1068,1078,1082 for cortex-c4j.3 all contained 'LLM request rejected ... context limit' and looped as completed re-dispatches. Fixes applied: scheduler churn-escalation dedupe (active existing churn issue check) plus regression tests (TestHasActiveChurnEscalation, TestDetectTerminalOutputFailure_OpenClawContextLimitRejection). Operational split applied: created scoped runbook tasks cortex-070, cortex-wp6, cortex-byi, cortex-trl, cortex-84h; moved cortex-c4j.3 to in_progress to stop overnight re-dispatch while subtasks proceed. Verification: go test ./... passed.","dependencies":[{"issue_id":"cortex-ztu","depends_on_id":"cortex-c4j.3","type":"discovered-from","created_at":"2026-02-18T02:35:14.307299072+10:00","created_by":"Simon Heikkila"}]}
