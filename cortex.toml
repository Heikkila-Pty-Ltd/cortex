# Cortex Agent Orchestrator Configuration

[general]
tick_interval = "2m"
max_per_tick = 1
max_concurrent_coders = 1
max_concurrent_reviewers = 1
max_concurrent_total = 2
stuck_timeout = "30m"
max_retries = 2
log_level = "info"
state_db = "~/.local/share/cortex/cortex.db"

[projects.cortex]
enabled = true
beads_dir = "~/projects/cortex/.beads"
workspace = "~/projects/cortex"
priority = 0

[projects.cortex.dod]
checks = [
    "go test ./...",
    "go vet ./...",
    "golangci-lint run --timeout=5m",
]
coverage_min = 70
require_estimate = true
require_acceptance = true

[projects.hg-website]
enabled = true
beads_dir = "~/projects/hg-website/.beads"
workspace = "~/projects/hg-website"
priority = 1

[rate_limits]
window_5h_cap = 150
weekly_cap = 2000
weekly_headroom_pct = 70

[providers.openai-pro]
tier = "balanced"
authed = true
model = "o4-mini"

[providers.google-pro]
tier = "premium"
authed = true
model = "gemini-2.5-pro"

[providers.kimi]
tier = "premium"
authed = true
model = "kimi-k2"

[providers.codex-spark]
tier = "fast"
authed = true
model = "gpt-5.3-codex-spark"
cli = "codex"

[providers.codex]
tier = "balanced"
authed = true
model = "gpt-5.3-codex-spark"
cli = "codex"

[providers.codex-max]
tier = "premium"
authed = true
model = "gpt-5.3-codex-spark"
cli = "codex"

[providers.cerebras]
tier = "fast"
authed = false
model = "llama-4-scout"

[providers.groq]
tier = "fast"
authed = false
model = "llama-4-scout"

[tiers]
# Spark-only to conserve Pro/Max usage
fast = ["codex-spark", "cerebras", "groq"]
balanced = ["codex-spark"]
premium = ["codex-spark"]

[health]
check_interval = "2m"
gateway_unit = "openclaw-gateway.service"
gateway_user_service = true

[reporter]
channel = "matrix"
agent_id = "main"
matrix_bot_account = "spritzbot"
default_room = "!adJhqAxLcYqQuYraGf:vmi3041112.contaboserver.net"
daily_digest_time = "09:00"
weekly_retro_day = "Monday"

[learner]
enabled = true
analysis_window = "48h"
cycle_interval = "6h"
include_in_digest = true

[api]
bind = "127.0.0.1:8900"

[dispatch.cli.codex]
cmd = "codex"
prompt_mode = "stdin"
args = ["exec", "--full-auto"]
model_flag = "-m"
approval_flags = []

[dispatch.cli.aider]
cmd = "aider"
prompt_mode = "file"
args = ["--yes-always"]
model_flag = "--model"
approval_flags = []

[dispatch.routing]
fast_backend = "headless_cli"
balanced_backend = "headless_cli"
premium_backend = "headless_cli"
comms_backend = "headless_cli"
retry_backend = "headless_cli"

[dispatch.cost_control]
enabled = true
spark_first = true
retry_escalation_attempt = 2
complexity_escalation_minutes = 180
risky_review_labels = ["risk:high", "security", "migration", "breaking-change", "database"]
force_spark_at_weekly_usage_pct = 65
per_bead_stage_attempt_limit = 2
stage_attempt_window = "6h"
stage_cooldown = "45m"

[dispatch.timeouts]
fast = "15m"
balanced = "45m"
premium = "120m"

[dispatch.git]
branch_prefix = "cortex/"
branch_cleanup_days = 7
merge_strategy = "squash"
max_concurrent_per_project = 1

[dispatch.tmux]
history_limit = 50000
session_prefix = "cortex-"

[chief]
enabled = true
matrix_room = "#cortex-coordination"
model = "gpt-5.3-codex-spark"
agent_id = "cortex-chief-scrum"
require_approved_plan = true
